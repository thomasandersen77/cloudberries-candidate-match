{"id":"5e3152840b19890f4e8c0cf4","keyQualifications":[{"label":"Om Øystein:","description":"Øystein er en erfaren systemutvikler med spisskompetanse innen Microsoft SQL Server, .NET, API-er og Azure-tjenester. Han har bred erfaring fra prosjekter som omfatter programvareutvikling, integrasjoner, migreringer, administrasjon og teknisk rådgivning, med roller som spenner fra DBA til teknisk prosjektleder og arkitekt.\n\nSelv om hans kjernekompetanse er innen Microsoft-teknologi, har Øystein også solid kunnskap og erfaring med en rekke andre teknologier, inkludert Java, Lotus Notes, Oracle, Sybase, PostgreSQL, MySQL, VMware, AWS og flere Open Source-verktøy.\n\nHans dype interesse for MS SQL Server har gjort ham til en nøkkelressurs i de fleste prosjektene han har deltatt i. Han har vært sentral i design og utvikling av databaser og applikasjoner, samt samspillet mellom disse. I tillegg har han bred erfaring med serverarkitektur, continuous integration og deployment, systemintegrasjoner, sikkerhet, vedlikehold, ytelsesoptimalisering, monitorering, replikering og maskinvarekrav.\n\nDe siste årene har Øystein gradvis beveget seg over mot datavarehus, DevOps/DevEx og Continuous Delivery. Han har jobbet tett på tvers av team for å forbedre bygg- og deploy-prosesser samt utviklingsmiljøer, og har vært en drivkraft i kontinuerlig forbedring av utviklings- og leveranseprosesser. Denne overgangen har vært naturlig for ham, da han besitter bred erfaring både fra drift, applikasjonsforvaltning og utvikling."}],"workExperiences":[{"employer":"New Media Science / Cell Network (nå Bouvet)","period":{"from":[2000,1],"to":[2001,3]}},{"employer":"Bekk Consulting","period":{"from":[2001,4],"to":[2003,12]}},{"employer":"Bekk Consulting","period":{"from":[2004,1],"to":[2006,12]}},{"employer":"ErgoGroup AS (nå Evry)","period":{"from":[2007,1],"to":[2008,5]}},{"employer":"Statens pensjonskasse","period":{"from":[2008,5],"to":[2011,4]}},{"employer":"Avanade","period":{"from":[2011,4],"to":[2015,5]}},{"employer":"Helsedirektoratet/Direktoratet for eHelse/Norsk Helsenett","period":{"from":[2015,6],"to":[2020,5]}},{"employer":"Cloudberries","period":{"from":[2020,5],"to":null}}],"projectExperiences":[{"customer":"EU + Institutt for energiteknikk","description":"Benchmarking","longDescription":"Et forskningsprosjekt for EU for å benchmarke energibruk og effektivitet for industribedrifter i europeiske land.\nTeknologi: .NET 2.0 (Web Applications), SQL Server 2005","period":{"from":null,"to":null},"roles":[{"name":"Arkitekt","description":"Designet en selvrapporteringsløsning som var høyt konfigurerbar i forhold til ulike matematiske modeller basert på industritype, energitype, geografisk lokasjon etc."},{"name":"Utvikler","description":"Testdrevet utvikling, backend + frontend av selvrapporteringsskjema, administrasjonsverktøy og database."},{"name":"Prosjektledelse","description":"Oppfølging av kunden i forhold til ukentlige rapportering av progresjon og prioritering av funksjonalitet, samt gjennomføre retrospektiv og sprintdemoer."}],"skillsUsed":[{"name":".NET","durationInYears":0},{"name":"SQL Server 2005","durationInYears":0}]},{"customer":"If forsikring","description":"Waypoint","longDescription":"Design og implementasjon av et nytt forsikringssystem for å erstatte gamle mainframe systemer som dekker poliser, produkter, prissetting, CRM, dokumenthåndtering og dokumentgenerering, fakturering, skade osv.\nTeknologi: .NET/WCF, SQL Server 2005, SQL Server Integration Services, SQL Server Service Broker, SQL Server Reporting Services\n\nSOA, Scrum, Continuous Integration og Continuous Deployment","period":{"from":null,"to":null},"roles":[{"name":"Utvikler","description":"Utviklet funksjonalitet frontend + backend + database i flere team/moduler (Polise + Dokumenter). Lagde meldingsutveksling ved hjelp av SQL Server Service Broker. "},{"name":"Teamansvarlig","description":"Design av arkitektur og teamleder for utvikling av Dokument-modul i løsningen"},{"name":"Databaseekspert","description":"Hjelpe alle teamene med QA og rådgivning i forhold til design og bruk av SQL Server."}],"skillsUsed":[{"name":".NET","durationInYears":0},{"name":"WCF","durationInYears":0},{"name":"SQL Server 2005","durationInYears":0},{"name":"SQL Server Service Broker 2005","durationInYears":0},{"name":"SQL Server Integration Services 2005","durationInYears":0},{"name":"SQL Server Reporting Services 2005","durationInYears":0}]},{"customer":"Statens persjonskasse","description":"(ansatt)","longDescription":"Jobbet som DBA og rådgiver for Statens pensjonskasse:\nPlanlegging og implementering av strategi for backup/restore, vedlikehold, sikkerhet og monitorering.\nMigrering av databaser fra Sybase og SQL Server 2000 til SQL Server 2005 og SQL Server 2008R2\nOptimalisering og reparasjon av gamle databaser.\nRådgivning og implementering av testmiljø for konsolidering og clustring av SQL Server.\nAnsvar for implentering og vedlikehold av en stor datavarehusløsning med Informatica, SQL Server 2008 R2 Enterprise Edition og Itanium-servere.\n\nAnsvar for drift av Linux servere.\n\nMottak av prosjekt i forbindelse med pensjonsreformen.","period":{"from":null,"to":null},"roles":[{"name":"Drift","description":"Tredjelinjesupport for klienter og applikasjoner, drift av servere og systemer."},{"name":"Databaseansvarlig","description":""},{"name":"Applikasjonsforvaltning","description":"Ansvar for diverse applikasjoner som Public360, MinTid, Agresso, Bloomberg m.m"}],"skillsUsed":[{"name":"SQL Server 2000","durationInYears":0},{"name":"SQL Server 2005","durationInYears":0},{"name":"SQL Server 2008","durationInYears":0},{"name":"Sybase","durationInYears":0},{"name":"Linux","durationInYears":0},{"name":"Informatica PowerCenter","durationInYears":0}]},{"customer":"(Diverse småoppdrag)","description":"","longDescription":"Flere oppdrag for å løse ytelsesproblemer i forbindelse med SQL Server hos flere kunder.\nOppdrag for å løse problemer med eksisterende SSIS implementasjoner.\nAnalyse og rådgivning.","period":{"from":null,"to":null},"roles":[{"name":"Databaseekspert","description":""}],"skillsUsed":[{"name":"SQL Server Integration Services 2008","durationInYears":0},{"name":"ETL-utvikling","durationInYears":0},{"name":"SQL Server 2008","durationInYears":0}]},{"customer":"Codan Forsikring ","description":"","longDescription":"Innsamling og vask av kundedata for å forbedre prissetting, underwriting, kampanjer og oppdaging av svindel. \nLaget et rammeverk for implementering av datavarehus og ETL-prosesser.","period":{"from":null,"to":null},"roles":[{"name":"Lead utvikler","description":""}],"skillsUsed":[{"name":"SQL Server Integration Services 2008","durationInYears":0},{"name":"ETL-utvikling","durationInYears":0}]},{"customer":"Terra","description":"Løft","longDescription":"","period":{"from":null,"to":null},"roles":[{"name":"Teknisk rådgiver","description":"Designe metode for å håndtere kapasiteten i antall kjerner på databaseserverne på en bedre måte i ETL-prosessene.\nLage ramme- og malverk for databaseutviklerne."}],"skillsUsed":[{"name":"SQL Server Integration Services 2012","durationInYears":0},{"name":"ETL-utvikling","durationInYears":0}]},{"customer":"Helsedirektoratet","description":"Kvalitetsindikatorer","longDescription":"Bygge en generisk løsning for å samle inn statistikk fra sykehus og andre helseinstitusjoner for å presentere data i offentlige kvalitetsindikatorrapporter. \nSQL Server 2012 (inkl. SSIS, SSAS, SSRS), SharePoint Portal Server 2010\nScrum, Continuous Integration med Team Foundation Server og PowerShell.","period":{"from":null,"to":null},"roles":[{"name":"Teknisk lead","description":"Utviklet rammeverk/malverk for å kjøre testdrevet utvikling i ETL/Database-prosjekter, som teamet benyttet. Teknisk team-oppfølging og QA."}],"skillsUsed":[{"name":"SQL Server Integration Services 2014","durationInYears":0},{"name":"ETL-utvikling","durationInYears":0},{"name":".NET","durationInYears":0},{"name":"SQL Analysis Services 2012","durationInYears":0},{"name":"SQL Reporting Services 2012","durationInYears":0},{"name":"TFS","durationInYears":0},{"name":"PowerShell","durationInYears":0}]},{"customer":"Aker Solutions","description":"ASAP","longDescription":"Verktøy som benytter Business Intelligence teknologi i Microsoft SQL Server –platformen for å tilby analyse av et selskaps måte å kommunisere med verktøy som SharePoint Portal server og Lync.\nProsjektet bestod av konfigurasjon og tilpasning av ASAP-verktøyet til infrastrukturen i Aker Solutions, men også assistere med deployment og systemtest.","period":{"from":null,"to":null},"roles":[{"name":"Lead utvikler","description":""}],"skillsUsed":[{"name":"ETL-utvikling","durationInYears":0},{"name":"SQL Server Integration Services 2012","durationInYears":0}]},{"customer":"Nordea, Stockholm","description":"Basel - Analysis and performance tuning","longDescription":"Utføre analyse av eksisterende datavarehus og databaser for å finne de viktigste tiltakene for å øke den overordnede ytelsen. Rådgivning i forhold til migrering fra SQL Server 2005 til SQL Server 2008R2, og endring av databasestrukturen for å utnytte ny maskinvare på en bedre måte. Kursing av utviklere for å skrive bedre og mer effektive databasespørringer.","period":{"from":null,"to":null},"roles":[{"name":"Konsulenttjenester","description":""}],"skillsUsed":[{"name":"SQL Server 2005","durationInYears":0},{"name":"SQL Server 2008","durationInYears":0},{"name":"ETL-utvikling","durationInYears":0}]},{"customer":"Sparebank1","description":"CRM Integration","longDescription":"Implementere et system for å forbedre markedsføringsaktiviteter, innsamling av bank- og forsikringsdata fra kildesystemer ved bruk av SQL Server Integration Services, transformering og aggregering av disse dataene for eskport til Microsoft Dynamics CRM. Kampanje- og markesdføringsdata blir så importert tilbake inn i en DataMart for videre analyse. Integrajoner mot andre lagringsløsninger som firmaets datavarehusløsning. Implementering av byggmiljø med Team Foundation Services, Team City, Power Shell og Delcom Lights for å understøtte Scrum metoden.","period":{"from":null,"to":null},"roles":[{"name":"Utvikler","description":""},{"name":"Build Master","description":"Continuous Integration, automatisk testing, bygg og deploy. "}],"skillsUsed":[{"name":"ETL-utvikling","durationInYears":0},{"name":"Datavarehus","durationInYears":0},{"name":"Team City","durationInYears":0},{"name":"Powershell","durationInYears":0},{"name":"TFS","durationInYears":0},{"name":"SQL Server Integration Services 2012","durationInYears":0},{"name":"Continous Integration","durationInYears":0}]},{"customer":"Helsedirektoratet","description":"Helsedirektoratet.no","longDescription":"Jobbet med backend og integrasjon for å utvikle nye helsedirektoratet.no, eHelse.no og nyeMetoder.no. Teknologi: SharePoint 2013, .NET 4.0","period":{"from":null,"to":null},"roles":[{"name":"Utvikler","description":""}],"skillsUsed":[{"name":".NET","durationInYears":0}]},{"customer":"Helsedirektoratet","description":"Helsenorge.no","longDescription":"Utviklet Innbyggerprofil-løsningen for Helsenorge.no, inkludert implementasjon av database, deployment-scripts, API og tjenestegrensesnitt. Sikret effektiv lagring og håndtering av brukerprofiler og egenskaper på tvers av flere helseplattformer. Teknologier brukt: MS SQL Server 2014 og .NET 4.0.","period":{"from":null,"to":null},"roles":[{"name":"Utvikler","description":""}],"skillsUsed":[{"name":"SQL Server 2014","durationInYears":0},{"name":".NET","durationInYears":0}]},{"customer":"Helsedirektoratet","description":"Frittsykehusvalg.no (forprosjekt)","longDescription":"Ledet design og spesifikasjon av løsning samt utvikling og dokumentasjon av prototype for den nye versjonen av FrittSykehusvalg.no. Påbegynte tidlig databaseutvikling, migreringsskript og API-utvikling for å sikre en robust og skalerbar plattform. Brukte teknologier som MS SQL Server 2014, SQL Server Integration Services 2014 og .NET 4.0 for å levere høy kvalitet og effektiv integrasjon.","period":{"from":null,"to":null},"roles":[{"name":"Databasearkitekt","description":""}],"skillsUsed":[{"name":"SQL Server 2014","durationInYears":0},{"name":"SQL Server Integration Services 2014","durationInYears":0},{"name":"ETL-utvikling","durationInYears":0},{"name":".NET","durationInYears":0}]},{"customer":"Helsedirektoratet (ansatt)","description":"Velg behandlingssted","longDescription":"Utviklet en moderne og robust løsning for å erstatte Frittsykehusvalg.no, med fokus på skalerbarhet og brukervennlighet. Brukte teknologier som .NET 4.0, WCF, SQL Server 2014 og SharePoint 2014 for å sikre høy ytelse og pålitelig integrasjon i eksisterende systemlandskap.","period":{"from":null,"to":null},"roles":[{"name":"Lead utvikler","description":"Backend + database + WCF integrasjoner"}],"skillsUsed":[{"name":".NET","durationInYears":0},{"name":"WCF","durationInYears":0},{"name":"SQL Server 2014","durationInYears":0}]},{"customer":"Helsedirektoratet/Direktoratet for eHelse/NHN (ansatt)","description":"Helsenorge.no","longDescription":"Teknisk team / DevOps\n-Definerte og implementerte strategier for mer effektive, stabile, sikre og hyppige leveranser gjennom hele utviklingsløpet.\n-Designet og standardiserte merge- og branch-strategier for å sikre smidig samarbeid på tvers av teams.\n-Støttet produksjonssetting og fasiliterte tydelig kommunikasjon mellom utvikling og drift for rask problemløsning.\n-Aktivt bidratt til å øke autonomi i utviklingsteamene og integrere DevOps-prinsipper bredt.\n-Utviklet rammeverk for bygg, deploy, enhetstesting, logging, rapportering og feilsøking på tvers av team.\n-Automatisert provisjonering av utviklings-, featuretest- og integrasjonstestmiljøer for å sikre rask og konsistent miljøtilgang.\n-Administrerte Azure-abonnement og optimaliserte kostnader via automatisering av oppetid for Azure-komponenter.\n-Skapte selvbetjeningsverktøy og portaler, inkludert Slack Commands, for å øke effektivitet og redusere avhengighet til support.\n-Fungerte som teknisk støtte for utviklere ved utfordringer og hindringer.\n\nTeknologier og verktøy:\nTFS/Azure DevOps, Azure/DSC, ARM-templates, Octopus Deploy, Git, DBUp/FluentMigrator, BigIP, SonarQube, Splunk, SQL Server 2012–2017, SharePoint 2014, PowerShell, Terraform, ASP.NET/.NET Core 2.2/3.1, WCF/REST, AMQP, RabbitMQ, Confluence, Slack","period":{"from":null,"to":null},"roles":[{"name":"Teknisk team/devops","description":""}],"skillsUsed":[{"name":"TFS/Azure Devops","durationInYears":0},{"name":"Azure/DSC","durationInYears":0},{"name":"Octopus Deploy","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Azure","durationInYears":0},{"name":"FluentMigrator","durationInYears":0},{"name":"Splunk","durationInYears":0},{"name":"PowerShell","durationInYears":0},{"name":"ASP.NET","durationInYears":0},{"name":"WCF","durationInYears":0},{"name":"Terraform","durationInYears":0},{"name":"F5 BigIP","durationInYears":0},{"name":"SQL Server 2017","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"Continous Integration","durationInYears":0},{"name":"Continuous Delivery","durationInYears":0},{"name":"ARM templates","durationInYears":0}]},{"customer":"Norsk Helsenett (ansatt)","description":"Statistikk prosjektet (forprosjekt)","longDescription":"Utviklet en Proof of Concept for en Power BI-løsning i Azure, inkludert ETL-prosesser som henter data fra flere databaser med varierende sikkerhetsnivåer, anonymiserer dataene, og visualiserer dem i et brukervennlig analyseverktøy.","period":{"from":[2020,5],"to":[2020,9]},"roles":[{"name":"Utvikler","description":""}],"skillsUsed":[]},{"customer":"Vipps as","description":"Vipps kundeinnsikt og data","longDescription":"Levere strategisk fagstøtte innen kundeinnsikt og datadrevet beslutningstaking, og hjelpe organisasjonen med å omsette data til konkrete, forretningsverdige innsikter.","period":{"from":[2020,10],"to":[2022,11]},"roles":[{"name":"Dataanalytiker","description":"Moderniserte eksisterende dataflyt ved å implementere ny teknologi, samlet og kvalitetssikret datagrunnlag for rapportering, og utviklet både forbedrede og nye rapporter for å dekke komplekse rapporteringsbehov."}],"skillsUsed":[{"name":"Azure Data Factory","durationInYears":0},{"name":"Aure Data Bricks","durationInYears":0},{"name":"Azure Data Lake Storage","durationInYears":0},{"name":"Azure Stream Analytics","durationInYears":0},{"name":"Power BI","durationInYears":0},{"name":"DAX","durationInYears":0},{"name":"Synapse SQL pool (data warehouse)","durationInYears":0},{"name":"Azure Analysis Services","durationInYears":0},{"name":"SQL Server 2019","durationInYears":0},{"name":"SQL Server Analysis Services 2019","durationInYears":0}]},{"customer":"BankAxept/BankID","description":"Bidbax kundeinnsikt og data","longDescription":"Levere strategisk fagstøtte innen kundeinnsikt og datadrevet beslutningstaking, og hjelpe organisasjonen med å omsette data til konkrete, forretningsverdige innsikter.","period":{"from":[2022,7],"to":[2024,9]},"roles":[{"name":"Data Engineer","description":"Ansvarlig for utvikling og drift av et API som gir betalende kunder tilgang til anonymiserte, dagsferske korttransaksjonsdata i Norge, segmentert på geografi og bransjer. Implementerte administrasjonsløsning for API-et via PowerApps for effektiv bruker- og tilgangsstyring. I tillegg integrerte jeg kundedata fra flere kilder inn i Salesforce via datavarehuset, samtidig som jeg håndterte vedlikehold og videreutvikling av datavarehusløsningen for å sikre stabilitet og skalerbarhet."}],"skillsUsed":[{"name":"Azure Synapse","durationInYears":0},{"name":"Azure Data Factory","durationInYears":0},{"name":"Azure API Management","durationInYears":0},{"name":"Azure SQL Database","durationInYears":0},{"name":"Azure App Services","durationInYears":0},{"name":"Power BI","durationInYears":0},{"name":"PowerApps","durationInYears":0},{"name":".NET Core","durationInYears":0},{"name":".NET Web API","durationInYears":0},{"name":"REST API","durationInYears":0},{"name":"Salesforce Data API","durationInYears":0},{"name":"SQL Server Analysis Services 2019","durationInYears":0}]},{"customer":"KPMG","description":"Kera 2.0","longDescription":"Migrerte et komplett datavarehus fra Oracle til Microsoft-plattform, og la samtidig grunnlaget for en smidig overgang til skybaserte tjenester i fremtiden. Sikret sømløs dataintegrasjon, optimal ytelse og fremtidssikret arkitektur for virksomhetens voksende behov.","period":{"from":[2023,11],"to":[2024,9]},"roles":[{"name":"Lead utvikler","description":"-Arkitekt for infrastruktur med fokus på skalerbarhet og robusthet\n-Ansvarlig for valg av metoder innen portering, utvikling, teststrategi, ytelse og sikkerhet\n-Veiledet og støttet utviklere for å sikre høy kvalitet og effektivitet\n-Utviklet automatiserte scripts for kodegenerering, inkludert avansert håndtering av SCD2\n-Utførte ytelsesoptimalisering for å sikre raske og stabile løsninger"}],"skillsUsed":[{"name":"Oracle","durationInYears":0},{"name":"Oracle (ODI)","durationInYears":0},{"name":"SQL Server Integration Services (SSIS)","durationInYears":0},{"name":"SQL Server Migration Assistant (SSMA)","durationInYears":0},{"name":"SQL Server 2019","durationInYears":0},{"name":"Visual Studio 2019","durationInYears":0},{"name":"C# .NET","durationInYears":0},{"name":"SQL Server Analysis Services (SSAS)","durationInYears":0}]},{"customer":"Element Logic","description":"eManagager","longDescription":"Prosjektet vedlikeholder og videreutvikler eksisterende lagerstyringssystem, implementerer kontinuerlige forbedringer og håndterer supporthendelser fra eksisterende kunder for å sikre stabilitet og optimal drift.","period":{"from":[2024,10],"to":[2025,3]},"roles":[{"name":"DBA og Utvikler","description":"Forbedre ytelse og kvalitet i databaser gjennom grundig analyse av eksisterende struktur, spørringer og indekser – med mål om optimal responstid og skalerbarhet. Utarbeide tydelig dokumentasjon for vedlikehold og beste praksis, og bidrar aktivt i supporthåndtering for å identifisere feil, avdekke flaskehalser og realisere forbedringspotensial."}],"skillsUsed":[{"name":"SQL Server","durationInYears":0},{"name":".NET Core","durationInYears":0},{"name":"NHibernate","durationInYears":0},{"name":"Archbee","durationInYears":0},{"name":"Podman","durationInYears":0}]},{"customer":"Element Logic","description":"ESS","longDescription":"Prosjektet leverer en fullstendig nyutviklet versjon av det eksisterende lagerstyringssystemet, bygget på en moderne plattform med de nyeste teknologiene og metodene for å sikre optimal ytelse, skalerbarhet og brukervennlighet.","period":{"from":[2025,4],"to":null},"roles":[{"name":"DevEx Utvikler","description":"Skaper sømløs utvikleropplevelse på tvers av organisasjonen gjennom arbeid i DevEx-teamet, hvor jeg bygger og integrerer en felles plattform med applikasjoner og komponenter som effektiviserer samhandlingen mellom team i et DevOps-miljø. Har spesielt fokus på å utvikle robuste GitHub Reusable Workflows og optimalisere distribusjon med Octopus Deploy, for å levere en enhetlig og friksjonsfri CI/CD-opplevelse på tvers av teknologier som .NET, Java og Kotlin.\nIntegrerer løsninger med ledende verktøy som SonarCloud, Docker/Podman, Trivy, Testmo, JFrog Artifactory, AWS, PostgreSQL – og skaper helhetlige pipelines som kombinerer kvalitet, sikkerhet og hastighet."}],"skillsUsed":[{"name":"Sonar Cloud","durationInYears":0},{"name":"PostgreSQL","durationInYears":0},{"name":"Trivy","durationInYears":0},{"name":"Testmo","durationInYears":0},{"name":"Podman","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Java/Kotlin","durationInYears":0},{"name":"JFrog artifactory","durationInYears":0},{"name":"Octopus Deploy","durationInYears":0},{"name":"GitHub Workflows","durationInYears":0},{"name":"GitHub Actions","durationInYears":0},{"name":"Microsoft 365 Copilot","durationInYears":0},{"name":"AWS","durationInYears":0},{"name":"Docker Compose","durationInYears":0}]}],"educations":[{"degree":"","school":"Universitetet i Oslo (UiO)","period":{"from":[1993,1],"to":[1994,12]}},{"degree":"","school":"Høgskolen i Molde","period":{"from":[1996,1],"to":[1999,12]}}],"certifications":[{"name":"Microsoft Certified Solution Developer: Microsoft .NET","year":2003},{"name":"Microsoft Certified Application Developer: Microsoft .NET","year":2003},{"name":"Microsoft Certified Professional: Microsoft Certified Professional","year":2001}],"courses":[{"name":"Red Hat Linux Administration","organizer":"","year":2010},{"name":"Business Intelligence Boot camp (SSIS, SSAS, SSRS – SQL Server 2008 R2)","organizer":"","year":2011},{"name":"SQL Server PDW training","organizer":"","year":2013}],"languages":[{"name":"Norsk","level":"Morsmål"},{"name":"Engelsk","level":"Flytende"},{"name":"Spansk","level":"Elementært"},{"name":"Tysk","level":"Elementært"},{"name":"","level":""}],"skillCategories":[],"qualityScore":null}
{"id":"5c949e28c6989c24f41e7a87","keyQualifications":[],"workExperiences":[],"projectExperiences":[],"educations":[],"certifications":[],"courses":[],"languages":[],"skillCategories":[],"qualityScore":null}
{"id":"63dfaef4d3c4bb39ad35db85","keyQualifications":[{"label":"","description":"Peder har en bakgrunn med sivilingeniør-utdanning fra NTNU hvor han studerte kybernetikk og robotikk med valgfag innen kunstig intelligens og maskinsyn. Programmeringen på studiet ga mersmak og han valgte derfor å begynne som utvikler etter studiene. Her har han sittet i samfunnsviktige prosjekter for store aktører som Equinor og Bane NOR. I disse prosjektene har han bidratt til å styre og utvikle deres systemer mot moderne løsninger som kan levere stabile tjenester i lang tid.\n\nSom utvikler har Peder hovedsakelig jobbet fullstack, men med en ekstra forkjærlighet for backendutvikling. Som backendutvikler er hans foretrukne verktøy C# og ASP.net Core, som han har flere års erfaring med. Med disse verktøyene leverer han raske, stabile og sikre backendsystemer som oppfyller kundens behov. \n\nI sine år i arbeidslivet har Peder fått jobbe mye DevOps og trives godt med dette. Han mener at utviklerteam som også får styre sin egen infrastruktur kan jobbe raskere og levere smidigere. Derfor har han også opparbeidet seg en god kompetanse i DevOps-verktøy som github actions og gitlab pipelines, samt skyarkitektur og containerteknologi.\n\nNoen av Peders styrker som utvikler er at han jobber systematisk og nøye. Han er rask til å sette seg inn i komplekse systemer og problemstillinger og finner stor glede i å lære nye ting og dele denne kunnskapen videre til andre.\nHan er opptatt av å levere kode som er forståelig og lesbar også langt frem i tid. På denne måten sikrer han at det han leverer er vedlikeholdbart og vil gi kunden varig verdi."}],"workExperiences":[{"employer":"Ent3r Trondheim","period":{"from":[2016,8],"to":[2019,6]}},{"employer":"NTNU Trondheim","period":{"from":[2016,8],"to":[2018,12]}},{"employer":"Forsvarets Forskningsinstitutt","period":{"from":[2018,6],"to":[2018,8]}},{"employer":"Bouvet","period":{"from":[2019,8],"to":[2023,4]}},{"employer":"Cloudberries","period":{"from":[2023,5],"to":null}}],"projectExperiences":[{"customer":"Forsvarets forskningsinstitutt (FFI)","description":"Kamerabasert posisjonering av fly og helikopter (masteroppgave)","longDescription":"Sommeren 2018 tok Peder en jobb som forskningsassistent ved Forsvarets Forskningsinstitutt (FFI). Her ble han satt til å lage et system som estimerte posisjon av flyvende fartøy ved hjelp av kamera med kjent posisjon og orientering. Prosjektet ble videreført som prosjektoppgave høsten 2018 og masteroppgave våren 2019. Peder jobbet på oppgaven alene, men med veiledere fra både NTNU og FFI. Programvaren som styrte systemet ble utviklet i C++ og baserte seg på OpenCV-biblioteket. Dataene systemet produserte ble analysert med Python i ettertid.","period":{"from":[2018,6],"to":[2019,6]},"roles":[{"name":"Utvikler","description":"Peder hadde selv ansvaret for oppgaven og gjorde alt av utvikling og noe testing på egenhånd. Utstyr ble supplert av FFI. "}],"skillsUsed":[{"name":"C++","durationInYears":0},{"name":"OpenCV","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"Pandas","durationInYears":0},{"name":"Matplotlib","durationInYears":0},{"name":"LaTeX","durationInYears":0}]},{"customer":"Equinor","description":"Gas Operations","longDescription":"Utvikling, drift og vedlikehold av systemer for planlegging og gjennomføring av gasstransport i Europa og USA.\n\nDispatch er et 24/7 forretningskritisk system bestående av klient, servicer og databaser. Løsningen er publisert i Microsoft Azure og distribuert til sluttbrukerne via Azure Virtual Desktop. Teamet arbeider etter Kanban-metodikk og har utstrakt bruk av nUnit enhetstester, SpecFlow akseptansetester og godt etablerte rutiner for å sikre best practice. Rutinene omfatter blant annet code-review, peer-review og automatiserte tester for å sikre en stabil og trygg leveranse. GitHub brukes for versjonshåndtering av koden.\n\nI tillegg til utvikling, drift og vedlikehold er teamet ansvarlig for å bemanne support i arbeidstiden og vakttelefon etter arbeidstid. Vaktordning går på rundgang i teamet, hvor en ansvarlig bærer telefon og er ansvarlig for å svare på supporthenvendelser utenfor normal kontortid.","period":{"from":[2019,9],"to":[2022,5]},"roles":[{"name":"Utvikler","description":"Oppdraget bestod av å vedlikeholde, fornye og videreutvikle det eksisterende systemet. Peders oppgaver var å samarbeide med kunden om å komme frem til løsninger som best mulig leverte etter deres behov, for så å utvikle og teste disse løsningene. \n Noen eksempler på spesifikke oppgaver som ble gjort er utvikling av nye skjermbilder, utvikling av nye servicer for å automatisere kommunikasjon mellom Dispatch og andre systemer, og flytting av hele Dispatch systemet fra on-prem til Azure."},{"name":"IT Business Analyst","description":"Peder fungerte som IT-BA i en prosess hvor Dispatch skulle ta inn en ny brukergruppe. De nye brukerne hadde mange ønsker og krav til hvordan Dispatch skulle fungere. Peders oppgave bestod i å sette seg inn i brukerenes funksjonelle krav og utarbeide en løsning for hvordan Dispatch best kunne oppfylle disse."},{"name":"DevOps","description":"Dispatch teamet jobbet under devops-metodikk med automatisert deploy av server- og klientkode til både on-prem servere og skyplattform. Som en del av teamet har Peder vært med på å utvikle og vedlikeholde github actions som automatiserer test og deploy av koden, samt jobbet med infrastructure-as-code opp mot Azure. "}],"skillsUsed":[{"name":".NET","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"GitHub","durationInYears":0},{"name":"Kanban","durationInYears":0},{"name":"Visual Studio","durationInYears":0},{"name":"Oracle","durationInYears":0},{"name":"PL/SQL","durationInYears":0},{"name":"WPF","durationInYears":0},{"name":"NUnit","durationInYears":0},{"name":"Serilog","durationInYears":0},{"name":"Azure","durationInYears":0},{"name":"Github Actions","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"ASP.NET Core","durationInYears":0},{"name":"Kodebasert infrastruktur (IaC)","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Jenkins CI/CD","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":".NET Core","durationInYears":0}]},{"customer":"Bane NOR","description":"FIDO","longDescription":"FIDO er et samfunnskritisk arbeidsverktøy som alle togførere i Norge må benytte, i tillegg til mange andre hos Bane NOR og i jernbaneforetakene som jobber med togfremføring. Trafikkinformasjon formidles elektronisk fra Bane NOR til flere tusen sluttbrukere, og erstattet i 2014 et papirbasert system.\n \nLøsningen består av to deler:\n \n1) En webbasert registreringsportal hvor togledere og ruteplanleggere kan registrere kritiske hendelser.\n \n2) En webbasert distribusjonsportal med høye oppetidskrav, hvor førere får opp ruten for toget sitt, samt oppdatert informasjon fra registreringsportalen. Informasjonen oppdateres i sanntid på førerens skjerm i toget. i Distribusjonsportalen må mottakere kvittere på mottatt informasjon, og det er funksjonalitet varsling og oppfølging av manglende kvitteringer, selv om fører er offline i lengre perioder.\n \nFIDO har integrasjon mot flere andre systemer: Ruter, planlagt arbeid og endringer i infrastruktur importeres kontinuerlig fra et fagsystem. I tillegg gjøres oppdaterte ruter og hendelser tilgjengelig for flere tredjepartsapplikasjoner.\n \nFIDO ble lansert for Ofotbanen Januar 2013, og ble året etter tatt i bruk i hele Norge  Etter dette har den blitt utvidet med nye verktøy, samt gjort mange forbedringer. Løsningen er utviklet i .NET/C# med SQL server og RavenDb som databaser. Prosjektet kjøres etter smidig metodikk.","period":{"from":[2022,5],"to":[2023,5]},"roles":[{"name":"Utvikler","description":"Peders oppgave som utvikler bestod i å vedlikeholde systemet og utvide dets funksjonalitet. Samtidig hadde teamet en oppgave med å modernisere systemet. Dette gikk ut på å bytte ut systemets frontend med en moderne reactløsning, samt flytte backenden fra .Net framework over til .Net core"},{"name":"Vakt","description":"Da FIDO er et driftskritisk system og nødvending for all togtrafikk i Norge hadde teamet en rullerende vaktordning for å sikre nødvending drift for Bane NOR. Ansvaret inkluderte å overvåke systemet i arbeidstiden og svare på henvendelser fra \n om eventuelle feil. Vakta måtte også betjene vakttelefonen hvor kritiske feil og mangler kunne meldes inn, samt hadde ansvar for å utbedre slike feil om nødvendig."},{"name":"DevOps","description":"Fido driftes på on-prem windows servere som konfigureres av teamet ved hjelp av desired state configuration. Det kjøres også automatisert testing og deploy ved hjelp av gitlab pipelines som Peder har vært med på å vidreutvikle. I løpet av tiden på prosjektet har Peder jobbet med å forbedre automatisert oppsett og nedriving av databaser for testing."}],"skillsUsed":[{"name":"Knockout","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"ASP.NET Core","durationInYears":0},{"name":"ASP.NET Web API","durationInYears":0},{"name":"React","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"GitLab","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"JIRA","durationInYears":0},{"name":"SQL Server","durationInYears":0},{"name":"RavenDB","durationInYears":0},{"name":"NoSQL","durationInYears":0},{"name":"Entity Framework Core","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"ASP.NET MVC","durationInYears":0},{"name":"HTML","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"CSS","durationInYears":0},{"name":".NET","durationInYears":0},{"name":".NET Core","durationInYears":0}]},{"customer":"Norwegian Air Shuttle","description":"Norwegian Reward","longDescription":"Norwegian Reward er Norwegians prisbelønnede kundelojalitetsprogram. Programmet gir fordeler og poeng til kunder som flyr med Norwegian, eller handler hos en av deres mange partnere. Poengene og fordelene kan brukes på Norwegians flyreiser.\n\nAv tekniske komponenter består programmet av en nettside med CMS, samt flere servicer for å integrere med andre tjenester hos Norwegain, som appen Travel Assistant og Bookingportalen. Det selges også gavekort, med integrasjoner mot betalingsløsninger som NETS og Bank Norwegian. Comarch CLM brukes som backendsystem og NServiceBus brukes for å oppnå sikker tapsfri kommunikasjon mellom komponenter.","period":{"from":[2023,5],"to":null},"roles":[{"name":"Tech Lead","description":"Som tech lead for Norwegian Reward hadde Peder ansvar for alt det tekniske knyttet til Norwegians Fordelsprogram. Dette innebar å monitorere, drifte, vedlikeholde, og oppdatere eksisterende tjenester, samt spesifisere og utvikle nye komponenter. Han fungerte også som teknisk hovedkontakt for resten av teamet og hadde ansvar for tekniske avgjørelser i samarbeid med Norwegians arkitektur-team."},{"name":"DevOps","description":"I løpet av sin tid som Tech Lead på Reward gjorde Peder store endringer i CI/CD oppsettet på prosjektet. Han la om slik at kode ble grundig testet både automatisk og manuelt før den ble merget til hovedbranch og produksjonsatt. Dette løste mange problemer teamet hadde hatt med at ikkefungerende kode spredde seg til flere featurebrancher og kortet betydelig ned tiden fra utvikling til produksjonsetting. Han satte også opp CI/CD pipeline for nyutviklede servicer som ble deployet som docker-containere i AWS."},{"name":"Utvikler","description":"Som Tech Lead var det viktig for Peder å kjenne kodebasen han hadde ansvaret for svært godt. Derfor gjorde han også mye utvikling. Dette innebar videreutvikling og feilretting på nettsiden norwegianreward.com, en ASP.NET MVC nettside med en del React-komponenter, samt diverse dotnet servicer som støtter funksjonaliteten til nettsiden. Han utviklet også noen greenfield-tjenester som ble utviklet som dotnet 8 servicer, pakket og deployet som docker-containere i AWS."}],"skillsUsed":[{"name":"ASP.NET MVC","durationInYears":0},{"name":"Jetbrains Rider","durationInYears":0},{"name":"SQL Server","durationInYears":0},{"name":"NServiceBus","durationInYears":0},{"name":"NETS","durationInYears":0},{"name":"Bitbucket","durationInYears":0},{"name":"Team City","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Octopus Deploy","durationInYears":0},{"name":"React","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"AWS","durationInYears":0},{"name":"Comarch CLM","durationInYears":0},{"name":"JIRA","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Jenkins CI/CD","durationInYears":0},{"name":"HTML","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"CSS","durationInYears":0},{"name":"Kodebasert infrastruktur (IaC)","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"ASP.NET Core","durationInYears":0},{"name":".NET","durationInYears":0},{"name":".NET Core","durationInYears":0}]}],"educations":[{"degree":"Master - Kybernetikk og Robotikk","school":"NTNU Trondheim","period":{"from":[2014,1],"to":[2019,12]}}],"certifications":[{"name":"Sikkerhetsklarering - Hemmelig","year":2021}],"courses":[{"name":"Diverse Kurs i React","organizer":"PluralSight ","year":null}],"languages":[{"name":"Norsk","level":"Morsmål"},{"name":"Engelsk","level":"Flytende muntlig og skriftlig"}],"skillCategories":[{"name":"Rammeverk og standarder","skills":[{"name":".NET","durationInYears":6},{"name":"NUnit","durationInYears":3},{"name":".NET Core","durationInYears":6},{"name":"ASP.NET Core","durationInYears":6},{"name":"ASP.NET Core MVC","durationInYears":0},{"name":"ASP.NET Web API","durationInYears":1},{"name":"ASP.NET MVC","durationInYears":3}]},{"name":"Programmeringsspråk","skills":[{"name":"C#","durationInYears":6},{"name":"PL/SQL","durationInYears":3},{"name":"Python","durationInYears":1},{"name":"C++","durationInYears":1},{"name":"JavaScript","durationInYears":3}]},{"name":"Database og databaseverktøy","skills":[{"name":"Oracle","durationInYears":3},{"name":"SQL","durationInYears":6},{"name":"SQL Server","durationInYears":3},{"name":"RavenDB","durationInYears":1},{"name":"Entity Framework Core","durationInYears":1},{"name":"NoSQL","durationInYears":1}]},{"name":"Front-end","skills":[{"name":"WPF","durationInYears":3},{"name":"CSS","durationInYears":3},{"name":"React","durationInYears":3},{"name":"HTML","durationInYears":3},{"name":"Knockout","durationInYears":1}]},{"name":"DevOps og infrastruktur","skills":[{"name":"CI/CD","durationInYears":6},{"name":"Team City","durationInYears":2},{"name":"Octopus Deploy","durationInYears":2},{"name":"Kodebasert infrastruktur (IaC)","durationInYears":5},{"name":"Jenkins CI/CD","durationInYears":5},{"name":"Docker","durationInYears":5}]},{"name":"Skyteknologi","skills":[{"name":"Azure","durationInYears":3},{"name":"AWS","durationInYears":2}]},{"name":"Kildekontroll","skills":[{"name":"Git","durationInYears":6},{"name":"GitHub","durationInYears":3},{"name":"GitLab","durationInYears":1},{"name":"Bitbucket","durationInYears":2}]}],"qualityScore":null}
{"id":"670e623bbb557e07926ef7d3","keyQualifications":[],"workExperiences":[],"projectExperiences":[],"educations":[],"certifications":[],"courses":[],"languages":[],"skillCategories":[],"qualityScore":null}
{"id":"5e8a32c563046210c28435d3","keyQualifications":[{"label":"Om","description":"Petter er en erfaren utvikler med mer enn 13-års erfaring, og har jobbet spesielt mye med .NET , Azure og søkeløsninger. \nPetter har i sitt siste oppdrag jobbet med Datavarehus basert på skyteknologi (Azure) for EcoOnline fra 2020 til 2024. Dette prosjektet har bestått av å sammenfatte data fra flere kilder fra forskjellige deler av bedriften i datavarehuset, for så å tilby både data direkte og ferdige rapporter derifra. Siste halvdel av 2022 og videre i 2023 har fokuset vært tilbake på applikasjonsutvikling og skreddersøm med .NET som Arkitekt, TechLead og utvikler. Hovedteknologier i bruk på dette var Azure Data factory, Azure Functions og Service Bus.\n\nPetter har jobbet som TechLead, utvikler og arkitekt på tjenester for barne-, ungdoms- og familiedirektoratet (bufdir). Arbeidet har vært variert, med fokus på å oppgradere plattformen til en nyere og mer robust versjon, samt videreutvikle funksjonalitet for direktoratet og etaten. Det har også blitt utviklet et større prosjekt for avtale om felles barn mellom foreldre som går fra hverandre.\n\nFør dette jobbet Petter i seks år tett med Norges Fotballforbund og flere av deres løsninger som utvikler og rådgiver. Arbeidsoppgavene var mange, fra utvikling av skreddersøm .NET løsinger, episerver, integrasjoner, utvikling av søk med elasticsearch for å nevne noe. Han jobbet der i DevOps team, hvor man har ansvar for vedlikehold av kodebasen, nyutvikling og agere på hendelser som gjelder løsningen under daglig drift.\n\nEt annet større prosjekt som ble fullført hos NFF var å flytte alt av infrastruktur over til Azure. Fornye løsningene, og ta i bruk flere muligheter Azure og skyløsninger tilbyr.\n\nTidligere har han fokusert på håndtering av digitale skjemaer for flere kunder, for eksempel Stortinget. Der mye av oppgaven var å digitalisere en del fysiske papirskjema.\n\nPetter interesseres av ny teknologi, og liker å utforske hvordan dette kan skape reel nytteverdi i de kundeprosjektene han har arbeidet. Derfor er han opptatt av å tilegne seg så mye kunnskap om det nye som kommer på teknologifronten, og hvordan dette kan supplere dagens måte å løse utfordringer på. Han har flere ganger deltatt på Microsoft Build konferansen i Seattle, for å holde seg oppdatert med Azure, .NET, og det nyeste av tanker og tjenester fra Microsoft."}],"workExperiences":[{"employer":"Freelance webdevelopment","period":{"from":[2009,8],"to":[2011,8]}},{"employer":"Making Waves  AS","period":{"from":[2011,8],"to":[2016,8]}},{"employer":"Making Waves AS","period":{"from":[2016,8],"to":[2020,3]}},{"employer":"Cloudberries","period":{"from":[2020,4],"to":null}}],"projectExperiences":[{"customer":"Elkem","description":"Intranett","longDescription":"Utvikler på et nytt, sosialt intranett med EPiServer og Relate. Intranettet bygges opp av innhold som arbeidstakerene selv kommer med, og legges til en nyhetsstrøm som kan avgrenses fra globalt, helt ned til personlig nivå. Noe innhold vil også komme fra redaktører, i form av pressemeldinger o.l. Det ble laget spesielle tjenestesider, som inneholder alt fra IT-support til ansattgoder. Intranettet er i bruk i flere land, Kina, Canada, Brasil, for å nevne noen.","period":{"from":[2011,10],"to":[2012,4]},"roles":[{"name":"Utvikler","description":"Utviklet frontend (HTML/CSS), og var utvikler i et team på backend, som bestod av .NET teknologi"}],"skillsUsed":[{"name":"ASP.NET","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"Episerver Relate","durationInYears":0},{"name":"Episerver CMS","durationInYears":0},{"name":"Visual Studio","durationInYears":0},{"name":"SVN","durationInYears":0},{"name":"HTML/CSS","durationInYears":0},{"name":".NET","durationInYears":0}]},{"customer":"Statens Helsetilsyn","description":"Intranett","longDescription":"Jobbet som utvikler på et nytt intranett for Statens Helsetilsyn. Denne løsningen var laget med EPiServer CMS 6 og EPiServer Relate. Relate-funksjonaliteten ble brukt til å berike brukerprofiler med informasjon om seg selv, og personens arbeidsoppgaver/arbeidsfelt. Relate ble også brukt til kalenderhendelser, møter og prosjektrom.","period":{"from":[2012,4],"to":[2012,9]},"roles":[{"name":"Utvikler","description":"Utvikler på backend siden, som en del av et team"}],"skillsUsed":[{"name":"ASP.NET","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"Episerver CMS","durationInYears":0},{"name":"Episerver Relate","durationInYears":0},{"name":"Google Mini","durationInYears":0},{"name":"Visual Studio","durationInYears":0},{"name":"SVN","durationInYears":0},{"name":"HTML/CSS","durationInYears":0},{"name":".NET","durationInYears":0}]},{"customer":"Stortinget","description":"Intranett","longDescription":"Intranettet er en ny og forbedret utgave av det dagens intranett var, med flere funksjoner. Det fungerer som en felles front mot alle partiportaler, komiteportaler, utredningsportaler og dokumentlagre som benyttes i Stortinget. I tillegg fungerer det som informasjonsbærer for all intern kommunikasjon for både ansatte og innvalgte representanter på Stortinget. Brukergruppene er Stortingsrepresentantene, partigruppene og Stortingets administrasjon. Løsningen bidrar til effektiv samhandling og informasjonsdeling. Det finnes støtte for ulike typer av prosjekter i løsningen, med mange elektroniske skjemaer som er integrert med flere av IT-systemene til Stortinget. Intranettet har et meget avansert virksomhetssøk som indekserer og søker i mange ulike kilder. Dette presenteres enhetlig i løsningen. Hoveddelen er bygget på Episerver CMS, MS SharePoint, skreddersøm og bruker IntelliSearch ESP til søk. En omfattende integrasjonsjobb er utført for å sy sammen Episerver og SharePoint til en helhetlig og sømløs opplevelse for sluttbruker.","period":{"from":[2012,8],"to":[2013,10]},"roles":[{"name":"Utvikler","description":"Petter jobbet som utvikler på prosjektet, med et særlig fokus på digitale og automatiserte prosesser for skjemahåndtering."}],"skillsUsed":[{"name":".NET","durationInYears":0},{"name":"ASP.NET","durationInYears":0},{"name":"EpiServer","durationInYears":0},{"name":"C#","durationInYears":0}]},{"customer":"Norges Fotballforbund","description":"fotball.no - Norges Fotballforbunds kommunikasjonsportal","longDescription":"Fotball.no er teknisk bygget etter smidige prinsipper på Episerver CMS, ImageVault og sterkt støttet av søkeløsningen Elasticsearch, og er tett integrert med FIKS (Fotballens Informasjons- og Kommunikasjons-System) som er NFFs administrative kjernesystem som håndterer og administrerer all fotballaktivitet. Fotball.no viser historiske data og til enhver tid oppdaterte fotballdata fra FIKS , relevant og praktisk innhold og relevante nyheter. Systemet er designet fra bunnen av for å håndtere høy trafikk, og er svært skalerbart. Den høye trafikken og komplekse sammensetning av brukere krever også at designet tar høyde for mange ulike bruksscenarier, skjermvarianter, visningspreferanser og mye annet, som ble tungt vektlagt ved redesign av nettstedet lansert i 2016.","period":{"from":[2013,10],"to":[2019,4]},"roles":[{"name":"Utvikler","description":"Petter var utvikler på fotball.no og jobbet med brukergrensesnitt, forretningslogikk, dataaksess og integrasjonsprosesser. Det er jobbet mye med å optimalisere sidene, for å få de så lette og raske som mulig."},{"name":"Rådgiver","description":"Etter lang erfaring i prosjektet, og god oversikt, ble Petter brukt som rådgiver på teknologi og valg av retning videre for prosjektet. I slutten av perioden ble også en større jobbe med å flytte over teknologi til skytjenester gjort."}],"skillsUsed":[{"name":"ASP.NET","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"SQL Azure","durationInYears":0},{"name":"Episerver CMS","durationInYears":0},{"name":"Episerver Relate","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"jQuery","durationInYears":0},{"name":"HTML/CSS","durationInYears":0},{"name":"SASS","durationInYears":0},{"name":"Elasticsearch","durationInYears":0},{"name":"Elasticsearch.net","durationInYears":0},{"name":"Kibana","durationInYears":0},{"name":"Visual Studio","durationInYears":0},{"name":"Octopus Deploy","durationInYears":0},{"name":"TeamCity","durationInYears":0},{"name":"Azure","durationInYears":0},{"name":".NET","durationInYears":0},{"name":"MVC","durationInYears":0},{"name":"WCF","durationInYears":0},{"name":"ASP.NET WebApi","durationInYears":0},{"name":"SignalR","durationInYears":0}]},{"customer":"Norges Fotballforbund","description":"FIKS - Fotballens Informasjon og kommunikasjons system","longDescription":"Systemet tilbyr datatjenester til krets, dommere og klubb og har samlet over 15.000 brukere. FIKS er også datakilden for resultat-, kamp- og spillerinfo som vises på fotball.no (rundt 80 millioner sidevisninger i 2018) og i fotballappen MinFotball. Dataene blir også brukt av tredjeparter som Dynamic, NTB, S2S og Mediatec via et API basert på WCF. Løsningen er også integrert med Norges Idrettsforbunds SportsAdmin. Denne løsningen stiller svært store krav til hastighet, stabilitet og brukervennlighet.\n\nFIKS ble innført i 2008 og har siden den gang blitt videreutviklet til å være «up to date» teknologisk og til å kontinuerlig møte brukernes nye behov og trender. Systemet baserer seg på .NET som utviklingsrammeverk, sterkt støttet av søkeløsningen Elasticsearch.","period":{"from":[2013,10],"to":[2019,4]},"roles":[{"name":"Utvikler","description":"En del av oppgavene som utvikler på FIKS var å utvikle nye verktøy for \"fotballnorge\", og alle brukere som har arbeidsoppgaver innenfor fotballhverdagen. Det har også pågått et lengre arbeid med å omskrive eldre deler av FIKS til ny teknologi basert på .NET og MVC. En stor oppgradering var å utvikle og ta i bruk Elasticsearch og pattern for CQRS. Volum og behov dikterte endringer i hvordan man skulle lese og skrive data på en mer effektiv måte i en applikasjon der endringer er store, ofte, i transaksjon og behovet for les av data øker kraftig, også fra andre applikasjoner som bruker databasen."},{"name":"Rådgiver","description":"Etter lang erfaring i prosjektet, og god oversikt, ble Petter brukt til rådgiver på teknologi og valg av retning videre for prosjektet. I slutten av perioden ble også en større jobbe med å flytte over teknologi til skytjenester gjennomført."}],"skillsUsed":[{"name":"ASP.NET","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"SQL Azure","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"jQuery","durationInYears":0},{"name":"HTML/CSS","durationInYears":0},{"name":"ElasticSearch","durationInYears":0},{"name":"Elasticsearch.net","durationInYears":0},{"name":"Kibana","durationInYears":0},{"name":"Visual Studio","durationInYears":0},{"name":"Octopus Deploy","durationInYears":0},{"name":"Team City","durationInYears":0},{"name":"Azure","durationInYears":0},{"name":".NET","durationInYears":0},{"name":"MVC","durationInYears":0},{"name":"WCF","durationInYears":0},{"name":"ASP.NET WebApi","durationInYears":0},{"name":"Entity Framework","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"SignalR","durationInYears":0},{"name":"CQRS","durationInYears":0},{"name":"Microsoft SQL Managment Studio","durationInYears":0}]},{"customer":"Barne-, ungdoms- og familiedirektoratet","description":"Bufdir.no","longDescription":"Som utvikler og tech lead i prosjektet for bufdir, består arbeidet i å jobbe med deres digitale tjenester på nettstedet. Arbeidet hos kunden består bl.a. tjenestedesign, innholdsrådgivning og -produksjon, søkemotoroptimalisering, sosiale medier, statistikk og analyse, grafisk design, interaksjonsdesign, front end- og back end utvikling. Prosjektet arbeider også med utvikling av konsepter og veiledere for flere av Bufdirs kjernetjenester.","period":{"from":[2019,4],"to":[2020,5]},"roles":[{"name":"Tech lead","description":"Tech lead for bufdir.no, der han jobber med den langsiktig forvaltingen og videreutvikling av løsningene."},{"name":"Utvikler","description":""}],"skillsUsed":[{"name":".NET","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"ASP.NET WebApi","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"Entity Framework","durationInYears":0},{"name":"Episerver CMS","durationInYears":0},{"name":"jQuery","durationInYears":0},{"name":"React","durationInYears":0},{"name":"Visual Studio","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"Azure","durationInYears":0},{"name":"MVC","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Git flow","durationInYears":0},{"name":"Azure DevOps","durationInYears":0}]},{"customer":"Barne-, ungdoms- og familiedirektoratet","description":"Digitalt støttet mekling (DSM)","longDescription":"Digitalt støttet mekling, eller DSM er et prosjekt for å forenkle og digitalisere meklingsprosessen som gjøres når to personer med felles barn går fra hverandre. Prosjektet har stort fokus på å lage smidige løsninger der personer kan jobbe sammen seg i mellom, og i meklingstimer på familievernskontorer, for å komme sammen til en avtale for felles barn.\n\nLøsningen utvikles som en selvstendig tjeneste, men som integreres og leves i samme univers som bufdir.no. Det har vært stort fokus på sikkerhet i utviklingen av løsningen.","period":{"from":[2019,4],"to":[2020,5]},"roles":[{"name":"Tech lead","description":"Jobbet som tech lead og arkitekt på løsningen som skal lages som en selvstendig applikasjon, men som en del av bufdir.no sine tjenester."},{"name":"Utvikler","description":""}],"skillsUsed":[{"name":".Net Core","durationInYears":0},{"name":"React","durationInYears":0},{"name":"Azure","durationInYears":0},{"name":"Azure API Management","durationInYears":0},{"name":"ASP.NET WebApi","durationInYears":0},{"name":"Azure Functions","durationInYears":0},{"name":"Entity Framework","durationInYears":0},{"name":"Episerver CMS","durationInYears":0},{"name":"ASP.NET","durationInYears":0},{"name":"Visual Studio","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Git flow","durationInYears":0},{"name":"Azure DevOps","durationInYears":0},{"name":"C#","durationInYears":0}]},{"customer":"EcoOnline","description":"Datavarehus etablering","longDescription":"Prosjektet har innebefattet utforming av prosesser for utvikling for intern IT samt strukturere utvikling på tvers av team. Med oppsett av platform for prosjektarbeid, dokumentasjon og kode (Azure DevOps). \n\nVidere har det blitt opprettet et datavarehus, infrastruktur, prosesser og overvåkning. Dette for å samle inn data fra forskjellige systemer, levere data til rapporter, ferdige rapporter og utregne KPI'er.","period":{"from":[2020,5],"to":[2022,7]},"roles":[{"name":"Utvikler","description":"Petter jobbet mye med ETL utvikling og løsninger for hvordan data-inn delen av datavarehuset ble utviklet. Teamet bruker flere teknologier for denne delen, men hovedkomponenten i oppsettet er Azure data factory (ADF)."},{"name":"Rådgiver / Koordinator","description":""}],"skillsUsed":[{"name":"Datavarehus","durationInYears":0},{"name":".Net Core","durationInYears":0},{"name":"Azure Devops","durationInYears":0},{"name":"Microsoft SQL Managment Studio","durationInYears":0},{"name":"Azure Data Factory","durationInYears":0},{"name":"Azure SQL","durationInYears":0},{"name":"Azure Functions","durationInYears":0},{"name":".NET","durationInYears":0},{"name":"Azure Event Grid","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"SQL","durationInYears":0}]},{"customer":"EcoOnline","description":"Integrasjon","longDescription":"Integrasjonsprosjektet består av flere komponenter og applikasjoner basert på Azure skyteknologi som til sammen skaper en plattform for integrasjoner på tvers av kjernesystemer for EcoOnline. Denne plattformen er en meldingsbasert tjeneste der kjernesystemer kan kobles opp til å lytte på endringer, samt sende ut egne endringer. På denne måten holder man flere interessenter av endringene oppdatert med i et Pub/Sub pattern. \n\nPlattformen er basert på Azure integration services og forskjellige komponenter Azure tilbyr. Connectorer til systemer er bygget opp av APIer, Webhooks eller Logic apps, Azure functions for prosessering og berikelse samt Azure service bus for både køsystem og pub/sub på endringer. Arkitekturen tar utgangspunkt i å lage flere mindre tjenester med et lite ansvarsområde som i større grad er uavhengige av de andre. Fordelen er å raskere kunne endre eller oppdatere enkelte deler, uten å forstyrre andre parter, videreutvikle eller avvikle funksjonalitet uten større endringer i flere applikasjoner.","period":{"from":[2022,6],"to":[2024,5]},"roles":[{"name":"Tech lead og utvikler","description":"Petter tok over prosjektet som tech lead i juni 2022 og har brukt tid på å forbedre, videreutvikle og sette sammen et team bestående av flere personer for å jobbe med plattformen. Nye rutiner \nfor kodekvalitet og utviklingsløp er introdusert i sammarbeid med de andre på teamet. Teamet har fokusert på opprettelse av all infrastruktur som kode via ARM/Bicep templates, forbedring av pub/sub pattern og bedre monitorering, logging og feilhåndtering.\n\nDet finnes også andre integrasjoner og prosjekter Petter er inkludert i.   Implementasjon av nytt ERP system, oppfølging av eksterne tilbydere av funksjonalitet, samt mindre interne integrasjoner for IT-supportsystem og Azure DevOps. Petter har også personalansvar for en del av teamet, med personalsamtaler, kompetanseplaner og oppfølging av to studenter."},{"name":"Rådgiver / Løsningsarkitekt","description":"Et større løft for integrasjoner er i gang, hvor Petter leder arbeidet med en iPaaS evaluering og anskaffelse. Her vil nåværende plattform evalueres opp mot tilbydere som Dell Boomi, Mulesoft, Merkato m.fl. Etter evaluering starter et større integrasjonsprosjekt for ny CRM løsning, ERP integrasjon, kobling til markedsføringssystem samt integrasjon av ansatt data og bedriftshierarkier. \n\nPetter har også vært rådgiver på deler av andre prosjekt, som f.eks. løft på arbeidsmetodikk for alle teamene i IT avdelingen, Capability mapping for bedriften m.fl."}],"skillsUsed":[{"name":"Azure Functions","durationInYears":0},{"name":".Net 6","durationInYears":0},{"name":"ServiceBus","durationInYears":0},{"name":"Azure Storage","durationInYears":0},{"name":"Azure","durationInYears":0},{"name":"Azure Devops","durationInYears":0},{"name":"Azure DevOps Pipeline","durationInYears":0},{"name":"Azure Service Bus","durationInYears":0},{"name":"Pub/Sub","durationInYears":0},{"name":"iPaaS","durationInYears":0},{"name":"Team Lead","durationInYears":0},{"name":"Personalledelse","durationInYears":0},{"name":"Prosjektledelse","durationInYears":0},{"name":".NET","durationInYears":0},{"name":"Azure API Management","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"Entity Framework","durationInYears":0}]},{"customer":"EcoOnline","description":"Integrasjon","longDescription":"Et større løft for integrasjoner er i gang, hvor Petter har ansvaret for en IPaaS platform ved navn Workato. Prosjektet inneholder i første omgang til å integrere forskjellige deler av verdiskjeden til EcoOnline via integrasjonsplattformen. Dette starter med Marketing (Hubspot), Salesforce (CRM) og Dynamics Finance & Operation (ERP). Det er også tilknyttet systemer videre fra Dynamics, som Pagero for faktureringsbehandling.\n\nVidere vil prosjektet se på andre deler av bedriften som vil trenge automasjon og integrasjon, som HR systemer, on/off -boarding m.m","period":{"from":[2024,9],"to":null},"roles":[{"name":"Rådgiver / Arkitekt / Utvikler","description":"I denne rollen har Petter ansvaret for driften av IPaaS platformen (Workato), samtidig som han står for videreutvikling av nye prosjekter og ledelse av innsats tilknyttet denne platformen av andre. Han er leid inn i Arkitekt-teamet til EcoOnline og vil naturlig bli brukt til andre oppgaver innenfor teamet sine arbeidsfelt."}],"skillsUsed":[{"name":"iPaaS","durationInYears":0},{"name":"Workato","durationInYears":0},{"name":"Arkitektur","durationInYears":0}]}],"educations":[{"degree":"Bachelor, Multimedia Technologi og -Design","school":"Universitetet i Agder","period":{"from":[2008,1],"to":[2010,12]}},{"degree":"Bachelor, Multimedia Technologi og -Design","school":" University of New South Wales, Sydney, Australia","period":{"from":[2010,1],"to":[2010,12]}},{"degree":"Bachelor, Multimedia Technologi og -Design","school":"Universitetet i Agder","period":{"from":[2011,1],"to":[2011,12]}}],"certifications":[{"name":"MCTS: Web App Development .NET Framework 4","year":2011},{"name":"Episerver Certified Developer","year":2011},{"name":"Episerver Certified Developer","year":2013},{"name":"Episerver Certified Developer","year":2015},{"name":"Episerver Certified Developer","year":2018},{"name":"","year":null}],"courses":[{"name":"Creating ASP.NET applications","organizer":"","year":2011},{"name":"70-515 Web Application Development with .Net 4","organizer":"Programutvikling","year":2011},{"name":"EPiServer CMS 6 Course for Developers","organizer":"Episerver","year":2011}],"languages":[{"name":"Norsk","level":"Morsmål"},{"name":"Engelsk ","level":"Flytende skriftlig og muntlig"}],"skillCategories":[],"qualityScore":null}
{"id":"6228b778c1de2810d3eead13","keyQualifications":[{"label":"Politiet","description":"Philip er en erfaren utvikler og tech lead med over 7 års erfaring fra sky- og on-prembaserte løsninger i offentlig og privat sektor. Han har bred erfaring fra tverrfaglige utviklingsløp der han har hatt ansvar for både utvikling, arkitektur og drift, og har inngående kunnskap om mikrotjenester, API-er og integrasjonsarbeid.\n\nHan har spisskompetanse på Kotlin og Java, samt AWS, Kubernetes, Docker og Terraform. Philip har bred kompetanse innen forskjellige aspekter av systemutvikling, og har erfaring fra en rekke ulike teknologier. Han har sin hovedtyngde på utviklingssiden innenfor backendutvikling med Java, men han har erfaring med hele stacken fra databaseoppsett til frontendutvikling, fra mikrotjenester til store, komplekse systemer, og fra on-prem til skyen. Han liker seg i en smidig arbeidshverdag, og trives godt med automatisert oppsett med DevOps-pipelines, skytjenester og moderne kjøremiljøer som Kubernetes. Philip evner å se den store sammenhengen for å etablere og opprettholde en god arkitektur, og har i tillegg et øye for detaljene for å sikre kvaliteten også på kodenivå. I flere prosjekter har han jobbet med DevSecOps-prinsipper, IAM, autentisering (OAuth 2.0, JWT) og overvåkning med verktøy som Splunk, CloudWatch og X-Ray. \n\nPhilip har særlig interesse for løsninger som kombinerer teknologi og brukerbehov. Han er opptatt av å utvikle pålitelige og vedlikeholdbare systemer med høy grad av sporbarhet, og har betydelig erfaring med utvikling av løsninger i domener med høye krav til tilgjengelighet, tilgangsstyring og personvern.\n\nHan er strukturert og kunnskapsrik, trives i tverrfaglige team og deler gjerne av sin erfaring. Han har hatt roller som tech lead, mentor og sparringspartner, og kommuniserer godt med både utviklere, ledelse og ikke-tekniske ressurser.\n\nPhilip tar ansvar gjennom hele utviklingsløpet – fra innsiktsarbeid og kravspesifikasjon til produksjonssetting og drift – og evner å kombinere helhetsforståelse med detaljfokus. Han tar initiativ og jobber kontinuerlig for å forbedre både leveranser og arbeidsprosesser."}],"workExperiences":[{"employer":"Ungdomsakademiet","period":{"from":null,"to":null}},{"employer":"Netcompany","period":{"from":[2019,1],"to":[2021,12]}},{"employer":"Cloudberries","period":{"from":[2022,4],"to":null}},{"employer":"Netcompany","period":{"from":[2022,1],"to":[2022,3]}},{"employer":"Netcompany","period":{"from":[2016,8],"to":[2018,12]}}],"projectExperiences":[{"customer":"Mesta","description":"Videreutvikling og forvaltning av Anprod","longDescription":"Philip jobbet med videreutvikling og forvaltning av Anprod, Mestas sentrale system for anbudskalkulasjon og prosjektoppfølging. Systemet brukes gjennom hele livssyklusen til Mestas prosjekter – fra kontraktsinngåelse til gjennomføring og avslutning – og støtter prosesser som kalkulasjon, fakturering, budsjettering og rapportering.\n\nAnprod er forretningskritisk og inneholder kompleks og domene­spesifikk logikk, som stiller høye krav til både teknisk kvalitet og forståelse for prosesser i bygg- og anleggssektoren. Systemets stabilitet var avgjørende, og arbeidet inkluderte feilretting, tett samarbeid med brukere og kontinuerlig forbedring av løsningen.","period":{"from":[2016,9],"to":[2017,9]},"roles":[{"name":"Systemutvikler fullstack","description":"Philip jobbet tett med systemadministrator, produkteier, driftsleverandør og øvrige interessenter. Han var involvert i hele livsløpet for utviklingsoppgaver – fra kravspesifisering og design, via utvikling og test, til produksjonssetting. I tillegg til utvikling av applikasjonen hadde han ansvar for oppgaver knyttet til oppsett og drift av kjøremiljø og databaseinfrastruktur, samt enkelte utviklingsoppgaver i relaterte systemer hos Mesta."}],"skillsUsed":[{"name":"PL/SQL","durationInYears":0},{"name":"EJB","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Bitbucket","durationInYears":0},{"name":"WildFly","durationInYears":0},{"name":"Oracle SQL","durationInYears":0},{"name":"Swing","durationInYears":0},{"name":"JDBC","durationInYears":0},{"name":"Java","durationInYears":0},{"name":"jOOQ","durationInYears":0},{"name":"Linux","durationInYears":0},{"name":"Funksjonell arkitektur","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"IntelliJ IDEA","durationInYears":0},{"name":"Kanban","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"Maven","durationInYears":0}]},{"customer":"PostNord","description":"Booking av sendinger","longDescription":"PostNord utviklet nye API-er for booking av sendinger og transporttidsberegning som raskt ble blant selskapets mest sentrale IT-systemer. Tjenestene ble brukt fra ulike frontend-løsninger og stilte høye krav til ytelse og pålitelighet.\n\nTransporttids-API-et tok utgangspunkt i en underliggende kalkulasjonsmotor og flyttet deler av beregningen og caching til skybasert infrastruktur. Etter produksjonssetting hadde teamet også ansvar for daglig drift og feilretting, samt støtte til virksomhetskritiske systemer.\n\nProsjektet ble gjennomført i tett samarbeid med PostNords IT- og forretningssider, og var en del av selskapets moderniseringsløp.\n","period":{"from":[2017,9],"to":[2018,7]},"roles":[{"name":"Systemutvikler backend","description":"Philip hadde hovedansvar for backendutvikling i Java og Spring Boot for mikrotjenester knyttet til booking, transporttidsberegning, betaling og lager. Han jobbet med behovskartlegging, løsningsdesign, test, produksjonssetting og feilretting, og samarbeidet tett med produkteiere og API-konsumenter."},{"name":"Tech lead","description":"Som tech lead bidro han i teknologivalg, skytjenesteoppsett, autentiseringsløsninger og kvalitetssikring av løsninger. Han fungerte også som mentor og teknisk støttespiller for andre utviklere i teamet."},{"name":"Scrum master","description":"I en periode hadde han også rollen som scrum master for utviklingsteamet. Han fasiliterte sentrale scrum-seremonier, inkludert sprintplanlegging, daglige standups, sprintdemos og retrospektiver. Han holdt oversikt over fremdriften, sikret god kommunikasjon mellom utviklingsteam og produkteiere, og bidro til kontinuerlig forbedring av teamets arbeidsprosesser."}],"skillsUsed":[{"name":"Swagger Code Generator","durationInYears":0},{"name":"GitHub","durationInYears":0},{"name":"Maven","durationInYears":0},{"name":"EJB","durationInYears":0},{"name":"Spring Boot","durationInYears":0},{"name":"Java","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Bitbucket","durationInYears":0},{"name":"IBM Informix SQL","durationInYears":0},{"name":"Amazon Web Services","durationInYears":0},{"name":"DynamoDB","durationInYears":0},{"name":"JBoss","durationInYears":0},{"name":"Jenkins","durationInYears":0},{"name":"OAuth 2.0","durationInYears":0},{"name":"Auth0","durationInYears":0},{"name":"AWS CodePipeline","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"Integrasjoner","durationInYears":0},{"name":"Funksjonell arkitektur","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"IntelliJ IDEA","durationInYears":0},{"name":"OpenAPI","durationInYears":0},{"name":"Kibana","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"Postman","durationInYears":0},{"name":"JWT","durationInYears":0}]},{"customer":"Calpro","description":"Reimplementasjon av webportal","longDescription":"Prosjektet gikk ut på reimplementering av en webportal for Calpro, en aktør innen digital oppfølging av pasienter med kroniske sykdommer. Portalen skulle benyttes av både pasienter, leger og annet helsepersonell, og kommuniserte med backend-tjenester som også støttet Calpros mobilapp.\n\nLøsningen håndterer konfidensiell pasientinformasjon og var underlagt strenge krav til informasjonssikkerhet og datakvalitet. Målet med prosjektet var å forbedre brukeropplevelse, sikkerhet og vedlikeholdbarhet, samtidig som funksjonalitet for integrasjon med eksterne systemer ble videreutviklet.","period":{"from":[2018,8],"to":[2018,8]},"roles":[{"name":"Tech lead","description":"Philip hadde et én måneds engasjement i dette prosjektet for å bidra til å løfte den tekniske kvaliteten til et høyere nivå. Han var tech lead for et internasjonalt team, og jobbet mye med standardisering og kvalitetssikring av kodebase. Han jobbet mest med den Java-baserte backendkomponenten, men var også noe involvert i utvikling av webapplikasjonen. Han jobbet også en del med planlegging og oppsett av autentiseringsløp basert på OAuth 2.0 og leverandøren Auth0."},{"name":"","description":""}],"skillsUsed":[{"name":"Git","durationInYears":0},{"name":"Bitbucket","durationInYears":0},{"name":"Auth0","durationInYears":0},{"name":"Java","durationInYears":0},{"name":"Spring Boot","durationInYears":0},{"name":"Maven","durationInYears":0},{"name":"JPA","durationInYears":0},{"name":"PostgreSQL","durationInYears":0},{"name":"Flyway","durationInYears":0},{"name":"Bitbucket CI","durationInYears":0},{"name":"React.js","durationInYears":0},{"name":"OAuth 2.0","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"IntelliJ IDEA","durationInYears":0},{"name":"OpenAPI","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"Postman","durationInYears":0},{"name":"JWT","durationInYears":0}]},{"customer":"Oslo kommune, Utviklings- og kompetanseetaten ","description":"Katalog","longDescription":"Katalog-teamet utviklet og forvaltet systemer for administrasjon av brukere, tilganger og personalinformasjon i Oslo kommune. Systemene bestod av et sett mikrotjenester som kommuniserte via JMS og kjørte både i Kubernetes og eldre on-prem miljøer.\n\nProsjektet inngikk i kommunens arbeid med å sikre effektiv, stabil og sporbar brukerhåndtering på tvers av virksomheter og etater. Teamet hadde ansvar for både nyutvikling, integrasjoner og operasjonell drift.","period":{"from":[2018,9],"to":[2019,3]},"roles":[{"name":"Systemutvikler backend","description":"Philip jobbet med utvikling og vedlikehold av Java-baserte komponenter, med fokus på databaseoppsett, tjenesteintegrasjon og meldingsutveksling via JMS. Han samarbeidet med funksjonelle og tekniske ressurser for å sikre stabilitet og god samhandling mellom systemene.\n\nHan deltok i et forprosjekt for etablering av ny kjøreplattform og vurderte tekniske muligheter med AWS Elastic Kubernetes Service (EKS). Han implementerte også en løsning for SAML-basert innlogging via KeyCloak, som bidro til forenklet innlogging fra lokale utviklingsmiljøer."}],"skillsUsed":[{"name":"Java","durationInYears":0},{"name":"Helm","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Maven","durationInYears":0},{"name":"JMS","durationInYears":0},{"name":"JDBC","durationInYears":0},{"name":"Kibana","durationInYears":0},{"name":"Amazon Web Services","durationInYears":0},{"name":"Spring Boot","durationInYears":0},{"name":"Kubernetes","durationInYears":0},{"name":"Jenkins","durationInYears":0},{"name":"Oracle SQL","durationInYears":0},{"name":"Grafana","durationInYears":0},{"name":"Nexus","durationInYears":0},{"name":"Linux","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"Integrasjoner","durationInYears":0},{"name":"IntelliJ IDEA","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"GitHub","durationInYears":0},{"name":"Kanban","durationInYears":0},{"name":"PL/SQL","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"SOAP","durationInYears":0}]},{"customer":"Oslo kommune, Utviklings- og kompetanseetaten ","description":"Arkiv og digitale forsendelser","longDescription":"Prosjektet hadde som mål å videreutvikle og forvalte integrasjoner mellom ulike fagsystemer og arkivsystemer i Oslo kommune, med særlig fokus på overgang til et felles arkivsystem for kommunens virksomheter. Arbeidet inngikk i kommunens sentrale IT-plattform (ITAS), og var kritisk for forsvarlig dokumenthåndtering og digital forvaltning på tvers av etater og bydeler.\nTeamet utviklet og driftet Java- og Scala-baserte løsninger for digital journalføring, dokumentflyt og meldingshåndtering, og hadde ansvar for både utvikling, feilretting og teknisk forvaltning. Prosjektet omfattet både nyutvikling og vedlikehold, og stilte høye krav til samhandling, stabilitet og sporbarhet","period":{"from":[2019,3],"to":[2019,8]},"roles":[{"name":"Systemutvikler backend","description":"Philip jobbet med forvaltning og videreutvikling av eksisterende integrasjoner i Java og Scala, og deltok i planlegging og utvikling av nye arkivintegrasjoner. Han samarbeidet tett med teammedlemmer, brukere og tekniske interessenter for å analysere funksjonelle behov, definere arkitektur og løse feil i produksjon.\n\nHan hadde ansvar for oppsett og forvaltning av infrastrukturen med Kubernetes og Jenkins, og bidro til automatisert deploy og versjonshåndtering via Nexus. Philip ledet også arbeid med migrering av komponenter til ny kjøremiljøplattform, inkludert spesifikasjon, estimering og koordinering av utviklingsarbeidet."}],"skillsUsed":[{"name":"Scala","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"GitHub","durationInYears":0},{"name":"Helm","durationInYears":0},{"name":"Jenkins","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Kibana","durationInYears":0},{"name":"Maven","durationInYears":0},{"name":"JDBC","durationInYears":0},{"name":"Kubernetes","durationInYears":0},{"name":"Spring Boot","durationInYears":0},{"name":"Java","durationInYears":0},{"name":"JMS","durationInYears":0},{"name":"Oracle SQL","durationInYears":0},{"name":"Grafana","durationInYears":0},{"name":"Nexus","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"Kanban","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"SOAP","durationInYears":0},{"name":"Postman","durationInYears":0},{"name":"IntelliJ IDEA","durationInYears":0},{"name":"TDD","durationInYears":0}]},{"customer":"ShesGotThis","description":"EqualityCheck","longDescription":"EqualityCheck er en webapplikasjon utviklet av startupen She’s Got This (Hun Spanderer), som jobber for å fremme likestilling i arbeidslivet. Applikasjonen lar ansatte anonymt vurdere bedrifter på faktorer knyttet til likestilling og diskriminering, og ble utviklet som en MVP gjennom et sommerprosjekt.\nSystemet består av en backend i Spring Boot og en frontend bygget med TypeScript og React, og ble distribuert i sky via AWS.","period":{"from":[2019,5],"to":[2019,7]},"roles":[{"name":"Arkitekt og tech lead","description":"Philip deltok i hele prosjektløpet – fra kravspesifisering og teknologivalg til overlevering av løsningen. Han hadde ansvar for tekniske beslutninger, oppsett av kjøremiljø, samt veiledning og kvalitetssikring av arbeidet til et studentteam.\n\nHan definerte teknologistack og satte opp strukturen for backend og frontend, som ble koblet sammen via REST API-er. Han etablerte fullstendige pipelines for bygg og deploy med GitLab CI/CD og AWS CodePipeline, og satte opp kjøring i AWS ECS. I tillegg arbeidet han med sikkerhetsløsninger med Auth0 og OAuth 2.0."}],"skillsUsed":[{"name":"NGINX","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Java","durationInYears":0},{"name":"GitLab","durationInYears":0},{"name":"Spring Boot","durationInYears":0},{"name":"React.js","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Maven","durationInYears":0},{"name":"npm","durationInYears":0},{"name":"TypeScript","durationInYears":0},{"name":"AWS CodePipeline","durationInYears":0},{"name":"Amazon Web Services","durationInYears":0},{"name":"Auth0","durationInYears":0},{"name":"PostgreSQL","durationInYears":0},{"name":"Funksjonell arkitektur","durationInYears":0},{"name":"OAuth 2.0","durationInYears":0},{"name":"Redux","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"AWS Elastic Container Service (ECS)","durationInYears":0},{"name":"Flyway","durationInYears":0},{"name":"JPA","durationInYears":0},{"name":"OpenAPI","durationInYears":0},{"name":"Swagger Code Generator","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"Scrum","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"AWS CloudFormation","durationInYears":0},{"name":"JWT","durationInYears":0}]},{"customer":"Møller Mobility Group","description":"Bruktbil","longDescription":"Philip var del av et team med ansvar for bruktbildomenet, og jobbet hovedsakelig med løsningen HvorErBilen, en webapplikasjon som brukes av bilforhandlere for administrasjon av klargjøring og logistikk knyttet til bruktbiler.\n\nLøsningen besto av en frontend i React/Redux og en Spring Boot-backend, samt flere Java-baserte mikrotjenester som kommuniserte med både interne og eksterne systemer via Apache Kafka. Systemene kjørte i Azure Kubernetes Service, og utviklingsarbeidet ble kombinert med forvaltning og drift.","period":{"from":[2019,9],"to":[2020,3]},"roles":[{"name":"Systemutvikler fullstack og tech lead","description":"Philip jobbet som del av et tverrfaglig team, sammen med andre utviklere og produkteiere. Han hadde ansvar for utvikling av REST-baserte mikrotjenester i Java og Spring Boot, samt frontend i en responsiv React/Redux-applikasjon. I tillegg arbeidet han med databasehåndtering ved hjelp av Flyway, og utviklet integrasjoner mellom interne og eksterne systemer ved bruk av Apache Kafka.\n\nHan tok ansvar for å forbedre kodekvalitet og etablere felles kodestandarder, og tok initiativ til teknisk opprydding og forbedring av overvåkning og infrastruktur i samarbeid med drift. Han veiledet teammedlemmer, kvalitetssikret kode på tvers av team og bidro i løsningsdesign og arkitekturspørsmål i hele utviklingsmiljøet.\n\nPhilip hadde også ansvar for DevOps-oppgaver, inkludert konfigurasjon av CI/CD-pipelines og kjøremiljøer, produksjonssettinger, feilretting og driftsovervåkning ved hjelp av Splunk. Han jobbet tett med både produkteiere og eksterne parter for å definere funksjonell arkitektur og sikre smidige utviklingsprosesser fra analyse til produksjonssetting."}],"skillsUsed":[{"name":"React.js","durationInYears":0},{"name":"Java","durationInYears":0},{"name":"Maven","durationInYears":0},{"name":"Kotlin","durationInYears":0},{"name":"JDBC","durationInYears":0},{"name":"Microsoft Azure","durationInYears":0},{"name":"GitLab","durationInYears":0},{"name":"Flyway","durationInYears":0},{"name":"PostgreSQL","durationInYears":0},{"name":"Kubernetes","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"GitLab CI","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Spring Boot","durationInYears":0},{"name":"Splunk","durationInYears":0},{"name":"npm","durationInYears":0},{"name":"Funksjonell arkitektur","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"Integrasjoner","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"IntelliJ IDEA","durationInYears":0},{"name":"Redux","durationInYears":0},{"name":"Oracle SQL","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"Hendelsesdrevet arkitektur","durationInYears":0},{"name":"OpenAPI","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"OKR","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"Postman","durationInYears":0},{"name":"Apache Kafka","durationInYears":0},{"name":"Azure Kubernetes Service (AKS)","durationInYears":0},{"name":"Kanban","durationInYears":0},{"name":"OAuth 2.0","durationInYears":0},{"name":"JWT","durationInYears":0},{"name":"Domain Driven Design (DDD)","durationInYears":0}]},{"customer":"Oslo kommune, Utviklings- og kompetanseetaten ","description":"Tjeneste- og ordrekatatlogen/Team ordre","longDescription":"Utviklings- og kompetanseetaten (UKE) er Oslo kommunes interne leverandør av IT-tjenester, og har ansvar for drift og utvikling av kommunens sentrale plattform ITAS. Plattformen håndterer kommunikasjon og integrasjon mellom etater, bydeler og ulike interne og eksterne systemer.\n\nTeam Ordre utviklet og forvaltet Tjeneste- og ordrekatalogen (TOOK), en fellestjeneste for bestilling og administrasjon av interne tjenester i Oslo kommune. Systemet støttet alt fra artikkeladministrasjon og tjenesteutforming til integrasjoner mot saksbehandlingssystemer.\n\nTOOK var tett integrert med systemer i kommunens ITAS-plattform og var i daglig bruk i produksjon. I tillegg forvaltet teamet flere sentrale Java-komponenter som inngikk i kommunens tekniske infrastruktur. Prosjektet er bygd på Java 11 med Spring Boot og Oracle SQL, og med Vue.js/Vuex i frontend.\nArbeidet omfattet nyutvikling, drift, overvåking og modernisering, og ble utført i et tverrfaglig team med ansvar for både frontend og backend samt teknisk plattform.","period":{"from":[2020,4],"to":[2020,9]},"roles":[{"name":"Systemutvikler","description":"Philip jobbet hovedsakelig med backendutvikling i Spring Boot og deltok i hele stacken – fra databaseendringer med Oracle SQL og Flyway, til implementering av integrasjoner og definering av API-er med OpenAPI.\n\nHan arbeidet med både interne og eksterne integrasjoner, kvalitetssikret kode og var aktiv i definering av teknisk arkitektur og estimering av oppgaver. Han var også involvert i testarbeid og vedlikehold av infrastrukturen i Kubernetes, med observabilitet via Grafana og Kibana.\n\nPhilip ledet i tillegg modernisering av flere eldre komponenter i porteføljen, som ble migrert fra on-prem Linux-miljøer. Han hadde ansvar for analyse, design, estimering og oppfølging av utvikling frem til produksjonssetting."}],"skillsUsed":[{"name":"JDBC","durationInYears":0},{"name":"JMS","durationInYears":0},{"name":"Jenkins","durationInYears":0},{"name":"Vue.js","durationInYears":0},{"name":"Oracle SQL","durationInYears":0},{"name":"Helm","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Spring Boot","durationInYears":0},{"name":"Kubernetes","durationInYears":0},{"name":"Flyway","durationInYears":0},{"name":"Maven","durationInYears":0},{"name":"Java","durationInYears":0},{"name":"Yarn","durationInYears":0},{"name":"GitHub","durationInYears":0},{"name":"Kibana","durationInYears":0},{"name":"Grafana","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"Funksjonell arkitektur","durationInYears":0},{"name":"Integrasjoner","durationInYears":0},{"name":"IntelliJ IDEA","durationInYears":0},{"name":"Vuex","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"Scrum","durationInYears":0},{"name":"ActiveMQ","durationInYears":0},{"name":"Hendelsesdrevet arkitektur","durationInYears":0},{"name":"OpenAPI","durationInYears":0},{"name":"Swagger Code Generator","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"SOAP","durationInYears":0},{"name":"Postman","durationInYears":0},{"name":"Synkron arkitektur","durationInYears":0},{"name":"OAuth 2.0","durationInYears":0},{"name":"JWT","durationInYears":0},{"name":"Kafka","durationInYears":0},{"name":"Testdrevet utvikling (TDD)","durationInYears":0}]},{"customer":"Direktoratet for medisinske produkter","description":"Bivirkningsregisteret","longDescription":"Bivirkningsregisteret er Legemiddelverkets system for mottak og behandling av bivirkningsmeldinger for legemidler og vaksiner fra helsepersonell, pasienter og pårørende. Systemet består av en mottaksinfrastruktur, et hyllevaresystem for behandling, og den egenutviklede applikasjonen VigiSec, som håndterer personidentifiserende data med strenge krav til tilgangsstyring og sporbarhet.\n\nProsjektet startet rett før utrullingen av covid-19-vaksinene og opplevde en drastisk økning i antall meldinger. Systemene ble videreutviklet for å møte de høye kravene til kapasitet, sikkerhet og presisjon i rapporteringen.","period":{"from":[2020,11],"to":[2021,5]},"roles":[{"name":"Arkitekt og tech lead","description":"Philip ledet et team med utviklere og jobbet tett med både tekniske og faglige ressurser hos kunden. Han hadde ansvar for spesifisering av funksjonalitet, teknisk detaljering og estimering av utviklingsoppgaver.\n\nHan jobbet også med forbedring av teknisk arkitektur både på komponent- og kodenivå, og hadde ansvar for teknisk infrastruktur og sikkerhetsarkitektur. I tillegg ledet han arbeidet med integrasjoner mot andre helseinstanser, som Folkehelseinstituttet og Norsk helsenett, og sørget for kvalitetssikring og teknisk veiledning i teamet."}],"skillsUsed":[{"name":"Azure DevOps","durationInYears":0},{"name":"EF Core","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"RabbitMQ","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"Internet Information Services","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Microsoft SQL Server","durationInYears":0},{"name":"Razor Pages","durationInYears":0},{"name":".NET Core","durationInYears":0},{"name":"Azure Pipelines","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"Funksjonell arkitektur","durationInYears":0},{"name":"Integrasjoner","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"Octopus Deploy","durationInYears":0},{"name":"Rider","durationInYears":0},{"name":"ROS-analyse","durationInYears":0},{"name":"PKI","durationInYears":0},{"name":"Hendelsesdrevet arkitektur","durationInYears":0},{"name":"Synkron arkitektur","durationInYears":0},{"name":"Flyway","durationInYears":0}]},{"customer":"Direktoratet for medisinske produkter","description":"DELE-prosjektet","longDescription":"DELE-prosjektet hadde som mål å etablere en ny, felles plattform for digital saksbehandling. Plattformen skulle gradvis erstatte direktoratets mange eldre fagsystemer og møte behovene i en mer digitalisert arbeidshverdag. Løsningen ble bygget på Microsoft Dynamics Customer Service og SharePoint, med integrasjoner gjennom Microsoft Azure og Sesam Master Data Hub.\n\nProsjektet ble gjennomført i tett samarbeid med domeneeksperter og produkteiere, og første leveranse fokuserte på prosesser knyttet til søknader, tillatelser og tilsyn med blant annet apotek.","period":{"from":[2021,5],"to":[2022,3]},"roles":[{"name":"Arkitekt","description":"Philip jobbet som arkitekt med hovedfokus på analyse og design av integrasjoner mot kommunikasjonsportalen Altinn og arkivsystemet Public 360. Altinn ble brukt til apotekrelaterte søknader og kommunikasjon (f.eks. ved etablering eller endringer i apotekdrift), mens Public 360 håndterte all inn- og utgående dokumentasjon og intern arkivering.\n\nHan hadde ansvar for designet av disse integrasjonene gjennom hele syklusen – fra analyse av eksisterende systemer og brukerbehov til funksjonelt og teknisk design av løsningene i samarbeid med arkitekter og domeneeksperter. Han planla utvikling, og jobbet tett med utviklere og brukere for å definere både overordnet arkitektur og spesifikk funksjonalitet i Dynamics-plattformen."}],"skillsUsed":[{"name":"C#","durationInYears":0},{"name":"Public 360","durationInYears":0},{"name":"SharePoint","durationInYears":0},{"name":"Altinn","durationInYears":0},{"name":"Microsoft Dynamics 365 Customer Service","durationInYears":0},{"name":"Microsoft Azure","durationInYears":0},{"name":"Azure DevOps","durationInYears":0},{"name":"Sesam Master Data Hub","durationInYears":0},{"name":"PKI","durationInYears":0},{"name":"Scrum","durationInYears":0},{"name":"STRIDE","durationInYears":0},{"name":"ROS-analyse","durationInYears":0},{"name":"Azure Pipelines","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"Funksjonell arkitektur","durationInYears":0},{"name":"Integrasjoner","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"Arkivintegrasjoner","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Hendelsesdrevet arkitektur","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"SOAP","durationInYears":0},{"name":"Smidig metodikk","durationInYears":0}]},{"customer":"Norsk Luftambulanse","description":"AirCapture","longDescription":"Prosjektet var et proof of concept (PoC) for en ny backendtjeneste og webapp med sikker autentisering via HelseID, til bruk fra mobile enheter. Tjenesten skulle støtte både lesing og skriving til database, og gi grunnlag for fremtidige helseløsninger. PoC-en inngikk i et initiativ for å utforske moderne plattformer, sikkerhet og skyløsninger tilpasset helsefeltet.","period":{"from":[2022,5],"to":[2022,8]},"roles":[{"name":"Systemutvikler og arkitekt","description":"Philip jobbet med analyse, løsningsdesign, utvikling og test av PoC-løsningen. Han utviklet og etablerte backendtjenesten i ASP.NET Core. og satte opp autentiseringsflyt med HelseID, basert på OpenID Connect og OAuth 2.0 i henhold til sikkerhetsprinsipper for utvikling i skymiljø.\nHan hadde også ansvar for databaseintegrasjon med Microsoft SQL Server via EF Core, samt oppsett av infrastruktur i Microsoft Azure. I tillegg deltok han i vurdering av teknisk arkitektur og gjennomførte dokumentasjon og test av løsningen."}],"skillsUsed":[{"name":"C#","durationInYears":0},{"name":"ASP.NET Core","durationInYears":0},{"name":"EF Core","durationInYears":0},{"name":"Microsoft SQL Server","durationInYears":0},{"name":"Microsoft Azure","durationInYears":0},{"name":"HelseID","durationInYears":0},{"name":"OpenID Connect","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"OpenAPI","durationInYears":0},{"name":"Azure DevOps","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"Vue.js","durationInYears":0},{"name":"JWT","durationInYears":0},{"name":"OAuth 2.0","durationInYears":0},{"name":"Integrasjoner","durationInYears":0}]},{"customer":"DNB","description":"Cloud - Global Services - Communication Services","longDescription":"Som en del av moderniseringen av DNBs digitale plattform ble det etablert en ny skybasert løsning i AWS for kommunikasjonstjenester. Plattformen tilbyr tjenester på tvers av banken, og brukes både i dialog med kunder og interne systemer. Teamet utviklet API-er for innboks, meldingsutsendelse, varslinger og oppgaver – med støtte for bruk i både mobilbank, nettbank og som systemtjenester i interne prosesser.","period":{"from":[2022,8],"to":[2024,2]},"roles":[{"name":"Systemutvikler, arkitekt","description":"Philip hadde ansvar for utvikling og videreutvikling av flere forretningskritiske mikrotjenester for kommunikasjon mellom banken, kundene og eksterne aktører. Han deltok gjennom hele utviklingsløpet – fra use case-analyse og kravspesifikasjon til produksjonssetting og videreutvikling.\n\nHan designet og utviklet tjenestene i Kotlin, på en serverless arkitektur i AWS, med infrastruktur konfigurert gjennom Terraform. Han satte opp og videreutviklet CI/CD-pipelines i GitLab, og etablerte prosesser for automatisert testing, bygg og utrulling. Han tok ansvar for både funksjonell og teknisk arkitektur, og ledet arbeidet med å gjøre infrastrukturen modulær og gjenbrukbar på tvers av tjenester.\n\nPhilip samarbeidet tett med teamleder, produkteier og utviklere i eget team, samt med arkitekter og sikkerhetsressurser i sentrale fagmiljøer. Han hadde en drivende rolle i samordning og kvalitetssikring av infrastrukturen, og migrerte eksisterende CloudFormation-konfigurasjoner til et mer robust og vedlikeholdbart Terraform-oppsett.\n\nHan jobbet også med observabilitet og sikkerhet: blant annet etablering av IAM-policyer, secrets-håndtering, autentisering med OAuth 2.0/JWT, og overvåkning med CloudWatch og X-Ray. I tillegg tok han ansvar for onboarding av konsumenter, teknisk dokumentasjon (OpenAPI), og kontinuerlig forbedring av både kodebase og samarbeidsrutiner.\n\nPhilip var en sterk ressurs i teamet som sikret at leveransen ble levert i henhold til kvalitet og tid, samtidig som han var en god støttespiller og sparringspartner."}],"skillsUsed":[{"name":"Kotlin","durationInYears":0},{"name":"Amazon Web Services","durationInYears":0},{"name":"Terraform","durationInYears":0},{"name":"Gitlab CI/CD","durationInYears":0},{"name":"AWS DynamoDB","durationInYears":0},{"name":"Lambda","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"OpenAPI","durationInYears":0},{"name":"Gradle","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Apache Kafka","durationInYears":0},{"name":"Kubernetes","durationInYears":0},{"name":"Mikrotjenestearkitektur","durationInYears":0},{"name":"Hendelsesdrevet arkitektur","durationInYears":0},{"name":"Funksjonell arkitektur","durationInYears":0},{"name":"Teknisk arkitektur","durationInYears":0},{"name":"OKR","durationInYears":0},{"name":"Kanban","durationInYears":0},{"name":"PostgreSQL","durationInYears":0},{"name":"JWT","durationInYears":0},{"name":"OAuth 2.0","durationInYears":0},{"name":"LocalStack","durationInYears":0},{"name":"AWS CDK","durationInYears":0},{"name":"AWS CloudFormation","durationInYears":0},{"name":"AWS SNS","durationInYears":0},{"name":"AWS SES","durationInYears":0},{"name":"AWS SQS","durationInYears":0},{"name":"AWS IAM","durationInYears":0},{"name":"AWS CloudWatch","durationInYears":0},{"name":"AWS X-Ray","durationInYears":0},{"name":"AWS RDS","durationInYears":0},{"name":"AWS S3","durationInYears":0},{"name":"AWS Lambda","durationInYears":0},{"name":"AWS EKS","durationInYears":0},{"name":"Flyway","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Docker Compose","durationInYears":0},{"name":"AWS CodePipeline","durationInYears":0},{"name":"AWS API Gateway","durationInYears":0},{"name":"Synkron arkitektur","durationInYears":0},{"name":"SMS","durationInYears":0},{"name":"Smidig metodikk","durationInYears":0},{"name":"Grafana","durationInYears":0},{"name":"Splunk","durationInYears":0},{"name":"Domain Driven Design (DDD)","durationInYears":0},{"name":"Testdrevet utvikling (TDD)","durationInYears":0}]},{"customer":"Permisjon","description":"","longDescription":"Reising","period":{"from":[2024,3],"to":[2025,5]},"roles":[],"skillsUsed":[]}],"educations":[{"degree":" Bachelor - Informatikk","school":"Universitetet i Oslo (UiO)","period":{"from":[2013,1],"to":[2016,12]}},{"degree":"","school":"The University of Hong Kong","period":{"from":[2015,1],"to":[2015,12]}}],"certifications":[{"name":"AWS Certified Developer - Associate","year":2023}],"courses":[],"languages":[{"name":"Norsk","level":"Morsmål"},{"name":" Engelsk","level":"Flytende skriftlig og muntlig"}],"skillCategories":[{"name":"Programmeringsspråk","skills":[{"name":"C#","durationInYears":2},{"name":"Java","durationInYears":4},{"name":"Scala","durationInYears":1},{"name":"Kotlin","durationInYears":2},{"name":"JavaScript","durationInYears":2},{"name":"Python","durationInYears":1},{"name":"Vue.js","durationInYears":1},{"name":"React.js","durationInYears":1}]},{"name":"Metodikk","skills":[{"name":"OKR","durationInYears":2},{"name":"Scrum","durationInYears":2},{"name":"Jira","durationInYears":6},{"name":"Confluence","durationInYears":6},{"name":"Kanban","durationInYears":4}]},{"name":"Database","skills":[{"name":"JDBC","durationInYears":3},{"name":"Oracle SQL","durationInYears":3},{"name":"PL/SQL","durationInYears":2},{"name":"jOOQ","durationInYears":1},{"name":"PostgreSQL","durationInYears":2},{"name":"Flyway","durationInYears":4},{"name":"DynamoDB","durationInYears":1},{"name":"IBM Informix","durationInYears":0},{"name":"JPA","durationInYears":0},{"name":"Microsoft SQL Server","durationInYears":1},{"name":"EF Core","durationInYears":1},{"name":"SQL","durationInYears":5}]},{"name":"DevOps og infrastruktur","skills":[{"name":"Linux","durationInYears":2},{"name":"JBoss","durationInYears":1},{"name":"Kibana","durationInYears":2},{"name":"Helm","durationInYears":1},{"name":"Docker","durationInYears":4},{"name":"Amazon Web Services","durationInYears":3},{"name":"Kubernetes","durationInYears":4},{"name":"NGINX","durationInYears":0},{"name":"Splunk","durationInYears":2},{"name":"Microsoft Azure","durationInYears":2},{"name":"Internet Information Services","durationInYears":1},{"name":"JMS","durationInYears":1},{"name":"RabbitMQ","durationInYears":1},{"name":"Sesam Master Data Hub","durationInYears":1},{"name":"Grafana","durationInYears":3},{"name":"ActiveMQ","durationInYears":0},{"name":"Apache Kafka","durationInYears":2},{"name":"Cloudformation","durationInYears":0},{"name":"Terraform","durationInYears":2},{"name":"Lambda","durationInYears":2}]},{"name":"Sikkerhet","skills":[{"name":"OAuth 2.0","durationInYears":4},{"name":"OpenID Connect","durationInYears":0},{"name":"HelseID","durationInYears":0},{"name":"STRIDE","durationInYears":1},{"name":"ROS-analyse","durationInYears":1},{"name":"PKI","durationInYears":1}]},{"name":"Rammeverk","skills":[{"name":"EJB","durationInYears":2},{"name":"WildFly","durationInYears":1},{"name":"Swing","durationInYears":1},{"name":"Swagger Code Generator","durationInYears":2},{"name":"ASP.NET Core","durationInYears":0},{"name":"Spring Boot","durationInYears":3},{"name":"Razor Pages","durationInYears":1},{"name":".NET Core","durationInYears":1},{"name":"Redux","durationInYears":1},{"name":"Vuex","durationInYears":0},{"name":"OpenAPI","durationInYears":4}]},{"name":"Tjenester","skills":[{"name":"SharePoint","durationInYears":1},{"name":"Altinn","durationInYears":1},{"name":"Microsoft Dynamics 365 Customer Service","durationInYears":1},{"name":"Public 360","durationInYears":1},{"name":"Auth0","durationInYears":1}]},{"name":"Kildekontroll, bygg og deploy","skills":[{"name":"Jenkins","durationInYears":2},{"name":"Git","durationInYears":7},{"name":"Octopus Deploy","durationInYears":1},{"name":"Azure Pipelines","durationInYears":1},{"name":"Maven","durationInYears":5},{"name":"Bitbucket CI","durationInYears":0},{"name":"GitLab","durationInYears":1},{"name":"AWS CodePipeline","durationInYears":3},{"name":"npm","durationInYears":1},{"name":"GitLab CI","durationInYears":1},{"name":"Yarn","durationInYears":0},{"name":"Azure DevOps","durationInYears":2},{"name":"GitHub","durationInYears":2},{"name":"Bitbucket","durationInYears":2},{"name":"Nexus","durationInYears":1},{"name":"Gitlab CI/CD","durationInYears":2},{"name":"Gradle","durationInYears":2}]},{"name":"Standarder","skills":[{"name":"OpenAPI/Swagger","durationInYears":0},{"name":"REST","durationInYears":6},{"name":"SOAP","durationInYears":2}]}],"qualityScore":null}
{"id":"67c6ba92f251ee13c0f326d0","keyQualifications":[{"label":"Senior konsulent","description":"Preben har nærmere 20 års erfaring innen test- og prosjektledelse, endringskoordinering, funksjonell testing, kvalitetssikring, produktdokumentasjon, feilretting og brukerstøtte. Han er meget godt vant til å jobbe i hektiske miljøer med høye krav til leveranse og presisjon. Han har i mange år jobbet fordypende innenfor feltene testledelse, prosjektledelse og release management og har opparbeidet seg en meget god rammeverksforståelse i forhold til ulike arbeidsmetodikker innen utvikling, testing og forvaltning av store og komplekse systemmiljøer. Han besitter meget gode dokumentasjons- og kommunikasjonsevner som har blitt brukt til trening av andre ansatte, dokumentering av funksjonelle behov, beskrivelse av prosesser og prosedyrer, ledelse av prosjekter og faglig og personlig oppfølging av medarbeidere, ledelse og underleverandører.\n \nDet siste året har Preben jobbet som funksjonell arkitekt hos Statnett i et produktteam bestående hovedsaklig av utviklere med ansvar for å utvikle og forvalte den interne tjenesten CACTUS. Denne rollen har han videreutviklet og har med tiden også tilegnet seg god kompetanse innenfor kraftdomene. Med en nøkkelrolle i produktteamet er han sentral i kommunkiasjonen med sluttbrukere og andre interessenter på tvers av organisiasjonen.\n\nHos Statnett jobbet han tidligere som produktansvarlig med ansvar for forvaltning og vedlikehold av ODMS, et komplisert og kraftig lastflyts verktøy utviklet og levert av Siemens. Ansvarsområdene innebar direkte kontakt med ekstern leverandør (Siemens) både lokalt i Norge, men også med leverandørkontor i USA. Andre sentrale arbeidsoppgaver inneholdt ansvar for å teste leveranser fra leverandør, opprette testplaner, dokumentere endringsbestillinger, gjennomføre og lede produksjonsoppgraderinger, lage og dokumentere arbeidsrutiner og assistere andre produktteam med ansvar for Statnetts kraftmodeller.\n \nHan har jobbet som testleder for to ulike prosjekter hos Tine SA. Det ene var et internt utviklingsprosjekt og det andre var et hyllevareprosjekt med utvidet leverandørkontakt i Nederland. Her hadde han ansvar for blant annet oppsett av testplaner, opprettelse av testcaser for prosjektene til de ulike test nivåene og opplæring av Tines egne ansatte for å lære om testdekning og gjennomføring av test caser. Alle leveranser ble koordinert og håndtert av testleder. \n \nVed siden av å være utekonsulent har Preben også i en periode hos en tidligere arbeidsgiver hatt en intern rolle som Prosjektkoordinator (PMO). I dette arbeidet var han ansvarlig for å sikre god fremdrift på tvers av flere produktutviklingsprosjekter for direkte kunder av firmaet. Han jobbet tett med produkt- og prosjektledere i arbeid med planlegging, utarbeidelse av roadmaps, rapportering av budsjetter, ressursallokering, oppgavestyring og kundedialog. I tillegg har han jobbet tett med ledelsen for å utarbeide standardiserte rammeverk for gjennomføring og rapportering i Jira/Confluence, samt avtaleverk innenfor forretningsområdet. Han har sørget for god oversikt, fremdrift og vært en viktig bidragsyter til suksess i prosjektene.\n \nSom Endringskoordinator hos SVV jobbet han i 5 år med release management, prosjekt- og ressurskoordinering i tillegg til å bidra med prosjektleder kompetanse inn i store IT-prosjekter. Her hadde han ansvar for å se til at noen av Vegvesenet sine største IT-løsninger som involverte bl.a. store publikumstjenester, ble levert i henhold til avtale i samarbeid med etablerte prosjektteam. Ved inntreden i teamene hadde han en ledende rolle med ansvar for behovskartlegging, strategi planlegging, møteledelse, oppgavefordeling, dokumentering av leveranse og oppsummering av endelig resultat.\n \nGjennom sine roller og arbeid har han utviklet sterke mellommenneskelige ferdigheter og kan samarbeide effektivt med mangfoldige team og interessenter. Han trives med å identifisere forbedringsmuligheter og implementere løsninger som gir bærekraftige resultater. Dette har vært en særlig bidragsyter til de ulike arbeidsrollene og prosjektenes suksessfaktor."}],"workExperiences":[],"projectExperiences":[{"customer":"Statnett SF","description":"CACTUS","longDescription":"CACTUS er et internt leveranse- og produktteam med 13 medlemmer bestående av teamlead, produkteier, utviklere, designer, testleder, tech lead og funksjonell arkitekt. Teamet har som ansvar å forvalte og videreutvikle platformen som i Statnett brukes for å produsere og sende ulike lastflytsprognoser som gir fremtidig forventet produksjon til markedet. CACTUS produktteam henter inn store mengder data fra et stort antall interne og eksterne datakilder og setter sammen dette ved hjelp av en lastflytsløser produsert av Siemens.","period":{"from":[2024,8],"to":null},"roles":[{"name":"Funksjonell arkitekt","description":"I sitt prosjekt jobber Preben med å opprettholde et overordnet blikk på både nåværende og framtidige behov, der han gjennomfører grundig behovskartlegging i dialog med interessenter og brukere. Han detaljbeskriver behovene for å sikre at løsningene treffer riktig, og samarbeider tett med designere og utviklere for å utvikle gode løsninger. Preben sørger også for at funksjoner og løsninger blir godt dokumentert, slik at de er lett forståelige og tilgjengelige. Videre bidrar han aktivt til å forbedre prosjektets metoder og tilnærminger til problemløsning, noe som styrker både kvalitet og effektivitet i arbeidet."}],"skillsUsed":[{"name":"Arkitektur og løsningsdesign","durationInYears":0},{"name":"JIRA","durationInYears":0},{"name":"Confluence Wiki","durationInYears":0},{"name":"Tjenestedesign","durationInYears":0},{"name":"Brukerinnsikt","durationInYears":0},{"name":"Spesifisering","durationInYears":0},{"name":"Product Backlog","durationInYears":0},{"name":"KanBan","durationInYears":0},{"name":"SCRUM","durationInYears":0}]},{"customer":"Statnett SF","description":"CACTUS","longDescription":"CACTUS er et internt leveranse- og produktteam med 13 medlemmer bestående av teamlead, produkteier, utviklere, designer, testleder, tech lead og funksjonell arkitekt. Teamet har som ansvar å forvalte og videreutvikle platformen som i Statnett brukes for å produsere og sende ulike lastflytsprognoser som gir fremtidig forventet produksjon til markedet. CACTUS produktteam henter inn store mengder data fra et stort antall interne og eksterne datakilder og setter sammen dette ved hjelp av en lastflytsløser produsert av Siemens.","period":{"from":[2023,12],"to":[2024,8]},"roles":[{"name":"Produktansvarlig/ forvalter","description":"Som deltagende i CACTUS prosjektet innebar rollen som produktansvarlig å være bindeleddet mellom hyllevaresystemet levert av Siemens og Cactus løsningen utviklet av prosjektet. CACTUS bruker dette systemet for å kunne produsere data som i sin tur brukes til produksjon av lastflytsprognoser også kalt IGM (Individual Grid Model). Systemet er meget sentralt og svært kritisk for å kunne produsere lastflytsprognoser som sendes til et sentralt nordisk knutepunkt i København og settes sammen med input fra de andre nordiske TSO. \n\nSom produktansvarlig hadde Preben ansvar for den daglige forvaltningen og vedlikeholdet av systemet. Dette arbeidet innebar ansvar for å teste leveranser fra Siemens, skrive testplaner, dokumentere avvik, skrive endringsbestillinger, utstrakt kommunikasjon med leverandør både innenlands og utenlands, samt lede gjennomføringer av alle produksjonsoppgraderinger knyttet til systemet. Videre hadde han også ansvar for å overse at der dokumentasjon på arbeidsprosesser manglet så kom dette på plass. Han tok initiativ til å starte prosjekt med målsetning om å opprette helt nye tilgangsstrukturer som skulle forenkle interne prosesser rundt tilganger til sensitiv informasjon. Merverdien var å skape synergier for raskere beslutningsruter ved å flytte ansvaret nærmere brukerne og på den måten også frigjøre arbeidskapasitet som kan bedre brukes andre steder i organisasjonen."}],"skillsUsed":[{"name":"Produktforvaltning","durationInYears":0},{"name":"JIRA","durationInYears":0},{"name":"Confluence Wiki","durationInYears":0},{"name":"Brukeroppfølging og rådgiving","durationInYears":0},{"name":"SCRUM","durationInYears":0}]}],"educations":[],"certifications":[],"courses":[],"languages":[],"skillCategories":[],"qualityScore":null}
{"id":"6679d8612a27bc70f10be7b8","keyQualifications":[{"label":"Standard","description":"Rafael er en dyktig data scientist med solid realfaglig bakgrunn. Han har doktorgrad i modellering, simulering og analyse fra NTNU, der han studerte hvordan man kan optimalisere kjemiske prosesser og gjøre dem mer miljøvennlige. Rafael trives i rollen som konsulent og finner det spennende å holde seg oppdatert med de siste fremskrittene innen KI.\n\nRafael har bred erfaring med ulike teknologier og plattformer, og er teknologi-agnostisk i sin tilnærming. Han har spesialisert seg i Python og har god kompetanse innen utvikling, maskinlæring og dataanalyse. Han har også praktisk erfaring med Azure og Google Cloud Platform, samt dbt (data build tool), som han bruker for å bygge robuste data pipelines.\n\nRafael har jobbet med en rekke spennende prosjekter i forskjellige bransjer. Han har for eksempel utviklet flere maskinlæringsmodeller for å hjelpe Elvia med å detektere avvik i strømnettet, og fungert som rådgiver i et prosjekt som laget en chatbot drevet av store språkmodeller.\n\nRafael er en problemløser som er opptatt av kvalitet og er flink til å dele kunnskapen sin med andre. Han har en lidenskap for å bruke kraften i data science og dataanalyse til å skape verdifull innsikt som bedriftene kan dra nytte av i sine beslutningsprosesser."}],"workExperiences":[],"projectExperiences":[{"customer":"Oljefondet","description":"Design, utvikling og systemansvar for en SharePoint-basert løsning","longDescription":"Design, utvikling, testing og systemansvarlig for en intern personal trading løsning: SharePoint 2013 + Nintex Workflows 2013 + Nintex Forms 2013 + JavaScript. Systemet kjører SQL spørringer mot forskjellige databaser ved bruk av webtjenester, noe som innebar en del databasearbeid.","period":{"from":[2017,9],"to":[2019,8]},"roles":[{"name":"Arkitekt","description":"Definere prosessen og de tekniske krav sammen med kunden."},{"name":"Utvikler","description":"Utvikle Sharepoint løsning fra bunnen av og produksjonssette de."},{"name":"Test- og kvalitetsansvarlig","description":"Teste løsningen og sørge for at den oppfylte business user sine krav."},{"name":"Systemansvarlig","description":"Etter at løsningen gikk live, ble jeg systemansvarlig. Jobben gikk ut på sikre god drift og rette feil. "}],"skillsUsed":[{"name":"SharePoint 2013","durationInYears":0},{"name":"Microsoft SharePoint Designer 2013","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"HTML","durationInYears":0},{"name":"Nintex Forms","durationInYears":0},{"name":"Nintex Workflows","durationInYears":0},{"name":"WebServices","durationInYears":0},{"name":"Systemdesign","durationInYears":0},{"name":"Funksjonelt ansvarlig","durationInYears":0},{"name":"Kravspesifisering","durationInYears":0},{"name":"Test","durationInYears":0},{"name":"Database","durationInYears":0},{"name":"Prosessmodellering","durationInYears":0},{"name":"SQL","durationInYears":0}]},{"customer":"Oljefondet","description":"Parser .NET løsning","longDescription":"Webtjenesten mottar innhold fra forskjellige kilder og i forskjellige format, med målet om å hente en rekke ønskede verdier. Tjenesten konverterer innholdet til tekst og så bruker regular expressions for å finne de ønskede verdiene. Brukere kommuniserer med tjenesten gjennom webappen. App-dataene lagres i en SQL database.\nKonsulenten har arbeidet med design, utvikling og deretter vedlikehold av en .NET løsning som består av en MVC-webapplikasjon og en webtjeneste i back-enden.","period":{"from":[2016,9],"to":[2019,8]},"roles":[{"name":"Integrasjonsutvikler","description":"Utviklet systemintegrasjonen mot databaser og annen programvare, via webtjenester."},{"name":".NET Utvikler","description":"Utforme, utvikle, implementere og vedlikeholde forretningslogikken til nettjenesten og bidra til å utvikle den tilsvarende front-end webapplikasjonen."},{"name":"Test- og kvalitetsansvarlig","description":"Design og utviklet integrasjonstester, generelle tester og satt opp relevante KPIer."}],"skillsUsed":[{"name":"SQL Developer","durationInYears":0},{"name":"HTML","durationInYears":0},{"name":"Microsoft .NET","durationInYears":0},{"name":"Stored Procedures","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"Optisk tegngjenkjenning","durationInYears":0},{"name":"OCR","durationInYears":0},{"name":"MVC","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"Test","durationInYears":0},{"name":"Kvalitetssikring","durationInYears":0},{"name":"Integrasjonstesting","durationInYears":0},{"name":"WebServices","durationInYears":0}]},{"customer":"Hobbyprosjekt","description":"Investor Playground","longDescription":"Konsulenten har designet og utviklet en Android-app på fritiden. Appen henter prisdata fra Yahoo! Finance for selskaper notert på Oslo Børs og gir brukerne muligheten til å designe enkle handelsstrategier og se deres utvikling over tid. Appen ble skrevet i Java ved hjelp av Android Studio","period":{"from":null,"to":null},"roles":[{"name":"JavaUtvikler","description":"Konsulenten er ansvarelig for hele prosessen fra ide, design, utvikling og implementering av app. "},{"name":"Android-utvikler","description":"Konsulenten designet innholde og utviklet løsningen,- App for Android"},{"name":"Data analytiker","description":"I rollen som data anlytiker har konsulenten modellert, innhentet og laget modell for analyse av dataene. "}],"skillsUsed":[{"name":"Java","durationInYears":0},{"name":"Google Analytics","durationInYears":0},{"name":"Android Studio/IntelliJ","durationInYears":0},{"name":"Android app design","durationInYears":0}]},{"customer":"Oljefondet","description":"Migrering av systemer til skyen","longDescription":"Målsetning med prosjektet var å migrere forskjellige systemer fra \"on premises\" til EC2 instancer i AWS. Pipelinen innebar bruk av TeamCity, Octopus Deploy, AWS elastic load balancers, AWS auto-scaling groups samt scripting med Windows Powershell for å automatisere installeringen av de forskjellige programvarer når instancene starter opp.","period":{"from":[2019,2],"to":[2019,8]},"roles":[{"name":"Utvikler","description":"Ansvarlig for å lette løsninger inn i AWS igjennom å scripte, teste og deploye de. "}],"skillsUsed":[{"name":"Octopus Deploy","durationInYears":0},{"name":"Windows Powershell","durationInYears":0},{"name":"TeamCity","durationInYears":0},{"name":"AWS","durationInYears":0},{"name":"IAM","durationInYears":0},{"name":"Atlassian Confluence","durationInYears":0},{"name":"Atlassian JIRA","durationInYears":0},{"name":"GitHub","durationInYears":0},{"name":"Testrail","durationInYears":0},{"name":"Amazon Elastic load","durationInYears":0},{"name":"Migrering","durationInYears":0},{"name":"Cloud","durationInYears":0},{"name":"Skyteknologi","durationInYears":0},{"name":"Amazon EC2","durationInYears":0},{"name":"Lift&Shift","durationInYears":0}]},{"customer":"Aker Solutions","description":"SubSense","longDescription":"Subsense er et tilstandsovervåkingssystem for en olje og gass undervannsplattform. Dette systemet forbinder rådata fra subsea-sensorer og subsea-tjenester med bruk av dataanalyse basert på tidsserier data fra IoT (instrumenter, sensorer og forskjellige subsea-enheter). Subsense består av flere analytiske applikasjoner f.eks designlekkasje, pumpeffektivitet, choke og ventilakkumulator, reservoar, hydraulisk fluidforbruk og overvåking av instrumenttilstand.\n\nDe forskjellige analytiske applikasjonene leverer forskjellig typer resultater, slik som hendelser og tidsseriedata som domeneekspertene eller systemovervåkere kan bruke for å lettere se hvor det potensielt kan være et problem eller hvilke komponenter som bør byttes ut.","period":{"from":[2019,9],"to":[2020,2]},"roles":[{"name":"Data Engineer","description":"Jobbet med overføring og transformasjon av data mellom kundens plattform (Cognite) og Google Cloud Platform. De webtjenestene utviklet kjørte på Google Cloud AppEngine og benyttet Google Cloud Datastore som databaseløsning."},{"name":"Backendutvikler","description":"Rafael jobbet med å iverksette den generelle modellen som en engine/rammeverk som deler arbeidet i små tasks. Koden var skrevet i Python og taskene kjører i skyen ved bruk av Google AppEngine.\nI tillegg bidro Rafael med å lage og vedlikeholde endepunkter til de forskjellige webtjenestene."},{"name":"Data Scientist","description":"I denne rollen jobbet Rafael med å utforme en generell modell som kan håndtere transformasjoner av forskjellige typer sensordata på en fleksibel og robust måte."}],"skillsUsed":[{"name":"Python","durationInYears":0},{"name":"Google Cloud Platform","durationInYears":0},{"name":"Google App Engine","durationInYears":0},{"name":"Google Cloud Datastore","durationInYears":0},{"name":"Numpy","durationInYears":0},{"name":"Pipenv","durationInYears":0},{"name":"Flask","durationInYears":0},{"name":"Jenkins","durationInYears":0},{"name":"Cognite","durationInYears":0},{"name":"Atlassian Confluence","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Google Cloud Stackdriver","durationInYears":0},{"name":"Google Cloud Scheduler","durationInYears":0},{"name":"Pytest","durationInYears":0},{"name":"Atlassian JIRA","durationInYears":0},{"name":"Atlassian BitBucket","durationInYears":0},{"name":"Google Cloud Tasks","durationInYears":0},{"name":"scipy","durationInYears":0},{"name":"IoT","durationInYears":0},{"name":"Domenekunnskap: Subsea","durationInYears":0},{"name":"Dataanalyse","durationInYears":0},{"name":"Pandas","durationInYears":0}]},{"customer":"Elvia","description":"POC Bildegjenkjenning","longDescription":"Selskapets bildesystem inneholder millioner av bilder, hvorav mange av dem blir jevnlig tatt fra helikoptre eller droner. Disse bildene inneholder verdifull informasjon om strømnettets tilstand.\n\nVi gjennomførte en proof-of-concept for bildegjenkjenning, der vi:\n\n1. Trener og betjener en maskinlæringsmodell for klassifisering som kan klassifisere bilder basert på typen elektrisk stolpe som vises på bildet: tre, stål eller betong. Senere ble en fjerde kategori lagt til: flere stolper.\n2. Trener og betjener en maskinlæringsmodell for objektdeteksjon som oppdager om en beskyttende topphette mangler på toppen av tremaster.\n\nEn Flask-bakendapplikasjon ble satt opp for å orkestrere trening og for å betjene maskinlæringsmodellene. Bakendapplikasjonen blir kalt av kundens bildesystem når nye bilder ankommer.\n\nNår et nytt bilde ankommer bildesystemet, blir klassifikasjonsmodellen kalt, og resultatet lagres som bilde-metadata. Hvis stolpen blir klassifisert som tremast, kjører objektdeteksjonsmodellen, og dens resultat lagres også som metadata. Brukerne kan deretter filtrere bilder i bildesystemet etter prediksjonsresultater.","period":{"from":[2020,4],"to":[2021,3]},"roles":[{"name":"Backendutvikler","description":"Bakendapplikasjonen ble skrevet i Python ved hjelp av Flask. Trening av maskinlæringsmodeller kjører på Azure Custom Vision, utløst programmatisk fra bakendapplikasjonen via Azure Custom Vision SDK. Azure Custom Vision er en skybasert løsning for bildegjenkjenning (klassifisering og objektdeteksjonsproblemer) som praktisk nok aksepterer bilde-URL-er både for trening og inferens.\n\nBakendapplikasjonen er en del av et større økosystem, selskapets bildesystem, som består av flere andre API-er og databaser som inneholder bilde-metadata. Bakendapplikasjonen kjører på Azure Kubernetes Service, CI/CD-pipelinen kjører på Azure DevOps, og infrastrukturen er orkestrert med Terraform. API-et er sikret ved hjelp av selskapets implementasjon av OpenID Connect.\n\nVi brukte Pytest til å skrive enhets- og integrasjonstester. API-et ble dokumentert ved hjelp av Sphinx."},{"name":"Data Scientist","description":"Jupyter-notatbøker ble brukt omfattende for utforskende analyse og bildemerking. Vi bygde treningsdatasettene for begge modellene fra bunnen av, en tidkrevende prosess som innebar manuell merking av mange bilder. De endelige datasettene hadde omtrent 4500 bilder for klassifiseringstilfellet og 1300 for objektgjenkjenningstilfellet.\n\nByggingen av datasettet for objektgjenkjenning var en prosess hvor vi rutinemessig reviderte og justerte reglene vi satte for oss selv angående hvordan vi skulle merke bounding-boksene. I begynnelsen hadde vi kun 2 kategorier for objektgjenkjenning: \"topphette\" og \"manglende topphette\"; men over tid økte vi antall kategorier for å ta hensyn til forskjellige aspekter som farge (\"hvit tophette\", \"svart topphette\") eller geometri (\"manglende tophette\", \"delvis manglende topphette\").\n\nHver iterasjon av datasettene ble versjonert og sjekket inn i kodebasen. Vi var spesielt opptatt av reproduserbarhet og å kunne spore en prediksjon tilbake til treningsdatasettet. Hver prediksjon ble koblet til både datasettversjonen og applikasjonsversjonen.\n\nDen viktigste metrikken som ble brukt for å vurdere modellens ytelse var F1-score, som vi maksimerte. Den nådde hele 94% for objektgjenkjenning og 99% for klassifisering. I objektgjenkjenningstilfellet gjennomførte vi flere runder med modellevaluering, der vi aggregerte kategoriene på forskjellige måter, på jakt etter høyest mulig F1-score.\n\nEt viktig valg i objektgjenkjenningstilfellet var modellarkitekturen (kalt \"domain\" i Azure Custom Vision), hvor den større \"General A1\" modellarkitekturen klarte seg mye bedre enn \"General\"."}],"skillsUsed":[{"name":"Python","durationInYears":0},{"name":"Microsoft Azure Cognitive Services","durationInYears":0},{"name":"Dataset creation","durationInYears":0},{"name":"Image classification","durationInYears":0},{"name":"Object detection","durationInYears":0},{"name":"Convolutional Neural Network (CNN)","durationInYears":0},{"name":"Sphinx","durationInYears":0},{"name":"Pytest","durationInYears":0},{"name":"Jupyter Notebook","durationInYears":0},{"name":"Flask","durationInYears":0},{"name":"REST","durationInYears":0},{"name":"DevOps","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"Microsoft Azure Kubernetes Service","durationInYears":0},{"name":"Azure Cognitive Services","durationInYears":0},{"name":"Azure Custom Vision API","durationInYears":0},{"name":"Miro boards","durationInYears":0},{"name":"Atlassian Confluence","durationInYears":0},{"name":"Atlassian JIRA","durationInYears":0},{"name":"JWT","durationInYears":0}]},{"customer":"Elvia","description":"POC Ansiktsgjenkjenning","longDescription":"Selskapet har et bildesystem med millioner av bilder, hvorav mange av disse er tatt fra helikoptere eller droner. I forbindelse med GDPR-regler er det ønskelig å kjøre en ansiktsgjenkjenning POC. Målet er i første omgang å detektere ansikter på bilder, kartlegge omfanget av persondata i selskapets bildesystem, og eventuelt bruke bounding-box informasjon fra ML-prediksjoner til å automatisere sletting / tilpassing av bildene, f.eks. gjøre relevante bildeområder uskarpe. ","period":{"from":[2021,2],"to":[2021,9]},"roles":[{"name":"Backendutvikler","description":"Jeg utviklet en skalerbar backend-applikasjon ved bruk av Flask, som orkestrerer treningen og eksponerer ML-modellene for inferens.\n\nBackend-applikasjonen er en del av et større økosystem, selskapets bildesystem, som består av flere andre API-er og databaser som inneholder bildemetadata. Backend-applikasjonen kjører på Azure Kubernetes Service, CI/CD-pipelinen kjører på Azure DevOps og infrastrukturen\n er orkestrert med Terraform. API-et er sikret ved hjelp av selskapets implementasjon av OpenID Connect.\n\nBackend-applikasjonen blir kalt av kundens bildesystem når f.eks. nye bilder er lagt til, og prediksjonsresultatene lagres som bildemetadata. Sluttbrukerne kan deretter filtrere bilder i bildesystemet basert på prediksjonsresultater.\n\nAPI-et ble dokumentert ved bruk av Sphinx.\n"},{"name":"Data Scientist","description":"I denne rollen var min hovedoppgave å finne en bildegjenkjenningsmodell som kunne oppfylle prosjektmålene.\n\nJupyter-notatbøker ble brukt omfattende for utforskende analyse og bildemerking. \n\nEn første testomgang ble gjort ved bruk av standard ansiktsgjenkjenningsmodeller fra skytjenester som Azure Face fra Azure Cognitive Services. Azure Face tilbyr forskjellige objektdeteksjonsmodeller, som er ment å brukes til å gjenkjenne ansikter på hverdagsbilder. En utfordring i dette prosjektet var imidlertid at mange av bedriftens bilder er tatt fra helikoptre eller droner, som er en annerledes bruksområde enn det Azure Face er ment for. Dette resulterte i et høyt antall falske positiver, noe som betydde at Azure Face-modellene ikke var egnet for typen bilder vi ønsket å gjøre deteksjon på.\n\nI en andre runde testing og undersøkelse bestemte vi oss for å trene vår egen objektdeteksjonsmodell, ved å bruke en allerede trent modell (Azure Face) for å hjelpe oss med å finne bilder med ansikter for å bygge vårt treningsdatasett. Forekomsten av bilder med ansikter var ganske lav, noe som innebar at vi måtte skanne et stort antall produksjonsbilder for å finne kandidater til vårt treningssett. Etter hvert bygde vi et treningssett med rundt 300 bilder, og vi bekreftet at andelen falske positiver hadde falt betydelig, men den var fortsatt uakseptabel høy.\n\nHver datasettiterasjon ble versjonert og sjekket inn i kodebasen. Vi var spesielt opptatt av reproduserbarhet og å kunne spore en prediksjon tilbake til treningssettet. Hver prediksjon ble koblet til både datasettversjonen og applikasjonsversjonen.\n\nVi konkluderte med at ytelsen til vår tilpassede objektdeteksjonsmodell ville fortsette å forbedres hvis den trenes på flere bilder/bounding boxes, men på det tidspunktet fikk andre oppgaver høyere prioritet og POC-en ble satt på pause."}],"skillsUsed":[{"name":"Microsoft Azure Cognitive Services","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"Jupyter Notebook","durationInYears":0},{"name":"CI/CD","durationInYears":0},{"name":"Microsoft Azure DevOps","durationInYears":0},{"name":"Sphinx","durationInYears":0},{"name":"Flask","durationInYears":0},{"name":"Microsoft Azure Kubernetes Service","durationInYears":0},{"name":"Object detection","durationInYears":0},{"name":"Atlassian Confluence","durationInYears":0},{"name":"Atlassian JIRA","durationInYears":0},{"name":"Miro boards","durationInYears":0},{"name":"SQLite","durationInYears":0},{"name":"Microsoft Azure Face API","durationInYears":0}]},{"customer":"Moldtelecom","description":"Moldtelecom Churn POC","longDescription":"Vi kjørte en POC for Moldtelecom i samarbeid med / på vegne av Computas Development Center i Romania. Målet var å forutsi hvilke kunder var mest sannsynlige til å si opp deres mobilabonnement, ved bruk av en ML-modell trent med tidligere kundedata. I tillegg var det ønskelig å avdekke hvilke features som var viktigst, dvs. hvilke variabler hadde størst innvirkning.","period":{"from":[2020,3],"to":[2020,4]},"roles":[{"name":"Data Engineer/Scientist","description":"Pre-prosessering av rådataene, EDA, trening av ML modeller med forskjellige arkitekturer og rammeverker, vurdering av modellenes ytelse"}],"skillsUsed":[{"name":"Keras","durationInYears":0},{"name":"Jupyter Notebook","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"Machine Learning","durationInYears":0},{"name":"Pandas","durationInYears":0},{"name":"Pytorch","durationInYears":0}]},{"customer":"Elvia","description":"Forbruksprediksjon / Predict@Scale","longDescription":"Dette prosjektet har som mål å generere prediksjoner for fremtidig energiforbruk. I begynnelsen var omfanget å forutsi strømforbruket for transformatorstasjoner (nettstasjoner). Dette skapte mer interesse for prosjektet, som deretter ble utvidet for også å støtte prediksjoner på sluttkundenivå.\n\nArbeidet består, blant annet, av å velge et passende sett av såkalte features, som kan representere det underliggende studietilfellet på en fornuftig måte, også kjent som feature engineering. I tillegg fokuserer vi på å optimalisere bruken av store datamengder og minimere den totale prediksjonstiden.\n\nFeatursene / informasjonselementene som ble brukt var basert på: temperatur fra værmeldinger, strømpris og tidligere forbruk. Tidspunktet på dagen, ukedagen og måneden ble også matet inn i modellen som informasjonselementer, etter en trigonometrisk transformasjon.\n\nNår det gjelder maskinlæringsmodellarkitekturen som ble brukt, ga random forest gode resultater for nettstasjoner, der støynivået er relativt lavt. Å forutsi fremtidig forbruk for individuelle kunder er mer utfordrende, på grunn av mye større usikkerheter. Dette førte til at vi heller adopterte sannsynlighetsbaserte modeller, som returnerer en sannsynlighetsfordeling i stedet for en enkeltverdi.\n\nForskjellige sannsynlighetsbaserte modeller ble testet, og den som ga oss de beste resultatene, er Temporal Fusion Transformer (TFT), som er basert på konseptet med attention, hovedkonseptet som driver den nåværende generative AI-æraen. TFT ga oss mye bedre resultater for tidsserieprediksjoner, både på nettstasjonsnivå og på sluttkundenivå.\n\nEn av de viktigste metrikker vi brukte for å vurdere modellens ytelse, er kvantildekning. Den forteller oss i hovedsak hvor godt de forutsagte sannsynlighetsfordelingene samsvarer med de forventede sannsynlighetsnivåene.\n\nProsjektet er en videreføring av tidligere arbeid, har et sterkt fokus på automatisering og på å muliggjøre/fasilitere tilgang til maskinlæringsmodeller internt i selskapet, og har som mål å adoptere en ML-Ops-tilnærming.","period":{"from":[2021,7],"to":null},"roles":[{"name":"Frontendutvikler","description":"Jeg bidro til å utvikle et brukergrensesnitt som muliggjør visualisering av tidsserier (forbruksutvikling, prediksjoner og prediksjonsfeil) og utløser trening av nye maskinlæringsmodeller.\n\nTrening av modeller involverer bruk av skyressurser, noe som har kostnader (for eksempel opprettelse av compute instances). Derfor var det viktig å implementere autentisering med Open ID Connect. Brukere logger seg på løsningen ved hjelp av ulike godkjente påloggingsmetoder."},{"name":"Backendutvikler","description":"Jeg lagde en Python-applikasjon ved hjelp av Flask, komplett med endepunkter for å kjøre prediksjoner og trene nye ML-modeller, blant annet funksjonalitet. I tillegg håndterer applikasjonen planlagte prediksjonskjøringer, skriver resultater til BigQuery for kontinuerlig overvåking av prediksjonsfeil og ekte MLOps. Den administrerer også kømeldinger i Azure Service Bus, noe som deler treningsprosessen opp i mindre oppgaver.\n\nApplikasjonens endepunkter sikres ved hjelp av kundens implementasjon av Open ID Connect. De ulike instansene av applikasjonen kjører som pods i Kubernetes, og infrastrukturen administreres med Terraform.\n\nNår det gjelder CI/CD, består pipelinen blant annet av Azure DevOps og Aquasec. Dokumentasjonen anses også som en del av byggeprosessen; den genereres automatisk med Sphinx og publiseres til GitHub Pages."},{"name":"Data Scientist","description":"Jeg designet og iverksatte en ML-pipeline som henter data, forbehandler det til features som forventes av ML-modellen, trener en ny ML-modell og deployer den.\n\nML-pipelinen kjører på Azure AI, og de trente modellene deployes der ved hjelp av Azure Container Instances. For å sikre konsistent dataforbehandling og beregning av features både under modelltrening og inferens, er koden pakket inn i en separat Python-pakke som importeres av både ML-pipelinen og backend-applikasjonen.\n\nML-pipelinen er skriptet i sin helhet, og blir programmatisk deployet fra backend-applikasjonen ved hjelp av Azure AI SDK."},{"name":"Data Engineer","description":"Rådataene, som inkluderer måleverdier og metadata om både kunder og infrastruktur, er fordelt over ulike tabeller og datasett i BigQuery.\n\nDisse dataene gjennomgår en rekke transformasjoner (fra rådata til kuraterte data og dataprodukter) til de ønskede tabellene og visningene oppnås, i tråd med prinsippene i data mesh-rammeverket. Hele prosessen orkestreres ved hjelp av dbt, som også praktisk nok viser dataenes \"lineage\"."}],"skillsUsed":[{"name":"OpenID Connect","durationInYears":0},{"name":"Flask","durationInYears":0},{"name":"Google BigQuery","durationInYears":0},{"name":"Microsoft Azure ML","durationInYears":0},{"name":"HTML","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"Docker","durationInYears":0},{"name":"Microsoft Azure ML Studio","durationInYears":0},{"name":"Microsoft Azure DevOps","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"Microsoft Azure Kubernetes Service","durationInYears":0},{"name":"Maskinlæring","durationInYears":0},{"name":"Tidsserier","durationInYears":0},{"name":"HashiCorp Terraform","durationInYears":0},{"name":"Microsoft Azure Service Bus","durationInYears":0},{"name":"dbt","durationInYears":0},{"name":"Pandas","durationInYears":0},{"name":"Gen AI","durationInYears":0},{"name":"Attention-based models","durationInYears":0}]},{"customer":"Elvia","description":"Analysere strømpris vs. strømforbruk","longDescription":"Det jobbes med å hjelpe kunden få bedre innsikt i forholdet mellom strømprisen og kundenes strømforbruk. Dette er av stor interesse for kunden, og ligner forskningsarbeid. \n\nArbeidet begynner med å hente måleverdier for historisk forbruk, samt historiske strømpriser. Så forsøker man å finne mønstre og korrelasjoner. Det ønskes også å koble temperaturdata inn i analysen. \n\nEn utfordring i dette initiativet har vært at det mangles et API som kan levere historiske strømpriser i norske kroner, men dette er noe kunden jobber med å sette opp.","period":{"from":[2022,1],"to":null},"roles":[],"skillsUsed":[{"name":"Google BigQuery","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"Pandas","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"matplotlib","durationInYears":0}]},{"customer":"Elvia","description":"Nye tariffer","longDescription":"Målet er å hjelpe kunden skaffe de nødvendige datauttrekk de trenger til å oppdatere tariffene, noe som gjøres en gang i året. 2022 er mer krevende enn vanlig pga. nye lover og  forskrifter som innfører en ny modell for hvordan sluttkundene skal klassifiseres mtp. f.eks. hvilken effektgruppe de faller i.\n\nUttrekkene er som regel tidsserier der det aggregeres energiforbruket / makseffekt / antall kunder på tvers av forskjellige kundegrupper. Hver kunde skal klassifiseres blant annet basert på sitt 1 års- rullerende energiforbruk, noe som kompliserer beregningene og koblingene/lineage mellom de forskjellige SQL spørringer. \n\nOppgaven ville vært nærmest umulig å utføre uten DBT og BigQuery pga. de store datamengdene involvert. \n\nI denne prosessen fant vi feiler i måleverdier, som er et viktig  grunnlag for uttrekkene; det jobbes nå med å rette feilene.","period":{"from":[2021,10],"to":[2022,4]},"roles":[],"skillsUsed":[{"name":"dbt","durationInYears":0},{"name":"Google BigQuery","durationInYears":0},{"name":"Big Data","durationInYears":0},{"name":"Database mining","durationInYears":0},{"name":"Python","durationInYears":0}]},{"customer":"Elvia","description":"Pegasus","longDescription":"Prosjektet utforsker hvorvidt selskapets råd og informasjon til kundene påvirker sluttkundenes strømforbruk","period":{"from":[2022,4],"to":[2023,9]},"roles":[{"name":"Data Scientist","description":"Jeg arbeidet med den matematiske utledningen av 2 metrikker, eller scores, som kan brukes til å måle 1) flatheten i et forbruksmønster over tid og 2) hvor godt en kunde utnytter intradag prisvariasjoner.\n\nJeg foreslo også en mulig strategi som bruker de 2 nevnte metrics, samt en forbruksprediksjon-løsning, for å identifisere scenarier med høyt potensial for forbedring: besparelser for kunden og en reduksjon i belastningen for selskapets infrastruktur."}],"skillsUsed":[{"name":"dbt","durationInYears":0},{"name":"Dataanalyse","durationInYears":0},{"name":"Data Mining","durationInYears":0},{"name":"Google BigQuery","durationInYears":0},{"name":"Big Query","durationInYears":0},{"name":"Data science","durationInYears":0}]},{"customer":"Elvia","description":"Anonymisering av kundeundersøkelser","longDescription":"Anonymisere data fra kundeundersøkelser og publisere det som dataprodukt i selskapets interne datakatalog.","period":{"from":[2022,5],"to":[2022,5]},"roles":[{"name":"Data Engineer","description":"Jeg jobbet med flere Excel regneark fra et tidligere prosjekt, som inneholdt verdifull informasjon fra kundeundersøkelser. Etter å ha slått dem sammen med annen metadata og måleverdier, resulterte det i en rekke anonymiserte dataprodukter. Datamodellene ble satt opp i tråd med data mesh-rammeverket."}],"skillsUsed":[{"name":"dbt","durationInYears":0},{"name":"Google BigQuery","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"Pandas","durationInYears":0},{"name":"Data Mesh","durationInYears":0}]},{"customer":"Elvia","description":"Hjelpe økonomer å automatisere beregninger","longDescription":"Rafael hjelper et par økonomer automatisere beregningene sine ved hjelp av Python og Jupyter notebooks.\n\nKundens workflow inkluderer en del R-kode publisert hvert år av NVE, Norges Vassdrag og Energidirektoratet, som kjøres bak et API. Kunden har erfaring med R Studio og kan kjøre hele opplegget lokalt.\n\nDet er omfattende bruk av Excel filer i workflowen; Excel er både input- og output-formattet. Det brukes Python biblioteker for å lese og skrive Excel filer.\n\nJupyter notebooks er brukervennlig, og git forenkler samarbeidet. Kompleksiteten har økt med tiden, og koden blir etterhvert flyttet til en Python pakke, hvilket gjør Jupyter-opplevelsen smidigere.","period":{"from":[2022,9],"to":[2024,8]},"roles":[{"name":"Data analytiker","description":"Sette seg i kundens oppgaver og forstå deres behov. Kartlegge mulige måter å forenkle og automatisere beregningene deres. "},{"name":"Pythonutvikler","description":"Iverksette automatisering og forenkling av kundens oppgaver ved bruk av Python kode."}],"skillsUsed":[{"name":"Python","durationInYears":0},{"name":"Pandas","durationInYears":0},{"name":"Jupyter Lab","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"Microsoft Excel","durationInYears":0},{"name":"R","durationInYears":0}]},{"customer":"Elvia","description":"Fortelvia","longDescription":"Prosjektet handler om å utforske og utvikle generativ-AI funksjonalitet som kan bidra til å øke produktivitet.\nTeamet har allerede prodsatt en chatbot som, med hjelp av store språksmodeller, lar brukere chatte med flere interne kunnskapsbaser.","period":{"from":[2023,10],"to":[2024,8]},"roles":[{"name":"Rådgiver","description":"Utforsking av generativ AI: Jeg testet ny funksjonalitet innen generativ AI basert på prosjektlederens forespørsler eller nysgjerrighet. Deretter gjennomførte jeg live demoer for teamet, der jeg viste hva som er mulig. For eksempel: utforske Langchain i kombinasjon med Confluence eller BigQuery.\n\nData Science-konsepter: Jeg forklarte relevante data science-konsepter for prosjektteamet, slik at vi hadde en felles forståelse.\n\nJevnlige oppdateringer: Jeg holdt meg oppdatert med den nyeste forskningen og artikler relatert til generativ AI. Deretter oppsummerte og delte jeg disse funnene med teamet under våre ukentlige sync-møter.\n\nAnalyse av brukerdata: Jeg analyserte applikasjonsbrukerdata fra samtykkende brukere. Rapportene jeg lagde var automatiserte og aggregerte for å ivareta personvern. Jeg brukte vanlige statistiske verktøy som histogrammer, men utnyttet også språkmodeller (LLMs) for nyskapende analyser. Jeg lagde eksempelvis en rapport om \"user intent\" ved å klassifisere chatbot-samtaler ved hjelp av en LLM. I tillegg brukte jeg LLMs for å besvare ja/nei-spørsmål om chatbot-interaksjoner, f.eks.: “Handler samtalen om programmering?”."}],"skillsUsed":[{"name":"SQL","durationInYears":0},{"name":"Big Query","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"Data science","durationInYears":0},{"name":"Large Language Models","durationInYears":0},{"name":"LangChain","durationInYears":0},{"name":"Research","durationInYears":0}]},{"customer":"Elvia","description":"Jordfeil","longDescription":"Elvia må følge kravene for overvåkning og håndtering av jordfeil i henhold til FEF2006 §5-2.\n\nProsjektet skal lage en automatisert løsning for å håndtere jordfeil oppdaget ved fase-jord spenningsmålinger fra AMS (Avanserte Måle- og Styringssystemer) i nettstasjoner og hos sluttkunder ved bruk av lekkasjestrømmålinger.\n\nProsjektmålene inkluderer:\n\n- Bruke lekkasjestrømmer for å detektere jordfeil, og legge ansvar for utbedring på riktig part, med minimal manuell oppfølging. Forventet fordeling er 90% sluttkunde og 10% nettselskap.\n- Implementere en løsning hvor jordfeilsdeteksjon basert på lekkasjestrømmer genererer krav til kunder om å rette feil.\n- Etablere effektive prosesser for håndtering av jordfeil, inkludert endringer i nettstasjon og etablering av nye stasjoner.\n- Planlegge og gjennomføre nødvendige ettermontasjer i nettstasjoner.\n- Redusere kostnader knyttet til feilsøking og utbedring gjennom sikker deteksjon, automatisering og korrekt ansvarsfordeling.\n","period":{"from":[2023,8],"to":[2024,8]},"roles":[{"name":"Data Scientist","description":"Som data scientist i prosjektet var mine ansvarsområder å velge en passende maskinlæringsmodellarkitektur, utforme relevante features / informasjonselementer basert på de tilgjengelige rådataene, sette opp metrics / evalueringsmetrikker for å vurdere ytelsen til modellen vår, samt holde presentasjoner for resten av teamet der jeg forklarer data science-konsepter som er relevante for prosjektet.\n\nDen underliggende typen problem i dette prosjektet var et såkalt multi-class klassifiseringsproblem, der modellen forutsier sannsynligheter for hver kategori (i dette tilfellet er kategoriene: varsle kunden, ignorer, feilkobling, osv.) og summen av sannsynlighetene er lik 1.\n\nDe metrikkene vi valgte for å vurdere ytelsen til modellen vår var presisjon og recall, og sannsynlighetsgrensene ble satt ved å maksimere F-score. Hovedvalget for domeneeksperter og prosjektleder dreier seg om å bestemme en relativ viktighet mellom presisjon og recall som passer til prosjektets behov.\n\nI løpet av de første månedene av prosjektet brukte vi en spesifikk implementering av KNN-algoritmen som var ment å brukes med tidsseriedata. Imidlertid ønsket vi etter hvert flere features / informasjonselementer, for eksempel kategoriske features, som ikke var kompatible med vår tidsseriemodellarkitektur. Vi redesignet deretter featursene våre og begynte å bruke en random forest modellarkitektur, noe som forbedret ytelsen i henhold til våre vurderingsmetrikker.\n\nModellene ble trent på et datasett som var spesifikt kuratert for dette formålet, og det ble lablet av domeneekspertene i vårt team. Etterfølgende runder med forbedringer i vår datamerkingsløsning førte til misforståelser som resulterte i feilmerkede eksempler i datasettet vårt. For å øke datakvaliteten i treningssettet vårt, ble en clustering-algoritme brukt til å identifisere og rette opp disse dårlig lablet eksempler."},{"name":"Pythonutvikler","description":"Jeg hjalp utviklerne i teamet (erfarne .NET-utviklere) med å komme i gang med å sette opp en Python-applikasjon som kunne betjene våre maskinlæringsmodeller. Jeg hadde ikke tid til å utvikle selv, men jeg bidro med å løse hindringer relatert til både Python generelt og spesifikke Python-biblioteker."}],"skillsUsed":[{"name":"Flask","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"Maskinlæring","durationInYears":0},{"name":"Data science","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"Google BigQuery","durationInYears":0},{"name":"dbt","durationInYears":0},{"name":"Pandas","durationInYears":0},{"name":"NumPy","durationInYears":0}]},{"customer":"Elvia","description":"ENØK: Energiøkonomisering","longDescription":"Elvia har etablert et tverrfaglig utvalg for å støtte regjeringens mål om å redusere strømforbruket i bygg med 10TWh innen 2030 og øke solkraftinnmatingen med 8TWh. Prosjektet, kjent som ENØK2.0, undersøker hvordan Elvia kan bidra til disse målene og vurderer konsekvensene for deres nettområde, med fokus på plusskunde-segmentet.\nDataplattformrepresentantene arbeidet med forretningsteamet for å utvikle datavisualiseringer og proof-of-concepts, vurdere datakvalitet, og definere parametere for plusskunder. Prosjektet avsluttet med en gjennomgang av funn og analyser med energikoordinatorene for å fremme en mer data-drevet beslutningsprosess.","period":{"from":[2024,4],"to":[2024,8]},"roles":[],"skillsUsed":[]},{"customer":"Sparebank 1 - Forsikring","description":"PS27","longDescription":"Prosjektet PS27 omhandler en utskifting av det eksisterende kjernesystemet F2100 med et nytt system. Kjernesystemet F2100 er levert av det danske selskapet FDC. Prosjektets målsetning er å ha driftsstart den 1. januar 2027.\n\n","period":{"from":[2024,9],"to":null},"roles":[{"name":"Data Scientist","description":"I denne rollen undersøkte Rafael landskapet for generering av syntetiske data, med et særlig fokus på personvern. Han studerte ulike verktøy for syntetisk datagenerering og deres underliggende modellarkitekturer, og prioriterte fleksibilitet, robusthet og skalerbarhet på grunn av stramme tidsfrister og usikre krav. Differensielt personvern ble identifisert som et viktig matematisk rammeverk, da det tilbyr kvantifiserbare garantier knyttet til risikoen for re-identifisering, og eksplisitt adresserer den iboende avveiningen mellom styrken på personverngarantiene og realismen i de syntetiske dataene som genereres. Rafael anerkjente kompleksiteten i å generere syntetiske versjoner av relasjonsdatabaser, en kjent utfordring innen feltet. Etter en grundig vurdering av tilgjengelige løsninger, identifiserte han en metode beskrevet i en forskningsartikkel som den mest passende. Denne metoden benyttet en differensielt privat algoritme for flertabell-syntese, designet for å koble sammen uavhengig genererte syntetiske tabeller fra enkeltabell-synteseverktøy, ved å koble sammen tabeller to og to, samtidig som statistiske mønstre og datafordelinger på tvers av tabeller ble bevart. Den valgte algoritmen brukte marginal queries på tvers av tabeller og minimerte en tapsfunksjon for å sikre god kvalitet i forhold til skarpe data. Avgjørende var at denne tilnærmingen muliggjorde en modulær strategi, som delte opp det komplekse problemet med syntetisk databasegenerering i håndterbare steg. Gjennom hele prosessen brukte Rafael etablerte evalueringsmetrikker for syntetiske data, som utility og fidelity, for grundig å vurdere kvaliteten og realismen til de genererte syntetiske dataene."},{"name":"Rådgiver / Konsulent","description":"I denne rollen var Rafael ansvarlig for å planlegge arbeidet med syntetiske data og innhente innspill fra relevante interessenter. Arbeidet omfattet også å formidle kunnskap om personvernprinsipper og presentere resultater for ulike team."},{"name":"Pythonutvikler","description":"I rollen som Python-utvikler utviklet Rafael RelationalSynth, et Python-bibliotek designet for å automatisere differensielt privat flertabell-syntetisk datagenerering. Dette biblioteket benytter SmartNoise, et åpen kildekode-bibliotek for differensielt personvern som tilbyr query release og enkeltabell-syntetisatorer, for å generere individuelle syntetiske tabeller. RelationalSynth integrerer deretter en differensielt privat algoritme fra en forskningsartikkel fra 2024 for å koble sammen disse tabellene. Flertabell-algoritmen kobler sammen syntetiske tabeller to og to, håndterer referanseintegritet og bevarer relasjoner mellom foreldre- og barnetabeller. Kjernen i algoritmen går ut på å iterativt løse et stort system av lineære ligninger. For å sikre differensielt personvern ble støyinjeksjon strategisk implementert der skarpe data ble aksessert. Rafael utviklet denne algoritmen med PyTorch, og fokuserte på å optimalisere for sparsity og vektorisering for å forbedre ytelsen. RelationalSynth ble bygget for å gjenbruke så mye som mulig av SmartNoise sin funksjonalitet for forbehandling av data. Bibliotekets kodestruktur var sterkt inspirert av SmartNoise, og etterlignet designet, med tilpasninger der det var nødvendig på grunn av forskjellene i problemstillingene som ble adressert. For å håndtere den beregningsintensive naturen til flertabell-algoritmen, ble en dedikert server utstyrt med et GPU-kort satt opp. Rafael samarbeidet med flere team, inkludert teamet \"Informasjon og innsikt\", for å installere GPU-en og navigere i utfordringer knyttet til avhengigheter for å sikre kompatibilitet mellom Torch- og CUDA-versjoner. RelationalSynth forenkler prosessen til å spesifisere et sett med SQL-spørringer som definerer de skarpe databasetabellene, sammen med litt støttende metadata og avhengighetsinformasjon. Ved vellykket generering setter RelationalSynth sømløst inn de syntetiske dataene i en SQL Server-database."}],"skillsUsed":[{"name":"SQL","durationInYears":0},{"name":"Python","durationInYears":0},{"name":"Personvern","durationInYears":0},{"name":"GDPR","durationInYears":0},{"name":"PyTorch","durationInYears":0},{"name":"NumPy","durationInYears":0},{"name":"Pandas","durationInYears":0},{"name":"Forsikring","durationInYears":0},{"name":"Research","durationInYears":0},{"name":"MS SQL Server","durationInYears":0}]}],"educations":[{"degree":"Kjemisk prosessteknologi","school":"Cuyo Universitet, Argentina","period":{"from":[2003,1],"to":[2006,12]}},{"degree":"Ingeniør i kjernekraft ","school":"Balseiro Institutt, Argentina","period":{"from":[2006,1],"to":[2009,12]}},{"degree":"Ph.D. i kjemisk prosessteknologi","school":"Norges teknisk-naturvitenskapelige universitet (NTNU)","period":{"from":[2010,1],"to":[2014,12]}}],"certifications":[{"name":"Google Certified Professional - Data Engineer","year":2020}],"courses":[{"name":"Nordic Infrastructure Conference","organizer":"NIC","year":2018},{"name":"Achitecting on AWS","organizer":"AWS Training and Certification","year":2018},{"name":"Norwegian Developers Conference (NDC)","organizer":"NDC","year":2018},{"name":"Norwegian Developers Conference (NDC)","organizer":"NDC","year":2021},{"name":"EuroPhython (Dublin)","organizer":"EuroPython Society","year":2022},{"name":"ML Con Berlin 2023","organizer":"ML Conference","year":2023}],"languages":[{"name":"Engelsk skriftlig og muntlig","level":"Flytende"},{"name":"Norsk skriftlig og muntlig","level":"Flytende"},{"name":"Spansk skriftlig og muntlig","level":"Morsmål"}],"skillCategories":[{"name":"Kunnskapsområder","skills":[{"name":"Systemdesign","durationInYears":2},{"name":"Funksjonelt ansvarlig","durationInYears":2},{"name":"Google Analytics","durationInYears":2},{"name":"Android app design","durationInYears":2},{"name":"OCR","durationInYears":3},{"name":"Aspose SDK","durationInYears":0},{"name":"AWS","durationInYears":1},{"name":"Testrail","durationInYears":1},{"name":"Kvalitetssikring","durationInYears":3},{"name":"Kravspesifisering","durationInYears":2},{"name":"Database","durationInYears":2},{"name":"Prosessmodellering","durationInYears":2},{"name":"Amazon Elastic load","durationInYears":1},{"name":"Lift&Shift","durationInYears":1},{"name":"Dataset creation","durationInYears":1},{"name":"Image classification","durationInYears":1},{"name":"Object detection","durationInYears":1},{"name":"Convolutional Neural Network (CNN)","durationInYears":1},{"name":"Sphinx","durationInYears":1},{"name":"Azure Cognitive Services","durationInYears":1},{"name":"Azure Custom Vision API","durationInYears":1},{"name":"Docker","durationInYears":4},{"name":"Maskinlæring","durationInYears":4},{"name":"Data Mining","durationInYears":1},{"name":"Utvikler","durationInYears":0},{"name":"Microsoft Excel","durationInYears":2},{"name":"Data science","durationInYears":2},{"name":"Large Language Models","durationInYears":1},{"name":"LangChain","durationInYears":1},{"name":"Gen AI","durationInYears":4},{"name":"Attention-based models","durationInYears":4},{"name":"Subsea","durationInYears":0},{"name":"Back-end","durationInYears":0},{"name":"Research","durationInYears":2}]},{"name":"Mobil","skills":[{"name":"Android","durationInYears":0}]},{"name":"Rammeverk","skills":[{"name":"Pandas","durationInYears":7},{"name":"Windows Powershell","durationInYears":1},{"name":"Microsoft .NET","durationInYears":3},{"name":"Git","durationInYears":5},{"name":"Jenkins","durationInYears":0},{"name":"Flask","durationInYears":6},{"name":"Keras","durationInYears":0},{"name":"Pytorch","durationInYears":1},{"name":"OpenID Connect","durationInYears":4},{"name":"Microsoft Azure ML","durationInYears":5},{"name":"matplotlib","durationInYears":4},{"name":"NumPy","durationInYears":6},{"name":"Pipenv","durationInYears":0},{"name":"Data Mesh","durationInYears":0},{"name":"TensorFlow","durationInYears":0},{"name":"scipy","durationInYears":0}]},{"name":"Utviklingsverktøy","skills":[{"name":"Android Studio","durationInYears":0},{"name":"Atlassian JIRA","durationInYears":3},{"name":"Octopus Deploy","durationInYears":1},{"name":"GitHub","durationInYears":1},{"name":"Atlassian Confluence","durationInYears":3},{"name":"SharePoint 2013","durationInYears":2},{"name":"SQL Developer","durationInYears":3},{"name":"Nintex Workflows","durationInYears":2},{"name":"Atlassian BitBucket","durationInYears":0},{"name":"Cognite","durationInYears":0},{"name":"Jupyter Notebook","durationInYears":2},{"name":"Microsoft Azure ML Studio","durationInYears":4},{"name":"Miro boards","durationInYears":1},{"name":"Microsoft SharePoint Designer 2013","durationInYears":2},{"name":"dbt","durationInYears":4}]},{"name":"Programmeringsspråk","skills":[{"name":"Java","durationInYears":2},{"name":"C#","durationInYears":3},{"name":"Matlab","durationInYears":0},{"name":"Windows Powershell","durationInYears":1},{"name":"JavaScript","durationInYears":2},{"name":"HTML","durationInYears":7},{"name":"SQL","durationInYears":7},{"name":"Python","durationInYears":6},{"name":"R","durationInYears":2}]},{"name":"Portalteknologi","skills":[{"name":"WebServices","durationInYears":3},{"name":"Google Cloud Stackdriver","durationInYears":0},{"name":"Atlassian Confluence","durationInYears":3}]},{"name":"Cloud teknologi","skills":[{"name":"AWS Console","durationInYears":0},{"name":"Resource provisioning","durationInYears":0},{"name":"Google Cloud Platform","durationInYears":0},{"name":"Google Cloud Scheduler","durationInYears":0},{"name":"Google Cloud Tasks","durationInYears":0},{"name":"Microsoft Azure Cognitive Services","durationInYears":1},{"name":"Microsoft Azure DevOps","durationInYears":5},{"name":"Microsoft Azure Kubernetes Service","durationInYears":5},{"name":"Google BigQuery","durationInYears":4},{"name":"Microsoft Azure Face API","durationInYears":1},{"name":"Microsoft Azure Service Bus","durationInYears":4},{"name":"Amazon EC2","durationInYears":1}]},{"name":"Frontendteknologi","skills":[{"name":"Nintex Forms","durationInYears":2},{"name":"MVC","durationInYears":3},{"name":"Atlassian Confluence","durationInYears":3},{"name":"Flask","durationInYears":6},{"name":"HTML","durationInYears":7}]},{"name":"Standarder","skills":[{"name":"WebServices","durationInYears":3},{"name":"Android Studio/IntelliJ","durationInYears":2},{"name":"REST","durationInYears":1},{"name":"JWT","durationInYears":1}]},{"name":"Database","skills":[{"name":"Stored Procedures","durationInYears":3},{"name":"Oracle Database","durationInYears":0},{"name":"Google Cloud Datastore","durationInYears":0},{"name":"SQLite","durationInYears":1},{"name":"Google BigQuery","durationInYears":4}]},{"name":"Sikkerhet","skills":[{"name":"IAM","durationInYears":1},{"name":"OpenID Connect","durationInYears":4}]},{"name":"Mellomvare","skills":[{"name":"Google App Engine","durationInYears":0},{"name":"Jupyter Lab","durationInYears":2}]},{"name":"Testing","skills":[{"name":"Test","durationInYears":3},{"name":"Integrasjonstesting","durationInYears":3},{"name":"Pytest","durationInYears":1}]},{"name":"Fagkompetanse","skills":[{"name":"Dataanalyse","durationInYears":2},{"name":"IoT","durationInYears":0},{"name":"Cloud","durationInYears":1},{"name":"CI/CD","durationInYears":1},{"name":"Tidsserier","durationInYears":4},{"name":"Database mining","durationInYears":1}]},{"name":"Maskinlæring","skills":[{"name":"Pipeline","durationInYears":0},{"name":"Flask","durationInYears":6},{"name":"Microsoft Azure Cognitive Services","durationInYears":1},{"name":"Microsoft Azure Face API","durationInYears":1},{"name":"Big Data","durationInYears":1},{"name":"Machine Learning","durationInYears":0}]},{"name":"Metodikk","skills":[{"name":"DevOps","durationInYears":1}]},{"name":"Infrastruktur","skills":[{"name":"HashiCorp Terraform","durationInYears":4}]}],"qualityScore":null}
{"id":"5cb0a6dcd108254a89a8cc8c","keyQualifications":[{"label":"Tekst for Web","description":"Ragnar er  seniorkonsulent med solid erfaring innen datavarehusprosjekter i store og små prosjekter, og har jobbet for oppdragsgivere innen en rekke sektorer og bransjer, herunder samferdsel, Bank/Finans og Kraft/Energi. \n\nRagnar har bred teknologierfaring og opererer en omfattende teknologistack, der Oracle database, Oracle OLAP, Oracle Warehouse Builder, Informatica Powercenter og Microsoft BI (SSIS, SSAS & SSRS) er sentrale elementer.\n\nRagnar har en meget gode evne til å tilegne seg kunnskap og rask settet seg inn i de forretningsmessige behovene. \n"}],"workExperiences":[{"employer":"Structurum","period":{"from":[2005,9],"to":[2009,8]}},{"employer":"Inmeta","period":{"from":[2009,9],"to":[2011,2]}},{"employer":"Platon","period":{"from":[2011,3],"to":[2014,5]}},{"employer":"Webstep","period":{"from":[2014,9],"to":[2019,4]}},{"employer":"Deloitte","period":{"from":[2014,6],"to":[2014,8]}},{"employer":"Cloudberries AS","period":{"from":[2019,5],"to":null}}],"projectExperiences":[{"customer":"Idun","description":"","longDescription":"Opprettet en ny datavarehusløsning. Prosjektet Inneholdt alle deler fra staging til datamart og OLAP.","period":{"from":[2005,10],"to":[2005,11]},"roles":[{"name":"Utvikler","description":""}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0},{"name":"Oracle OLAP","durationInYears":0}]},{"customer":"Bertel O. Steen ASA","description":"POC","longDescription":"POC for Bertel O. Steen deler og logistikk med data fra flate filer","period":{"from":[2005,11],"to":[2005,11]},"roles":[{"name":"Utvikler","description":""}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0},{"name":"Oracle OLAP","durationInYears":0},{"name":"Toad","durationInYears":0}]},{"customer":"Color Line","description":"Bistand","longDescription":"Bistå kunden med oppgradering av programvare, testing av diverse datavarehus script og mappinger. Gjennomtesting av lastejobber med Workflow. Testing av datakvalitet. Dokumentasjon","period":{"from":[2006,1],"to":[2006,1]},"roles":[{"name":"","description":""}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Toad","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0}]},{"customer":"Bertel O. Steen ASA","description":"","longDescription":"Utvikle og implementere et fullt datavarehus for BOS Deler og Logistikk. Løsningen baserer seg på Oracle database, Warehouse Builder, Workflow og OLAP-option. Kildedata henter fra et IBM OS390 miljø. Løsningen består mye av funksjonelt arbeid i forbindelse med oppbygging av forretningslogikk i løsningens dimensjoner og hierarkier","period":{"from":[2006,1],"to":[2006,8]},"roles":[{"name":"Utvikler","description":""}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0},{"name":"Toad","durationInYears":0},{"name":"SQL Developer","durationInYears":0},{"name":"Oracle Discoverer","durationInYears":0},{"name":"Oracle OLAP","durationInYears":0}]},{"customer":"Color Line","description":"","longDescription":"Utvikling av Color Lines nye datavarehus fra bunnen av. Videre utvikling av flere data-marter og rapporteringsløsning","period":{"from":[2006,6],"to":[2006,10]},"roles":[{"name":"Utvikler","description":""},{"name":"Tester","description":""}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0},{"name":"Oracle Discoverer","durationInYears":0}]},{"customer":"Bertel O. Steen ASA","description":"Forhandlerpotensiale","longDescription":"Utvidelse av eksisterende datavarehus med bilbestand i Norge sammenstilt med verkstedbesøk hos Bertel O Steens verksteder for å finne ut forhandlerpotensialet.","period":{"from":[2006,10],"to":[2006,11]},"roles":[{"name":"Utvikler","description":"Utvikling av ETL pakker som henter inn data fra flatfiler som ble satt i sammenheng med eksisterende datavarehus. Dette gjorde det mulig å lage rapporter på forhandlerpotensiale for verkstedbesøk."}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0},{"name":"Oracle Discoverer","durationInYears":0},{"name":"Toad","durationInYears":0},{"name":"SQL Developer","durationInYears":0}]},{"customer":"Color Line","description":"","longDescription":"Utvidelse av det eksisterende datavarehuset med logistikk. Inkluderer alt fra staging til datamart.","period":{"from":[2006,11],"to":[2007,8]},"roles":[{"name":"Utvikler","description":"Analyse av kildesystem etterfulgt av utvikling av ETL pakker og Discoverer rapporter."}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0},{"name":"Toad","durationInYears":0},{"name":"Oracle Discoverer","durationInYears":0}]},{"customer":"Exie","description":"","longDescription":"Etablering datavarehus for integrasjon med Exie-Corporate Performance Management portal. Løsningen ble utviklet for ISS med et betydelig antall kilder.","period":{"from":[2007,8],"to":[2007,11]},"roles":[{"name":"Utvikler","description":""}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0},{"name":"SQL Developer","durationInYears":0}]},{"customer":"Color Line","description":"","longDescription":"Nyutvikling av eksisterende OLAP løsning med bedre styrings og kontrollmuligheter samt bedre tilpasninger mot brukere","period":{"from":[2008,2],"to":[2008,3]},"roles":[{"name":"Utvikler","description":"Nyutvikling av Oracle OLAP kuber bedre tilpasset kundes behov"}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Discoverer","durationInYears":0},{"name":"Oracle OLAP","durationInYears":0},{"name":"Toad","durationInYears":0}]},{"customer":"Folketrygdfondet","description":"","longDescription":"Utvikling av nytt datavarehus for finansielle tall til videre analyse og erstatning av eksisterende Excel rapporterings regime.","period":{"from":[2008,9],"to":[2010,1]},"roles":[{"name":"Utvikler","description":"ETL utvikling med særlig fokus på ratinger fra Moodys, Fitch og S&P. Oppdraget inkluderte også drift og vedlikehold av databasen."}],"skillsUsed":[{"name":"Informatica PowerCenter","durationInYears":0},{"name":"Oracle Database 10g","durationInYears":0},{"name":"Toad","durationInYears":0},{"name":"SQL Developer","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0},{"name":"SimCorp Dimension","durationInYears":0}]},{"customer":"Skattedirektoratet","description":"","longDescription":"Del av datavarehusprosjekt som har pågått over flere år. Endre kilde for en eksisterende del av datavarehuset","period":{"from":[2010,2],"to":[2011,2]},"roles":[{"name":"Utvikler","description":"Hente inn ny kilde til datavarehus inkludert utvikling av ETL pakker og discoverer sluttbrukerlag"}],"skillsUsed":[{"name":"Oracle Database 10g","durationInYears":0},{"name":"Oracle Discoverer","durationInYears":0},{"name":"SQL Developer","durationInYears":0},{"name":"Toad","durationInYears":0},{"name":"Oracle Warehouse Builder","durationInYears":0}]},{"customer":"Hafslund","description":"Foranalyse","longDescription":"Foranalyse for Hafslunds nye BI initiativ.Arbeidet med å kartlegge dagens rapporteringsløsninger og informasjonsbehov. \n\nAnalysen omfattet forretningsområdene Nett og Strøm.\n\nAnalyseprosjektet inkluderte 2 prototyper. \n- Microsoft Power Pivot løsning for faktura\n- Microsoft Power Point konseptuell dashboard for kundesenteret","period":{"from":[2011,5],"to":[2011,6]},"roles":[{"name":"","description":""}],"skillsUsed":[]},{"customer":"Kredinor","description":"","longDescription":"Over de siste fire årene har Kredinor etablert et omfattende datavarehus med flere tilhørende BI-løsninger for å realisere visjonen om mer effektive innkrevningstjeneste og økt kommunikasjon med kunder på alle nivåer. \n\nGjennom både intern og ekstern webløsning basert på Sharepoint leveres styringsinformasjon i form av dashboards og rapporter til ledelsen i Kredinor samt kredinors kunder.","period":{"from":[2011,8],"to":[2011,7]},"roles":[{"name":"Utvikler","description":"Ansvarlig for flere mindre leveranser  til eksisterende datavarehus samt drift og feilretting i eksisterende SSIS pakker."}],"skillsUsed":[{"name":"SQL Server Integration Services (SSIS)","durationInYears":0},{"name":"SQL Server Management Studio (SSMS)","durationInYears":0},{"name":"SQL Server Analysis Services (SSAS)","durationInYears":0},{"name":"Transact-SQL","durationInYears":0}]},{"customer":"Elektroskandia","description":"","longDescription":"Flere mindre prosjekter som til sammen skulle gi full kontroll på inntekter og kostnader på produktnivå og effektivisere prosesser knyttet til oppfølging av kunder og leverandører","period":{"from":[2012,7],"to":[2012,12]},"roles":[{"name":"Utvikler","description":"Design og utvkling i SSIS og SSAS tabular med Excel pivot som rapporteringsverktøy."},{"name":"","description":""}],"skillsUsed":[{"name":"SQL Server 2012","durationInYears":0},{"name":"SQL Server Integration Services (SSIS)","durationInYears":0},{"name":"SQL Server Analysis Services (SSAS)","durationInYears":0},{"name":"SQL Server Management Studio (SSMS)","durationInYears":0}]},{"customer":"Hafslund","description":"","longDescription":"Implementering av nytt datavarehus for Hafslund basert på \nPlaton Data warehouse Framework. Utviklingen inkluderte integrasjon mot IFS.","period":{"from":[2013,4],"to":[2013,8]},"roles":[{"name":"Utvikler","description":"Analysere IFS som ny kilde til datavarehuset og opprettelse av en prototyp for disse dataene."}],"skillsUsed":[{"name":"SQL Server","durationInYears":0},{"name":"SQL Server Integration Services (SSIS)","durationInYears":0},{"name":"SQL Server Management Studio (SSMS)","durationInYears":0}]},{"customer":"SG Finans","description":"","longDescription":"Bistand til drift, utvikling og testing av eksisterende datavarehus","period":{"from":[2013,8],"to":[2014,1]},"roles":[{"name":"Utvikler","description":"Drift og tuning av eksisterende SSIS pakker samt kvalitetssikre data i datavarehuset"}],"skillsUsed":[{"name":"JIRA","durationInYears":0},{"name":"SQL Server Management Studio (SSMS)","durationInYears":0},{"name":"SQL Server","durationInYears":0},{"name":"SQL Server Integration Services (SSIS)","durationInYears":0}]},{"customer":"Veidekke Industri","description":"","longDescription":"Nytt datavarehus for Veidekke Industri. I første omgang ment til å automatisere månedsrapporteringen men også den daglige rapporteringen innenfor Veidekke industris forskjellige områder. \n\nProsjektet benyttet seg av Microsoft teknologi i alle ledd.","period":{"from":[2014,2],"to":[2014,8]},"roles":[{"name":"Utvikler","description":"Utvikling av ETL pakker, SSAS tabular kuber og rapporter i SSRS/Excel/Sharepoint i nært samarbeid med kunde."}],"skillsUsed":[{"name":"SQL Server 2012","durationInYears":0},{"name":"SQL Server Integration Services (SSIS)","durationInYears":0},{"name":"SQL Server Management Studio (SSMS)","durationInYears":0},{"name":"SQL Server Analysis Services (SSAS)","durationInYears":0},{"name":"JIRA","durationInYears":0}]},{"customer":"Folkehelseinstituttet","description":"HKR DVH","longDescription":"Opprette et datavarehus på Hjerte og Kar Register (HKR). Både kilde og destinasjon er Oracle database og Microsoft SSIS er ETL verktøy. \n","period":{"from":[2014,11],"to":[2015,3]},"roles":[{"name":"Utvikler og rådgiver","description":"Utvikle en ETL løsning på SSIS mot Oracle tabeller. Inkludert i dette er testing rundt ulike alternativer som kan brukes i forbindelse med Oracle databaser. \nI tillegg så har det vært rådgivning rundt arkitektur og design av tabellstruktur/stjerneskjema. \n"}],"skillsUsed":[{"name":"Oracle Database","durationInYears":0},{"name":"SQL Server Integration Services (SSIS)","durationInYears":0},{"name":"SQL Server 2012","durationInYears":0}]},{"customer":"Storebrand Asset Managment","description":"Storebrand Asset Managements Datavarehus","longDescription":"Bistå med utvikling, feilretting og drift av Storebrand Asset Managements Datavarehus løsning\nUtvikling av datavarehus ihht krav som utgår fra rapportutviklingsprosessen\n·         Spesielt fokus på utvikling av funksjonalitet knyttet til Solvency 2 rapportering\n·         Stikkord Kimball-type DVH, ETL, Informatica Powercenter, Oracle / MSSQL ","period":{"from":[2015,3],"to":[2018,9]},"roles":[{"name":"Rådgiver/utvikler","description":"Hovedansvar for utvikling av SAMs Solvency 2 løsning. Dataene hentes fra kildesystemet SimCorpDimension og består av flere komplekse uttrekk. \nAnalyse og utvikling av nye og moduler som er introdusert i SimCorpDimension og som fra leverandør ikke er dokumentert. \nUtvikling av inntektsrapportering fra fondssystemet TCM (mssql)\nForbedring og videreutikling av eksisterende databaseuttrekk. \nRådgiving rundt utvikling og opplæring i SQL.\n"}],"skillsUsed":[{"name":"Oracle Database","durationInYears":0},{"name":"Informatica PowerCenter","durationInYears":0},{"name":"ETL","durationInYears":0},{"name":"Kimball","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"Toad","durationInYears":0},{"name":"JIRA","durationInYears":0},{"name":"SimCorp Dimension","durationInYears":0},{"name":"MS SQL","durationInYears":0}]},{"customer":"Nordic Choice Hotels","description":"BI NCH","longDescription":"Tilgjengeliggjøre data for kredittavdelingen for å forbedre eksisterende rapportering","period":{"from":[2018,9],"to":[2018,11]},"roles":[{"name":"Arkitekt / Designer / Senior Utvikler","description":"Hente ut og tilgjengeligøring av data nødvendig for å utvide kredittrapporteringen. Enkelte av dataene var enkelt tilgjengelig og kunne raskt legges inn i eksisterende kube. \nDen største utfordringen lå i å finne ut av forhåndsbetalinger ble lagret i kildesystemet og mye av tiden gikk med til å grave i dataene samt følge opp flere personer i forretningen for å få mere informasjon"}],"skillsUsed":[{"name":"SSAS Multidimensional","durationInYears":0},{"name":"SSIS","durationInYears":0},{"name":"Microsoft Power BI","durationInYears":0},{"name":"Microsoft Excel","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"Dimensjonsmodellering","durationInYears":0},{"name":"Microsoft Visual Studio","durationInYears":0},{"name":"Microsoft SQL Server 2000 - 2016","durationInYears":0}]},{"customer":"Fremtind Forsikring","description":"KDV","longDescription":"Fremtind Forsikring har for tiden to datalager i SAS, en for skadeforsikring og en for\nLivsforsikring. SpareBank 1 Forsikring har valgt å bytte ETL-verktøy fra SAS til Informatica PowerCenter og i forbindelse med dette må de to datalagerene bli konsolidert. Dette er et langsiktig prosjekt som involverer å modulere alle eksisterende løsninger i et datalager og implementere det ved hjelp av Informatica Powercenter.","period":{"from":[2018,12],"to":[2020,8]},"roles":[{"name":"Utvikler","description":"Utvikling  og forvaltning i Informatica Powercenter av dagens KDV løsning. \nIntegrasjon mot mye kilder ved å bruke REST API, JSON og vanlige CSV filer"}],"skillsUsed":[{"name":"Informatica PowerCenter","durationInYears":0},{"name":"IBM Netezza","durationInYears":0},{"name":"JIRA","durationInYears":0},{"name":"JQ","durationInYears":0}]},{"customer":"SpareBank 1 Forsikring","description":"Informasjonsplattform Pensjon - IPP","longDescription":"Informasjonsplattform Pensjon er SpareBank 1 Pensjon sin løsning for tilrettelegging av data for deling og analyse. Informasjonsplattformen samler data fra ulike kildesystemer, behandle disse ved å for eksempel slå sammen data fra ulike kildesystemer og tilgjengeliggjøre de for analyse- og rapporteringsverktøy, samt for andre IT-løsninger, som kundeportaler og kapitalforvaltning.","period":{"from":[2020,9],"to":null},"roles":[{"name":"Senior ETL-utvikler","description":"Utvikling, videreutvikling og drift av nye og eksisterende ETL-jobber i SSIS for rapportering i verktøy som Tableau og Power BI. Jobber hovedsaklig inn mot kildene F2100 (filer) og NJORD (database via Denodo)"}],"skillsUsed":[{"name":"SQL Server","durationInYears":0},{"name":"SSIS","durationInYears":0},{"name":"Power BI","durationInYears":0},{"name":"Denodo","durationInYears":0},{"name":"GIT","durationInYears":0}]}],"educations":[{"degree":"Bachelor of Information Systems","school":"Norges Informasjonsteknologiske Høyskole (NITH)","period":{"from":[2000,1],"to":[2003,12]}}],"certifications":[{"name":"Microsoft SQL Server 2005, Business Intelligence Development","year":2008},{"name":"SQL Server 2008, Business Intelligence Development and Maintenance","year":2011}],"courses":[{"name":"MS 2793 Implementing and Maintaining Microsoft SQL Server 2005 Reporting Services","organizer":"Glasspaper","year":2008},{"name":"MS 2792 Implementing and Maintaining Microsoft SQL Server 2005 Integration Services","organizer":"Glasspaper","year":2008},{"name":"MS 2791 Implementing and Maintaining Microsoft SQL Server 2005 Analysis Services","organizer":"Glasspaper","year":2008},{"name":"2 dagers DBA kurs","organizer":"Oracle","year":2007}],"languages":[{"name":"Norsk","level":"Morsmål"},{"name":"Engelsk","level":"Flytende"}],"skillCategories":[{"name":"Verktøy","skills":[{"name":"Oracle Warehouse Builder","durationInYears":5},{"name":"SQL Server Management Studio (SSMS)","durationInYears":2},{"name":"Toad","durationInYears":8},{"name":"Informatica PowerCenter","durationInYears":7},{"name":"Oracle Discoverer","durationInYears":3},{"name":"SQL Server Reporting Services (SSRS)","durationInYears":0},{"name":"SQL Developer","durationInYears":4},{"name":"SQL Server Analysis Services (SSAS)","durationInYears":1},{"name":"SQL Server Integration Services (SSIS)","durationInYears":2},{"name":"ETL","durationInYears":4},{"name":"JIRA","durationInYears":6}]},{"name":"Databaser","skills":[{"name":"SQL Server 2012","durationInYears":1},{"name":"SQL Server 2008","durationInYears":0},{"name":"Oracle Database 10g","durationInYears":5},{"name":"Oracle Database 11g","durationInYears":0},{"name":"SQL Server","durationInYears":6},{"name":"Oracle Database","durationInYears":4},{"name":"MS SQL Server","durationInYears":0},{"name":"SQL","durationInYears":4},{"name":"IBM Netezza","durationInYears":2}]},{"name":"Testing/Test tools","skills":[{"name":"Visual Studio 2010","durationInYears":0}]},{"name":"","skills":[{"name":"Transact-SQL","durationInYears":0}]},{"name":"","skills":[{"name":"Oracle OLAP","durationInYears":1},{"name":"Analytical Workspace Manager","durationInYears":0},{"name":"Kimball","durationInYears":4},{"name":"SimCorp Dimension","durationInYears":5},{"name":"SSAS Multidimensional","durationInYears":0},{"name":"SSIS","durationInYears":5},{"name":"Dimensjonsmodellering","durationInYears":0},{"name":"Microsoft Visual Studio","durationInYears":0},{"name":"Power BI","durationInYears":5}]},{"name":"Programmeringsspråk","skills":[{"name":"PL/SQL","durationInYears":0},{"name":"SQL","durationInYears":4},{"name":"MS SQL","durationInYears":4}]}],"qualityScore":null}
{"id":"622a71907286eb0ece6b1359","keyQualifications":[{"label":"Sammendrag 2","description":"Roald er en senior datavarehuskonsulent med erfaring fra en rekke domener og kunder. Han har særskilt kompetanse og erfaring på MS SQL Server og rapporteringsløsninger knyttet til denne plattformen, inkludert SQL Server Integration Services (SSIS), Database Engine, Analysis Services,\nReporting Services, Power BI Desktop og Power BI Report Server. Han har fylt roller som ETL-utvikler, forvaltningsansvarlig, rapportutvikler, fullstack utvikler, migreringsansvarlig, testutvikler og dokumentasjonsansvarlig mm.\n\nRoald har jobbet mye i Microsoft-plattformen i sin karriere. I tillegg til datavarehus har han erfaring med design og konfigurasjon av nettsteder, analyse og rapportering i Sharepoint 2013, og med utvikling i BIML, BIMLscript, PowerShell og Access 2010. Han har utover dette arbeidet en del med Oracle, Oracle SQL Developer og PLSQL. \n\nMetoder og beste praksiser for datavarehus-prosjekter og -utvikling: Roald har alltid i en eller annen grad fulgt Kimballs metodologi for Enterprise Data Warehouse. I særlig grad er teknikkene brukt i prosjektene på Husbanken, Storebrand og Helsedirektoratet. Roald har bedrevet Entity Relationship-modellering på flere prosjekter, og jobbet med løsningsarkitektur, herunder funksjonalitet, forretningsprosesser, dokumentasjon, forankring, brukervennlighet og infoarkitektur i mange av prosjekter, men særskilt på FESCA, Statoil ASA og eMegler, Exact Eiendomsmegling AS og OBOS-megleren ASA.\n\nI et av sine seneste prosjekt hos SpareBank 1 Forsikring har han utover å jobbe med SQL Server, Visual Studio og Azure DevOps, satt seg inn i og jobbet med virtualiseringsplattformen Denodo, inkludert vdpadmin og VQL. Han er kjent med og har konfigurert Azure SQL database og andre tjenester og ser at hans lange erfaring med SQL Server kommer godt med. Roald er godt vant med å jobbe innenfor rammene av smidig utviklingsmetodikk og verktøy. Han er trygg i kommunikasjon direkte mot kundens forretningsbrukere og systemeiere, samt å oversette vage spesifikasjoner til detaljert kode. \n\nRoald er strukturert, ryddig og leveransedyktig. Han har prosjekterfaring fra en rekke forskjellige bransjer, teknologier og roller.\nRoald trives godt i team, samtidig som han jobber selvstendig med å finne gode løsninger på kundens problemstillinger og utfordringer."}],"workExperiences":[{"employer":"Objectware","period":{"from":[1998,6],"to":[2008,8]}},{"employer":"Bouvet","period":{"from":[2008,8],"to":[2014,8]}},{"employer":"Capgemini","period":{"from":[2014,8],"to":[2022,6]}},{"employer":"Cloudberries AS","period":{"from":[2022,6],"to":null}}],"projectExperiences":[{"customer":"Sparebank 1 Forsikring","description":"Informasjonsplattform Pensjon","longDescription":"Informasjonsplattform Pensjon (IPP) er den tekniske plattformen som benyttes for å samle inn, strukturere og tilgjengeliggjøre data for forretningsbrukere i hele selskapet. IPP vil inneholde data fra egne fagsystem, men også fra andre interne og eksterne kilder. IPP skal betjene forretningens datagrunnlag for faste rapporter og analyser, men skal også støtte analytikere med data som kan benyttes i en rekke ulike modeller og analyser.","period":{"from":[2019,4],"to":[2022,9]},"roles":[{"name":"Forvaltningsansvarlig.","description":"Forvaltningsansvarlig for Informasjonsplattform Pensjon sitt systemtest-miljø. Påse at skedulerte lastejobber kjører uten feil og hvis ikke ta nødvendige aksjoner."},{"name":"ETL-utvikler","description":"Design og utvikling av ETL (Extraction Transformation Loading)-rutiner for last av data fra forskjellige kilder opp til kundens datavarehus."},{"name":"Database-utvikler","description":"Design og utvikling av tabeller, stored procedures og andre database-objekter i kundens datavarehus."},{"name":"Test-utvikler","description":"Testing av ETL-rutiner og database-objekter utviklet av andre utviklere, samt design av slike tester."},{"name":"Dokumentasjon","description":"Dokumentasjon av egne og andres ETL-rutiner og database-objekter."},{"name":"Ad hoc-leveranser av datasett","description":"På forespørsel produsere datasett fra datavarehus og andre kilder, til bestemte formål, så som f.eks. forretningsanalyse. "}],"skillsUsed":[{"name":"SQL","durationInYears":0},{"name":"Git","durationInYears":0},{"name":"SQL Server 2019","durationInYears":0},{"name":"Visual Studio 2019","durationInYears":0},{"name":"SQL Server Integration Services 2019 (ETL)","durationInYears":0},{"name":"Denodo","durationInYears":0},{"name":"Denodo VQL","durationInYears":0},{"name":"Zephyr","durationInYears":0},{"name":"Denodo vdpadmin","durationInYears":0},{"name":"MS SharePoint","durationInYears":0},{"name":"Confluence","durationInYears":0},{"name":"Jira","durationInYears":0},{"name":"Azure DevOps","durationInYears":0}]},{"customer":"Bane NOR","description":"DRAGE","longDescription":"Bane NOR har behov for å samle og fremstille historiske data for punktlighet, regularitet, oppetid, forsinkelser, innstillinger, kapasitetspris, ytelsesordning, tjenestekatalog og kundeopplevelser, og fakturere og kreditere togselskapene iht. disse data. Dette er nødvendig i forhold til etterspørsel fra Samferdselsdepartementet, togselskapene, internt forbedringsarbeid og til bruk på internett.\n\nBane NOR har i denne sammenheng tre behov:\n1. Rapportere overordnede tall eksternt og internt.\n2. Analysere statistikk på et høyere detaljeringsnivå.\n3. Fakturering og kreditering av togselskapene.\nBane NOR hadde tidligere en løsning for å dekke disse behovene. Eksisterende løsningen var basert på en eldre versjon av Oracles plattform. Istedenfor å oppgradere denne plattformen ønsket Bane NOR å bygge en ny løsning basert på Microsofts BI-plattform.\n\nDRAGE-prosjektene går ut på å bygge og videreutvikle denne løsningen for å kunne rapportere hendelser på jernbanen i Norge, og fakturere og kreditere togselskapene iht. disse. Hendelsene legges inn i diverse systemer og hentes ut herfra til et Datavarehus. Dataene modelleres i dimensjonsmodeller og lastes opp i kuber. For håndtering av masterdata benyttes Master Data Services. Power BI, Excel og Reporting Services brukes for rapportering. Faktura genereres som XML og sendes togselskapene. Løsningen er et generelt datavarehus og rapportportaler for Bane NOR sine controllers og togselskapene, som inneholder data fra mange ulike kilder og benyttes til ulike rapporteringsformål. Videreutvikling planlegges fortløpende mens vedtatte prosjekter pågår.","period":{"from":[2017,8],"to":[2019,2]},"roles":[{"name":"Fullstack utvikler","description":"2018 og 2019: Datavarehus-, integrasjons-, kube- og rapportutvikler og konfigurasjon på diverse DRAGE-prosjekter.\n2017: Datavarehus-, integrasjons-, kube- og rapportutvikler i prosjektet \"KYT 2018\" (Kapasitetspris, Ytelsesordning og Tjenestekatalog), som er videreutvikling og endring av konseptene for kapasitetspris og ytelsesordning for 2017."},{"name":"Power BI-administrator","description":"2018 og 2019: Installasjon, konfigurasjon og dokumentasjon av Power BI Desktop og Power BI Report Server i DRAGE-miljøene."},{"name":"Dokumentasjonsansvarlig","description":"2018 og 2019: Begrepskatalog, brukerveiledninger og installasjonsdokumentasjon for hele DRAGE-løsningen.\n2017: Strukturering og forbedring av DRAGE-dokumentasjonen, slik den har utviklet seg i det året han var ute av DRAGE."},{"name":"Migreringsansvarlig","description":"2018 og 2019: Migrering av hele DRAGE-løsningen fra SQL Server 2014 til 2017."},{"name":"Forvaltningsansvarlig","description":"2017, 2018 og 2019: Forvaltning og support på alle komponenter og teknologier i DRAGE-løsningen."},{"name":"Introduksjon","description":"Innføre Bane NOR-ansatte i bruk av Power BI Desktop og Power BI Report Server."}],"skillsUsed":[{"name":"Attunity","durationInYears":0},{"name":"Visual Studio 2015 og 2017","durationInYears":0},{"name":"T-SQL","durationInYears":0},{"name":"Power BI Report Server","durationInYears":0},{"name":"SQL Server Data Tools 2013 og 2017","durationInYears":0},{"name":"Oracle SQL Developer.","durationInYears":0},{"name":"Power BI Desktop","durationInYears":0},{"name":"SQL Server 2014 og 2017 (alle moduler)","durationInYears":0},{"name":"Reporting Services","durationInYears":0},{"name":"PL-SQL","durationInYears":0},{"name":"Internet Information Services","durationInYears":0},{"name":"MS Excel","durationInYears":0}]},{"customer":"Eika Alliansen","description":"EAK","longDescription":"Effektivisering av kredittprosessen (EAK) er et pågående prosjekt som utvikler IT- verktøy og -rutiner som forbedrer, forenkler og effektiviserer arbeidsprosessene relatert til kreditt- og lånetildeling i Eika-bankene. En del av EAK - den delen Roald er involvert i - er design og utvikling av prosesser og systemkomponenter for datavarehus og rapportering relatert til bevilgninger av lån og andre produkter til bankkundene i Eika-systemet. Kildedata lastes fra de sentrale saksbehandlingssystemene i Eika og transformeres inn i datamodeller tilpasset spesifikke rapporteringsbehov og datamodeller som er mer generelle datavarehus-skjema. Anvendte verktøy i dette arbeidet er SQL Server 2008 og 2016(Database Engine, Integration Services, SQL Server Agent, Reporting Services), Visual Studio, SQL Server Data Tools, Team Foundation Server og Excel. Roalds bidrag var første versjon av rapportene Boligforskrift og Bevilgningsrapport og alt underliggende programmatisk fundament (datamodeller og lasteprosess) for disse, samt dokumentasjon. Spesifikasjonen for rapportene var i høyeste grad dynamisk og levende underveis i hele prosessen, og Roald bidro til å lande en mengde detaljer i denne.","period":{"from":[2016,5],"to":[2017,6]},"roles":[{"name":"ETL-utvikler","description":"Designer og utvikler av rutiner for last, ekstraksjon og transformasjon (ETL) av data mellom kildene og datamodellene."},{"name":"Database-design","description":"Designer og utvikler av datamodeller for spesifikke rapporteringsbehov og datavarehus-modeller."},{"name":"Rapportutvikler","description":"Designer og utvikler av rapportene Boliglånforskrift og Bevilgningsrapporten, som begge skal være verktøy for personell involvert i kredittprosessene i Eika-bankene. Første versjon av rapportene bruker Staging-data."},{"name":"Utvikler","description":"Design og utvikling med basis i Eika sitt vedtatte rammeverk for datavarehus- og rapportutvikling, bl.a. med fokus på enklest mulig migrasjon til SQL Server 2016."},{"name":"Dokumentasjonsansvarlig","description":"Dokumentasjon av modeller og ETL i Confluence."}],"skillsUsed":[{"name":"Team Foundation Server","durationInYears":0},{"name":"SQL Server 2016","durationInYears":0},{"name":"SQL Server 2008","durationInYears":0},{"name":"Visual Studio","durationInYears":0},{"name":"MS Excel","durationInYears":0},{"name":"Confluence","durationInYears":0}]},{"customer":"Lærdal Medical","description":"Lærdal Medical Master Data Services","longDescription":"Introduksjon av SQL Server Master Data Services 2016 i selskapet, for håndtering av daværende og fremtidige master-data. Man ønsket å installere og konfigurere Master Data Services 2016 i et test- og etproduksjonsmiljø og få en introduksjon i hvordan begynne å bruke systemet på best mulig måte.","period":{"from":[2016,6],"to":[2016,6]},"roles":[{"name":"Masterdata starthjelp","description":"Roald installerte og konfigurerte Master Data Services 2016 i to miljøer. Etter implementasjonen var han sentral i å gi teknisk nøkkelpersonell i Lærdal Medical en innføring i hvordan begynne å bruke MDS2016 til forvaltning av selskapets masterdata via Excel Master Data Services plug-in. På bakgrunn av Roalds arbeid ble prosjektet vellykket gjennomført og som et resultat fikk Lærdal Medical bedre\nkontroll på sine masterdata. Roalds opplæring av bedriftens ansatte var i så måte et nøkkelbidrag. Roald bidro til en myk introduksjon av Master Data Services 2016 i Lærdal Medical og demonstrerte sentrale tekniske prinsipper å operere etter den initielle fasen av masterdata-håndteringen i selskapet."}],"skillsUsed":[{"name":"MS Excel","durationInYears":0},{"name":"SQL Server Master Data Services 2016","durationInYears":0},{"name":"SQL Server Database Engine 2016","durationInYears":0}]},{"customer":"Jernbaneverket","description":"DRAGE","longDescription":"Jernbaneverket har behov for å samle og fremstille historiske data for punktlighet, regularitet, oppetid, forsinkelsestimer og innstillinger. Dette er nødvendig i forhold til etterspørsel fra Samferdselsdepartementet, togselskapene, internt forbedringsarbeid og til bruk på internett.\nJernbaneverket har i denne sammenheng to behov:\n\n1. Rapportere overordnede tall eksternt og internt.\n2. Analysere statistikk på et høyere detaljeringsnivå.\n\nJernbaneverket besitter i dag en løsning for å dekke disse behovene. Eksisterende løsningen er basert på en eldre versjon av Oracles plattform. Istedenfor å oppgradere denne plattformen ønsker Jernbaneverket å bygge en ny løsning basert på Microsofts BI-plattform.\n\nDRAGE-prosjektene går ut på å bygge denne løsningen for å kunne rapportere hendelser på jernbanen i Norge. Hendelsene legges inn i diverse systemer og hentes ut herfra til et Datavarehus. Dataene modelleres i en dimensjonsmodell og lastes opp i kuber. For håndtering av masterdata benyttes Master Data Services. Power BI og Excel brukes for rapportering. I første versjon skal den nye løsningen kun omfatte funksjonalitet som finnes i eksisterende løsning. Samtidig skal løsningen være en start på et generelt datavarehus for Jernbaneverket som inneholder data fra mange\nulike kilder og benyttes til ulike rapporteringsformål. En eventuell videreutvikling vil planlegges parallelt med at dette prosjektet pågår.","period":{"from":[2015,11],"to":[2016,6]},"roles":[{"name":"SQL Server konfigurasjonsansvarlig","description":"- Oppsett og konfigurasjon av SQL Server 2014, herunder Database Engine,\nIntegration Services, Reporting Services, Analysis Services, Master Data Services og\nInternet Information Services.\n- Design av installasjons- og utrullingsrutiner for alle deler av løsningen.\n- Oppsett og konfigurasjon av forbindelser mot Oracle.\n- Oppsett og konfigurasjon av Excel-klienter.\n- Driftsdokumentasjon, systemdokumentasjon og installasjonsdokumentasjon.\n- Oppsett og konfigurasjon av utviklingsmiljø, herunder bl.a. Visual Studio, SQL Data\nTools og Team Foundation Server.\n- Kontaktpunkt for driftsleverandøren for DRAGE-systemet."}],"skillsUsed":[{"name":"Attunity","durationInYears":0},{"name":"Visual Studio 2013","durationInYears":0},{"name":"SQL Server Data Tools 2013","durationInYears":0},{"name":"MS Excel","durationInYears":0},{"name":"SQL Server 2014 (alle moduler)","durationInYears":0},{"name":"Internet Information Services 8.5","durationInYears":0}]},{"customer":"Norges Bank","description":"NBDataFactory","longDescription":"NBDataFactory er et rammeverk for funksjoner relatert til import og prosessering av variererende datakilder i Norges Bank. Løsningen støtter datawarehousing ETL pattern, og tilbyr følgende funksjonalitet:\n\n-Orkestrering av jobb-eksekveringer.\n-Automatisk logging og rapportering av eksekveringer.\n-Maler for implementasjon av jobber av varierende typer.\nPr september 2015 er følgende spesifikke funksjonalitet implementert:\n-Jobb-typer for import og tilbakerulling av flatfiler av diverse formater og XML-filer.\n-Jobb-type for eksekvering av pakker utviklet i Microsoft SQL Server Integration Services (SSIS).\n\nNBDataFactory er implementert på Microsoft SQL Server-plattformen, og består pr september 2015 av et SSIS-prosjekt, 4 SQL Server-databaser og et deploy- og test-system utviklet med Visual Studio, SQL Server Management Studio og PowerShell.","period":{"from":[2015,5],"to":[2015,9]},"roles":[{"name":"Utvikler","description":"-Videreutvikling og forvaltning av SSIS-pakker og SQL Server-databaser iNBDataFactory.\n-Ferdigstillelse sys.dok, bruksanvisning og deploy-anvisning av versjon 1.\n-Testing, kodegranskning, administrasjon og godkjenning av versjon 1 før produksjonssetting. Roald avdekket en del feil og leverte en liste til Norges Bank over ting han mente burde vurderes å gjøre noe med. \n-Prototyping av NBDataFactory-komponenter i Biml og BimlScript for demonstrasjon av mulighetene. Roald har vært en pådriver for å ta i bruk BIML, men Norges Bank har foreløpig valgt å la være.\n-Design av utvikling av regresjonstest av alle implementerte jobber og komponenter i NBDataFactory, i PowerShell, SQL og XML. Testen har vært med å avdekke alvorlige feil i NBDataFactory.\n-Noe rådgivning med utgangspunkt i versjon 1 og videreutvikling av denne.\nEllers: Feiltretting i SSIS-pakker i forvaltning, utenfor NBDataFactory."}],"skillsUsed":[{"name":"SQL Server 2012","durationInYears":0},{"name":"Visual Studio 2012","durationInYears":0},{"name":"BimlScript","durationInYears":0},{"name":"Team Foundation Server","durationInYears":0},{"name":"PowerShell","durationInYears":0},{"name":"SQL Server Integration Services","durationInYears":0},{"name":"Biml","durationInYears":0},{"name":"SQL Server Data Tools 2012","durationInYears":0},{"name":"XML","durationInYears":0},{"name":"Smidig utvikling","durationInYears":0},{"name":"Visual Studio 2013","durationInYears":0}]},{"customer":"Nordea Bank","description":"MIS","longDescription":"Avdelingen AMS Front forvalter MIS, som er en applikasjon for administrasjon og rapportering på mislighold av lån i i Nordea Bank Norge ASA. MIS har i årrekke vært kontinuerlig utviklet i Access 2010 og SQL Server 2000, og er integrert med bl.a. bankens SAP-system og stormaskin-miljøer. Antall brukere er i dag ca. 1400 (hvorav ca 200 samtidige). AMS Front og brukerne av MIS opplever store utfordringer med systemets stabilitet, robusthet og ytelse, og trengte hjelp til å forbedre det med tiltak på både kort og lang sikt. Før Roald kom inn i prosjektet, ble en rekke tiltak\nidentifisert og til en viss grad også utført: AMS Front ønsket bistand med å tilpasse MIS til ny organisasjonsstruktur i Nordea Norge, ettersom MIS per mars 2015 opererte iht til den gamle strukturen og hadde implementert inne i seg en god del avhengigheter til denne. Det manglet i tillegg\noversikt over hvor i MIS disse avhengighetene konkret befant seg. AMS Front ønsket i tillegg å bygge inn logging av oppslag på persondata i MIS, iht\nlovfestede krav fra norske myndigheter. Logge-mekanismene skulle lagre loggdataene i SQL Server og presentere dem for Nordeas LogI-system som XML-filer. Roald bidro til at AMS Front fikk vesentlig innsikt og bedre kontroll med funksjonaliteten og implementasjonsdetaljene i MIS, sånn at de i fremtiden er mindre avhengig av ekstern konsulenthjelp i den daglige driften, forbedringer og videreutvikling.","period":{"from":[2015,3],"to":[2015,4]},"roles":[{"name":"Reverse engineering","description":"Kartlegging i MIS av avhengigheter til organisasjonsstrukturen og utarbeidelse av strategi og kode-komponenter for migrering til ny struktur. Dette arbeidet ble hovedsakelig utført gjennom kodegranskning av MIS-applikasjonen (Access, Visual Basic og SQL) og SQL-programmering."},{"name":"Utvikler","description":"Design og utvikling av logge-funksjonalitet i MIS vha Visual Basic, SQL, SQL Server Integration Services (SSIS) og XML: Det ble lagt inn logge-kommandoer i Visual Basic-modulene, som kalte lagrede prosedyrer for lagring av logg-dataene på SQL Server.\nDet ble laget SSIS-pakker som trakk ut logg-dataene fra SQL Server og presenterte dem som XML-filer for LogI-systemet."},{"name":"Forvaltning","description":"Noe DBA-bistand ifbm daglige, ukentlige og månedlige MIS-importjobber på SQL Server."}],"skillsUsed":[{"name":"Access 2010","durationInYears":0},{"name":"SQL Server Agent","durationInYears":0},{"name":"Visual Basic for Applications","durationInYears":0},{"name":"XML","durationInYears":0},{"name":"stored procedures","durationInYears":0},{"name":"Visual Studio 2012","durationInYears":0},{"name":"DBA-bistand","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"SQL Server Integration Services","durationInYears":0},{"name":"SQL Server 2012","durationInYears":0},{"name":"SQL Server Data Tools 2012","durationInYears":0}]},{"customer":"Avinor","description":"SiA","longDescription":"Styringsinformasjon i Avinor (SiA) er et datavarehus som gir datagrunnlag fra alle strategiske målområder i Avinorkonsernet, samt automatiserer\ninformasjonsinnhentingen. SiA skal være et komplett datavarehus som gir Avinor konsernet en versjon av sannheten for helhetlig styring innenfor alle målområdene. SiA skal gi mulighet for strategisk styring gjennom balanserte målekort, samt gi god støtte til strategiske og taktiske analyse, planlegging og rapporterings- prosesser. Datavarehuset skal i utgangspunktet gi informasjon for styring og ledelse og skalikke benyttes som en erstatning for fagsystem rapportering for saksbehandlingsformål eller lignende.\nRapporteringsområdene er: Økonomi & Finans, Personell & Organisasjon, Flysikkerhet, Kommersielt, HMS, Kunder & Samarbeidspartnere, Samfunn & Miljø og Tverrgående.\n\nSiA er implementert på Microsoft BI-plattformen versjon 2012 og Sharepoint 2013. I bunn ligger relasjonsdatabaser implementert i SQL Server, som får sine data fra bl.a. kildesystemer på Oracle via flyter implementert i SQL Server Integration Services(SSIS). Disse data er igjen basis for kuber i SQL Analysis Services (SSAS), som igjen brukes av rapporter implementert og distribuert til brukerne med Reporting Services (SSRS), PerformancePoint Services, Excel Services og Sharepoint 2013. SiA implementeres og vedlikeholdes i 80+ prosjekter i Visual Studio 2010 og TeamFoundation Server 2010. Arbeidet med SiA styres og administreres med Scrum-metodikken og støtteverktøyet Jira.","period":{"from":[2014,11],"to":[2015,2]},"roles":[{"name":"Utvikler","description":"Scrum team member. Utvikling og forvaltning av SSIS-pakker, SSAS-kuber og RS-rapporter. Database design og –utvikling. Konfigurasjon av rapporter og data-forbindelser på Sharepoint 2013. som gjøres tilgjengelig via intranettet til Avinor og Microsoft Reporting Services. vesentlig bidragsyter inn til SQL Server Integration Services-prosjektet for Extraction/Transformation/Loading av data til bruk irapportering i avdeling Flysikring. Forsøkt gjennom dette å innføre en del bredt anerkjente beste praksiser for produksjon av SSIS-pakker."}],"skillsUsed":[{"name":"SQL Server Analysis Services","durationInYears":0},{"name":"Sharepoint 2013-konfigurasjon","durationInYears":0},{"name":"SQL Server 2012","durationInYears":0},{"name":"SQL Server Reporting Services","durationInYears":0},{"name":"SQL Server Integration Services","durationInYears":0},{"name":"Oracle database","durationInYears":0}]},{"customer":"Nordea Bank","description":"MIS","longDescription":"Avdelingen AMS Front forvalter MIS, som er en applikasjon for administrasjon og rapportering på mislighold av lån i Nordea Bank Norge ASA. MIS har i årrekke vært kontinuerlig utviklet i Access 2010 og SQL Server 2000, og er integrert med bl.a. bankens SAP-system og stormaskin-miljøer. Antall brukere er i dag ca. 1400 (hvorav ca 200 samtidige). AMS Front og brukerne av MIS opplever store utfordringer med systemets stabilitet, robusthet og ytelse, og trengte hjelp til å forbedre det med tiltak på både kort og lang sikt. Før Roald kom inn i prosjektet, ble en rekke tiltak\nidentifisert og til en viss grad også utført: \n-En rekke forbedringer på implementasjonen og konfigurasjonen av objektene i Access, som løste en del utfordringer som gikk på ytelse.\n-Automatisering av en rekke manuelle rutiner, realisert som lagrede prosedyrer og jobber på SQL Server, samt robustifisering, stabilisering og optimalsering av eksisterende automatiske rutiner.\n-Migrering av implementasjonen og database på SQL Server til 2012-versjon, bl.a. fra DTS 2000 til SQL Server 2012 Integration Services.\n-Kvikkfiks for problem med voksende Access-fil, i form av manuell rutine med bytting av filen med en ny «frisk» fil hver dag.\n-Ytterligere forslag til tiltak for å gjøre MIS mer robust, stabilt og optimalt, og for å gi applikasjonen bedre ytelse. Bl.a. ved å konsolidere bort unødvendige elementer og applisere beste praksiser for applikasjoner basert på SQL Server 2012 og Access 2010.\n-Det kom også inn forslag om å omskrive MIS til en annen mer moderne og hensikstmessig plattform.\nRoald bidro til at AMS Front fikk vesentlig innsikt og bedre kontroll med funksjonaliteten og implementasjonsdetaljene i MIS, sånn at de i fremtiden er\nmindre avhengig av ekstern konsulenthjelp i den daglige driften, forbedringer og videreutvikling.","period":{"from":[2014,8],"to":[2014,10]},"roles":[{"name":"Utvikler","description":"Analyse av MIS per august 2014; hva som er gjort og hva som gjenstår, og gi råd for hva som bør være veien videre. Herunder skissere muligheter for fremtiden til MIS. Utførende av alle tiltak og aksjoner som han identifiserer, og som blir vedtatt gjennomført. Bistand under migreringen til SQL Server 2012-plattform."}],"skillsUsed":[{"name":"SQL Server 2012","durationInYears":0},{"name":"SQL Server Integration Services","durationInYears":0},{"name":"Visual Basic for Applications","durationInYears":0},{"name":"Access 2010","durationInYears":0},{"name":"DBA-bistand","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"stored procedures","durationInYears":0},{"name":"SQL Server Agent","durationInYears":0},{"name":"databasemodellering","durationInYears":0}]},{"customer":"Bayerngas Norge","description":"Intranett","longDescription":"Et intranett med samhandlingsløsning basert på Sharepoint 2013 on-premise er under utvikling. BG hadde ikke noe intranett før, men noe samhandling basert på eDocs DB, License2Share og Projectplace. Denne samhandlingen har en del ulemper, så som inkonsistent dokumenthåndtering, vanskelig tilgjengelighet til dokumentene, og manglende støtte for deling av dokumentene og annen informasjon. Den nye\nsamhandlingsplattformen skal løse disse problemene, og innføres i faser i takt med organisasjonens voksende modenhet for nye løsninger, og for å gjøre nytte av muligheter og læring som oppdages underveis. Lavere risiko er også en viktig driver for oppdelingen i faser.","period":{"from":[2014,4],"to":[2014,6]},"roles":[{"name":"Sharepoint-utvikler","description":"Konfigurasjon og utvikling av rapporter i Excel og Excel Services, og av arbeidsflyter for dokumenthåndtering, mottak av nyansatte og nettsted-bestillinger. Engasjementet varte 3 måneder og ble avsluttet grunnet overgang til ny arbeidsgiver."}],"skillsUsed":[{"name":"Sharepoint 2013 site settings","durationInYears":0},{"name":"MS SharePoint Designer","durationInYears":0},{"name":"Sharepoint 2013-konfigurasjon","durationInYears":0},{"name":"Visual Studio 2013","durationInYears":0},{"name":"Sharepoint 2013 Service Bus","durationInYears":0},{"name":"Sharepoint 2013 Workflow Manager","durationInYears":0},{"name":"MS SharePoint Admin","durationInYears":0},{"name":"Sharepoint 2013 GUI","durationInYears":0},{"name":"Sharepoint 2013 on- premise","durationInYears":0}]},{"customer":"Uloba","description":"Rådgivning databaseadminstrasjon","longDescription":"Uloba ønsket bistand i forbindelse med databaseadministrasjon av MS SQL Server. Hovedhensikten var å få denne databaseadministrasjonen inn i mer formelle rammer og iht. beste praksiser, og komme frem til hensiktsmessig SQL Server-landskap gjennom konsolidering, oppgradering og fjerning av eksisterende SQL Server-instanser og –databaser. Følgende oppgaver ble stipulert:\n\n-Foreslå nye og bedre løsninger for automatisk vedlikehold.\n-Gjøre ytelsesvurderinger og evt foreslå forbedringer – herunder vurdere virtueltversus fysisk vertsmaskinmiljø.\n-Vurdere skalerbarhet av daværende SQL Server-konstellasjon i Sharepoint 2013-løsningene for freedom.uloba.no og www.uloba.no.\n-Vurdere behov for og foreslå utvidelse av diskplass for SQL Server-databasene.\n-Vurdere sikkerhet på databaser, SQL Server-instanser og vertsmaskiner.\n-Etablere dokumentasjon av de ulike objektene i SQL Server-miljøet, der dette manglet.\n-Utrede konsekvenser av og planlegge oppgradering av MS SQL Server til BI- eller Enterprise-versjon (Daværende SQL Server-park var i hovedsak i Standard-versjon)","period":{"from":[2014,1],"to":[2014,2]},"roles":[{"name":"Rådgiver","description":"Rådgiver og initierende rolle i etableringen av nye og endrede rutiner i databaseadministrasjonen, og i utføringen av de andre oppgavene beskrevet over. Resultatet av arbeidet ble nedfelt i en rapport som omhandler følgende:\n\n-Kartlegging av eksisterende systemlandskap: Fysiske og virtuelle vertsmaskiner,disker, SQL Server –instanser og –databaser.\n-Kartlegging av eksisterende aktivitet mot databasene (ETL-rutiner, ad-hoc-spørringer), ytelse og ressursbruk (I/O, diskbruk, RAM, CPU).\n-Kartlegging av evt eksisterende vedlikeholdsrutiner, herunder bl.a. backup, varsling, indeksering og failover-mekanismer.\n-Kartlegging av viktige historiske og pågående feilsituasjoner, og årsakene til disse.\n-Kartlegging av eksisterende sikkerhetskonfigurasjon.\n-Beskrivelse av hvilke databaser o.a. entiteter som er i bruk og hvilke som kan fjernes.\n-Forslag til tiltak for hver enkelt SQL Server-instans og –database mhp vedlikeholdsrutiner, sikkerhet, skalerbarhet og testing, både på kortere og lengre sikt.\n-Forslag til bedre metodikk for utrulling av databaseendringer.\n-Viktige momenter til beslutningsprosessen for valg av nytt overvåkingsverktøy, herunder beskrivelse av eksisterende verktøy SQL Server.\n-Råd rundt innhold i og administrasjon av dokumentasjonen som må lages, herunder; Bruk av navnestandard, Master Data Management og verktøy for dokumentasjonsgenerering.\n-Anbefalinger rundt nåværende og fremtidig virtualisering.\n-Forslag til initielle tiltak for konsolideringen av SQL Server-instanser, databaser og lisenser.\n-Bevisstgjøring rundt beste praksiser for Sharepoint 2013-databaser.\n-Analyse og anbefalinger vedrørende oppgradering av SQL Server Standard-versjon til BI/Enterprise-versjon.\n\nFikk positiv respons på rapporten beskrevet ovenfor, og Roald håper den ble et vesentlig bidrag i prosessen med å komme frem til konkrete tiltak rundt bruken av SQL Server i Uloba."}],"skillsUsed":[{"name":"MS SQL Server 2012/2008/2005 Standard / BI / Enterprise","durationInYears":0},{"name":"Sharepoint 2013 on-premise","durationInYears":0},{"name":"Database Administration (DBA)","durationInYears":0},{"name":"VMware","durationInYears":0}]},{"customer":"Husbanken","description":"Analyse og rapportering","longDescription":"Prosjektet «Analyse og Rapportering» har ansvar for å forbedre dagens datavarehusløsning og presentere denne i SharePoint. Det er etablert ny løsning for ETL, database, arkitektur og infrastruktur. Arbeidet med ny løsning innebærer alle vanlige oppgaver innenfor et datavarehus, som modellering, aggregering, automatisering, rapportutvikling osv.\n\nDet er også etablert en ny presentasjonsløsning i SharePoint. Presentasjonslaget vil bestå av en produktportefølje som gir interne og eksterne brukere enklere tilgang til relevant statistikk og rapporter. Områdene er delt inn etter hvilket fagsystem som informasjonen hentes ut fra. I prosjektets første fase ble det formgitt, etablert og testes et nytt presentasjonslag med nødvendige verktøy for å dekkeinformasjonsbehov knyttet til området for bostøttesystemet, inkludert kopling mot økonomidata fra Agresso og data fra Statistisk sentralbyrå. Produkteiers krav tiluttak av egne og tilpassede rapporter og statistikker har gitt grunnlag for å kunne velge rett presentasjonsverktøy og -løsning.\n\nLøsningen er valgt implementert på Microsoft-plattform. Et nytt datavarehus er utviklet (og er under videreutvikling) på SQL Server 2012, foreløpig med Bostøtte-og styringsinformasjon. ETL-arkitektur, -rutiner og –rammeverk etableresfortløpende i SQL Server 2012 Integration Services, Pragmatic Works BiXpress og Task Factory. Rapporter og datamodeller for disse realiseres med Power View, Power Pivot, Excel Services og SQL Server Analysis Services, og presenteres i Sharepoint 2013. Sharepoint 2013 –løsningen er på sikt planlagt å utvides til å bli den nye samhandlingsplattformen for Husbanken.\n\nEn rød tråd i utviklingen av datavarehuset har vært og er fortsatt (august 2022) bruk av Kimballs metodologi for utvikling av Enterprise Data Warehouse. Se \"Sammendrag\" innledningsvis for oppsummering av punkter som har vært viktige elementer.","period":{"from":[2012,1],"to":[2013,12]},"roles":[{"name":"Utvikler","description":"Rådgivende og utførende rolle i etableringen av ny standard og rammeverk for ETL-utvikling i Husbanken, inkludert hvordan bruke Pragmatic Works BixPress og Task Factory. I tillegg til utvikling av ETL-rutiner innebærer rollen også sentral deltagelse i designet og implementasjonen av datavarehuset. Rådgivende og utførende rolle også i testing av alle aspekter ved løsningens første fase. Har vært sentral i utviklingen av presentasjonslaget, gjennom design og utvikling i Sharepoint 2013 GUI, og konfigurasjon og tilpasninger via Sharepoint 2013 sitt konfig,grensesnitt. Design og konfigurasjon av bl.a. sikkerhetsstruktur, metadatadefinisjoner, tilkoplinger til eksterne data, arbeidsflyter, samt alle lister og bibliotek. Samt forvaltning av alle lag og biter av løsningen (Databaser, integrasjon, Sharepoint). Roald håper det ble bygd videre på det han har gjort, både på ETL/SSIS/database- siden og på Sharepoint-siden. Alt som ble produsert var iht bredt anerkjente beste\npraksiser innen datavarehus, ETL og Sharepoint."}],"skillsUsed":[{"name":"Pragmatic Works Task Factory","durationInYears":0},{"name":"Pragmatic Works BIxPress","durationInYears":0},{"name":"Excel Services","durationInYears":0},{"name":"SQL Server Integration Services","durationInYears":0},{"name":"JavaScript Object Notation","durationInYears":0},{"name":"Subversion","durationInYears":0},{"name":"Datavarehus","durationInYears":0},{"name":"Excel Power Pivot","durationInYears":0},{"name":"Sharepoint 2013-on-premise-konfigurasjon","durationInYears":0},{"name":"MS SQL Server 2012","durationInYears":0},{"name":"Excel Power View","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"ETL-arkitektur","durationInYears":0},{"name":"relasjonsdatabaser","durationInYears":0},{"name":"SQL Server Analysis Services","durationInYears":0}]},{"customer":"Statoil ASA","description":"Business Intelligence Web","longDescription":"BIW (Business Intelligence Web) er et verktøy med nyhetsmodul, dokumentadminstrasjon («Knowledge bank»), rapporter og analyse (Business\nintelligence). Innholdet leveres av Evaluserve i India. Det lastes opp med FTP, går videre gjennom Biztalk for dekryptering og signering, og inn i BIW via SQL Server integration Services (SSIS) og Sharepoint. SSIS laster og prosesserer de strukturerte dataene inn i SQL Server datavarehus og kuber, som igjen vises i rapporter implementert med SQL Server Reporting Services (SSRS), Performance point dashboards og Excel. Sharepoint sørger for administrasjon, visning og søk av nyheter og ustrukturte dokumenter (word, pdf, xls osv.). \n\nFormålet med BIW (på engelsk):\n“The purpose of BIW is to spur knowledge sharing and collaboration within Statoil, and by doing so advance the internationalisation of the company. The mission and vision is to build a globally accessible knowledge platform that collects and integrates information from across Statoil divisions and external sources, as well as to provide value-adding analytical tools and functions.”","period":{"from":[2012,3],"to":[2012,12]},"roles":[{"name":"Utvikler","description":"Scrum team member. Backend design, utvikling og problemløsning. Har jobbet med design og utvikling av SSIS-pakker, rapporter i SSRS, PerformancePoint, .NET, SQL og Excel, kuber i SSAS, samt database-utvikling og -administrasjon. En del konfigurasjon via Sharepoint 2010 Central Admin."}],"skillsUsed":[{"name":"C#","durationInYears":0},{"name":"SSRS)","durationInYears":0},{"name":"MS Visual studio 2008","durationInYears":0},{"name":".NET","durationInYears":0},{"name":"MS PerformancePoint services 2010","durationInYears":0},{"name":"MS SQL Server 2008 R2 (SSIS","durationInYears":0},{"name":"SSAS","durationInYears":0},{"name":"MS Team Foundation Server 2010","durationInYears":0},{"name":"MS SharePoint","durationInYears":0},{"name":"XML","durationInYears":0},{"name":"MS Visual studio 2010","durationInYears":0},{"name":"Biztalk","durationInYears":0},{"name":"SQL","durationInYears":0},{"name":"MS Excel services 2010","durationInYears":0},{"name":"FTP","durationInYears":0}]},{"customer":"Statoil","description":"FESCA","longDescription":"FESCA (Front End System for Cost Allocation) er et forsystem for kostnadsallokeringinternt i Statoil. Allokeringen innebærer knytting av interne kostnader til de forskjellige avdelingene i Statoil nasjonalt og globalt. Systemet leser månedlig inndata om kostnader fra filer på diverse formater, bl.a. XML, samt filer med konfigurasjonsdata. Data-filene produseres av de forskjellige linjene/avdelingene i Statoil som tilbyr produkter og tjenester, og legges på bestemte lokasjoner hvor FESCA forventer å finne dem. Konfigurasjonsfilene inneholder info om ansatte, avdelinger, produkter, priser, økonomi-koder o.a. data som er nødvendige for kostnadsberegningen og -allokeringen.\n\nAntall kilder er i dag ca. 80 og er økende. FESCA kobler sammen dataene og gjør beregningen og allokeringen etter bestemte forretningsregler som typisk er varierende for de forskjellige datakildene. Etter at kostnadsallokering er gjort, produserer FESCA XML-filer med aggregerte kostnadstall, som vha. bl.a. BizTalk sendes til økonomisystemet i Statoil (SAP) for postering. FESCA presenterer også et view av de produserte allokeringsresultatene, for import til et SAP Business Warehouse i Statoil.\n\nFESCA opereres fra et grensesnitt i MS Reporting Services 2008, med diverse rapporter for kontroll av dataene før og etter kjøring av de forskjellige stegene i allokeringsprosessen, samt knapper for igangsetting og reversering av disse stegene. I løpet av 2012 ble dette grensesnittet delvis erstattet av web-grensesnitt implementert i Microsoft .NET. Utviklingen av FESCA har pågått gjennom forskjellige prosjekter, faser og leveranser siden oktober 2008, og pågår fortsatt. Systemet har vært i normal produksjon siden begynnelsen av 2010.","period":{"from":[2008,10],"to":[2012,6]},"roles":[{"name":"Utvikler","description":"Design og utvikling av hele FESCA for Global Business Services i Statoil, med utgangspunkt i SAS-koden for systemet FESCA skulle erstatte. Herunder: Design og utvikling av relasjonsdatabase, Extraction/ Transformation/Loading (ETL)-rutiner,rapporter, user interface og XML-formater. Administrasjon og forvaltning av hele løsningen i test- og produksjonsmiljø. Initelt design for ETL og database ble kvalitetssikret av representant fra Microsoft.\n\nMed SSIS bidro Roald til visualisering av og bevisstgjøring på komplisert logikk som før var skjult inne i SAS-koden, og bare kjent og forstått av ytterst få personer. Underveis i prosessen ble det også avdekket og fikset feil og mangler som kunne ha fått store konsekvenser. Etter at logikken kom over i SSIS ble det også enklere å gjøre endringer på den."}],"skillsUsed":[{"name":".NET","durationInYears":0},{"name":"MS Excel","durationInYears":0},{"name":"MS SQL Server 2008 (SSIS/SSRS/SQL)","durationInYears":0},{"name":"SAS","durationInYears":0},{"name":"relasjonsdatabaser","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"Biztalk","durationInYears":0},{"name":"Altova XML-verktøy","durationInYears":0},{"name":"MS Team Foundation Server 2010","durationInYears":0},{"name":"XML","durationInYears":0},{"name":"SAP","durationInYears":0}]},{"customer":"Zacco","description":"Ledelsesrapportering","longDescription":"Design og utvikling av en rapporterings-database og tilhørende ETL-rutiner.","period":{"from":[2008,8],"to":[2008,11]},"roles":[{"name":"Utvikler","description":"Design og utvikling av en rapporterings-database og tilhørende ETL-rutiner.\nRoald illustrerte og \"made a start\" når det gjelder å få til da skjulte data inn i en modell og opp i dagen via rapporter."}],"skillsUsed":[{"name":"MS SQL Server 2005 / 2000; SQL Server Management Studio og SSIS / DTS","durationInYears":0}]},{"customer":"Storebrand","description":"Datavarehus","longDescription":"Etablering av datavarehusløsning for månedlige konto- og kundedata samt daglige transaksjoner, hvor hoveddriver var BASEL II direktivene, som angir retningslinjer for risikostyring.","period":{"from":[2005,4],"to":[2008,4]},"roles":[{"name":"Utvikler","description":"Database-design og -utvikling, design og utvikling av ETL-rutiner, design, utvikling og testing av\nvedlikeholdsapplikasjon i ASP.NET og C#. Dokumentasjon. Migrering av MS SQL2000 DTS-pakker og -jobber til MS SQL2005 SSIS-pakker og jobber. Nyutvikling og videreutvikling av SSIS-pakker og -jobber. Forvaltning/drift av bankens datavarehus.\n\nRoald leverte et bidrag til hvordan bruke MS SQL 2005 SSIS i datavarehus-prosjekt etter beste praksiser.\n\nSentralt i utviklingen av datavarehuset var bruk av Kimballs metodologi for utvikling av Enterprise Data Warehouse. Se \"Sammendrag\" innledningsvis for oppsummering av punkter som har vært viktige elementer."}],"skillsUsed":[{"name":"MS SQL Server 2005 Management Studio","durationInYears":0},{"name":"MS Internet Information Server","durationInYears":0},{"name":"MS Visual Studio .NET 2003","durationInYears":0},{"name":"Oracle","durationInYears":0},{"name":"MS ASP.NET 1.1","durationInYears":0},{"name":"Toad","durationInYears":0},{"name":"SQL Server 2005 SSIS","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"MS SQL server 2000","durationInYears":0},{"name":"ApexSQL","durationInYears":0}]},{"customer":"Exact Eiendomsmegling og OBOS-megleren","description":"eMegler","longDescription":"eMegler er et komplett saksbehandlingssystem for eiendomsmeglingen og oppgjørsprosessen i Exact og OBOS, fra selger melder seg til oppgjør og overtakelse har funnet sted. Systemet er integrert med en rekke av OBOS sine andre kjernesystemer, bl.a. økonomisystem og medlemsregister på AS/400 stormaskin, og datavarehus/kuber/rapportering på Cognos-plattform.","period":{"from":[2002,8],"to":[2008,4]},"roles":[{"name":"Utvikler","description":"Database-design og utvikling, Extraction/Transformation/Loading (ETL), design, utvikling og testing av COM+-komponenter og ASP-websider. Alle typer dokumentasjon. Forvaltningsansvarlig for alle lag av eMegler. Rådgivning og teknisk bistand i alle typer driftsspørsmål.\n\nGjennom sine mange år på eMegler-prosjektene bidro Roald til stabilitet,  forutsigbarhet og trygghet rundt driften og videreutviklingen av eMegler. Han mener også å ha avdekket og fikset mange feil og mangler, og sørget for at beste praksiser har blitt fulgt i alle lag av applikasjonen."}],"skillsUsed":[{"name":"MS Visual Basic 6.0","durationInYears":0},{"name":"MS SQL Server 2000 DTS","durationInYears":0},{"name":"MS Commerce Server 2000","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"MS SQL Server 2000","durationInYears":0},{"name":"MS Active Directory","durationInYears":0},{"name":"MS Windows NT 4.0","durationInYears":0},{"name":"MS MDAC","durationInYears":0},{"name":"Cognos","durationInYears":0},{"name":"MS LDAP","durationInYears":0},{"name":"Rational Rose","durationInYears":0},{"name":"MS .NET Framework 1.1","durationInYears":0},{"name":"MS Internet Information Server 5.0","durationInYears":0},{"name":"80-20 Document Management Extensions Server 6.5 og 8.5","durationInYears":0},{"name":"MS COM+","durationInYears":0},{"name":"XML","durationInYears":0},{"name":"MS Visual Studio .NET 1.1","durationInYears":0},{"name":"MS Visual Interdev 6.0","durationInYears":0},{"name":"MS Active Server Pages 6.0","durationInYears":0},{"name":"MS Windows Server 2000","durationInYears":0},{"name":"MS SourceSafe 6.0","durationInYears":0},{"name":"AS/400 stormaskin","durationInYears":0},{"name":"VBScript","durationInYears":0},{"name":"MS Exchange Server 2000","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"Fulcrum Index Server","durationInYears":0},{"name":"MS Transaction Server","durationInYears":0},{"name":"IBM DB2","durationInYears":0}]},{"customer":"Forlagssentralen","description":"Løsning av spesifikt problem","longDescription":"Databaseteknisk problemløsning på Forlagssentralens IT-system for mottak og effektuering av bok-bestillinger, ifbm. problemer som oppsto i kjølvannet av re-installasjon på ny versjon av OS. Feilsøking, konfigurasjon og oppsett av MS SQL Server 2000.","period":{"from":[2005,3],"to":[2005,3]},"roles":[{"name":"Problemløser","description":"Databaseteknisk problemløsning på Forlagssentralens IT-system for mottak og effektuering av bok-bestillinger, ifbm. problemer som oppsto i kjølvannet av re-installasjon på ny versjon av OS. Feilsøking, konfigurasjon og oppsett av MS SQL Server 2000.\n\nRoald bidro til at en meget plagsom feil ble analysert og fikset."}],"skillsUsed":[{"name":"Apache","durationInYears":0},{"name":"MS SQL Server 2000","durationInYears":0},{"name":"Tomcat","durationInYears":0},{"name":"OPTA 2000 + diverse annen Javatek","durationInYears":0},{"name":"MS Windows Server 2003","durationInYears":0}]},{"customer":"Living","description":"Rapportløsning for møbelkjeden Living","longDescription":"Rapportløsning for møbelkjeden Living, som gikk ut på Extraction / Transformation / Loading (ETL) av varedata fra Axapta inn SQL Server 2000 OLAP-kuber for visning i Excel via webside.","period":{"from":[2004,11],"to":[2005,2]},"roles":[{"name":"Utvikler","description":"Design, utvikling og testing av varerapport i ASP.NET for visning av nøkkeltall (lager, salg og innkjøp) fra OLAP-kubene. Bidro i alle lagene av applikasjonen."}],"skillsUsed":[{"name":"MS Office Web Components 2003","durationInYears":0},{"name":"MS SQL Server 2000","durationInYears":0},{"name":"MS Visual Studio .NET 2003","durationInYears":0},{"name":"MS ASP.NET 1.1","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"MS Excel","durationInYears":0},{"name":"MDX","durationInYears":0},{"name":"MS SQL Server 2000 Analysis Services","durationInYears":0}]},{"customer":"Cicero Consulting","description":"CiceroPortalen","longDescription":"CiceroPortalen samt portaler med DnB- og Postbanken-informasjon (bl.a. fondskalkulatorer): Kunnskapsbase med mye markedsinformasjon om bank og finansbransjen, samt relevante nyheter og analyser/bakgrunnsartikler. Konstruert som en lukket internettportal som finanskonsern; de største spare- og forretningsbankene i Norge, har tilgang til.","period":{"from":[2004,10],"to":[2004,10]},"roles":[{"name":"Problemløser","description":"Problemløsning rundt import til datavarehus og bygging av kuber. Extraction / Transformation / Loading (ETL). Feilretting i COM+-komponenter og ASP-websider."}],"skillsUsed":[{"name":"MS SourceSafe 6.0","durationInYears":0},{"name":"Rational Rose Data Modeller","durationInYears":0},{"name":"VBScript","durationInYears":0},{"name":"MS Internet Information Server 5.0","durationInYears":0},{"name":"MS SQL Server 2000","durationInYears":0},{"name":"MS LDAP","durationInYears":0},{"name":"File Transfer Protocol","durationInYears":0},{"name":"MS COM+","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"MS Visual Interdev 6.0","durationInYears":0},{"name":"MS Commerce Server 2000","durationInYears":0},{"name":"MS Commerce Server 2000 Bizdesk","durationInYears":0},{"name":"MS Windows Server 2000","durationInYears":0},{"name":"MS Active Server Pages 6.0","durationInYears":0},{"name":"MS SQL Server 2000 Analysis Services (kuber","durationInYears":0},{"name":"MS Active Directory","durationInYears":0},{"name":"MS Visual Basic 6.0","durationInYears":0}]},{"customer":"Finansforbundet","description":"Ny nettløsning","longDescription":"Ny nettløsning (www.finansforbundet.no): Informasjonsportal med funksjonalitet for publisering nyheter, artikler og diskusjoner og utfylling av diverse skjema (verving, innmelding, hytte, kurs m.m.).","period":{"from":[2003,10],"to":[2004,3]},"roles":[{"name":"Utvikler","description":"Forvaltning. Design og utvikling av ASP-websider, databaseutvikling, vedlikehold/endring av .NET-basert wrapper for kall av diverse web services (bl.a. for medlemsbase). Tilpasning/endring av Digimaker ASP-websider og konfig. av Digimaker 4.0."}],"skillsUsed":[{"name":"JavaScript","durationInYears":0},{"name":"MS SourceSafe 6.0","durationInYears":0},{"name":"MS VB 6.0","durationInYears":0},{"name":"MS Visual Studio .NET 2003","durationInYears":0},{"name":"Digimaker 4.0","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"MS .NET Framework","durationInYears":0},{"name":"web services","durationInYears":0},{"name":"Zocas","durationInYears":0},{"name":"MS Transaction Server","durationInYears":0},{"name":"MS COM+","durationInYears":0},{"name":"VBScript","durationInYears":0},{"name":"MS Internet Information Server","durationInYears":0},{"name":"MS MDAC","durationInYears":0},{"name":"MS Windows Server 2000","durationInYears":0},{"name":"MS Active Server Pages 6.0","durationInYears":0},{"name":"XML","durationInYears":0},{"name":"MS SQL Server 2000","durationInYears":0}]},{"customer":"OBOS-megleren","description":"eMegler","longDescription":"eMegler er et komplett saksbehandlingssystem for eiendomsmeglingen og oppgjørsprosessen i Exact Eiendomsmegling, fra selger melder seg til oppgjør og overtakelse har funnet sted. Systemet er integrert med en rekke av OBOS sine andre kjernesystemer, bl.a. økonomisystem og medlemsregister på AS/400 stormaskin, og datavarehus/kuber/rapportering på Cognos-plattform.\nOBOS ønsket å endre eMegler slik at også OBOS-megleren o.a. meglerorg. i OBOS sin salgsdivisjon kunne ta det i bruk. Prosjektet innebar bl.a. integrasjon mot OBOS sitt medlemsregister på AS/400 og generering av OBOS-spesifikke annonser til web og avis.","period":{"from":[2003,1],"to":[2003,9]},"roles":[{"name":"Utvikler","description":"Database-design og utvikling, Extraction/Transformation/Loading (ETL), design, utvikling og testing av COM+-komponenter og ASP-websider. Alle typer dokumentasjon. Forvaltningsansvarlig for alle lag av eMegler. Rådgivning og teknisk bistand i alle typer driftsspørsmål.\n\nGjennom sine mange år på eMegler-prosjektene bidro Roald til stabilitet, forutsigbarhet og trygghet rundt driften og videreutviklingen av eMegler. Han mener også å ha avdekket og fikset mange feil og mangler, og sørget for at beste praksiser har blitt fulgt i alle lag av applikasjonen."}],"skillsUsed":[{"name":"IBM DB2","durationInYears":0},{"name":"MS Visual Interdev 6.0","durationInYears":0},{"name":"MS Exchange Server 2000","durationInYears":0},{"name":"MS SQL Server 2000 DTS","durationInYears":0},{"name":"MS MDAC","durationInYears":0},{"name":"MS Visual Basic 6.0","durationInYears":0},{"name":"MS COM+","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"80-20 Document Management Extensions Server 6.5 og 8.5","durationInYears":0},{"name":"MS Windows Server 2000","durationInYears":0},{"name":"MS SourceSafe 6.0","durationInYears":0},{"name":"MS Transaction Server","durationInYears":0},{"name":"MS Active Server Pages 6.0","durationInYears":0},{"name":"AS/400 stormaskin","durationInYears":0},{"name":"MS Internet Information Server 5.0","durationInYears":0},{"name":"MS Active Directory","durationInYears":0},{"name":"MS Commerce Server 2000","durationInYears":0},{"name":"MS SQL Server 2000","durationInYears":0},{"name":"MS Visual Studio .NET 1.1","durationInYears":0},{"name":"XML","durationInYears":0},{"name":"VBScript","durationInYears":0},{"name":"MS .NET Framework 1.1","durationInYears":0},{"name":"Rational Rose","durationInYears":0},{"name":"MS Windows NT 4.0","durationInYears":0},{"name":"MS LDAP","durationInYears":0},{"name":"C#","durationInYears":0},{"name":"Cognos","durationInYears":0},{"name":"Fulcrum Index Server","durationInYears":0}]},{"customer":"Exact Eiendomsmegling AS","description":"eMegler","longDescription":"eMegler er et komplett saksbehandlingssystem for eiendomsmeglingen og oppgjørsprosessen i Exact Eiendomsmegling, fra selger melder seg til oppgjør og overtakelse har funnet sted. Systemet er integrert med en rekke av OBOS sine andre kjernesystemer, bl.a. økonomisystem og medlemsregister på AS/400 stormaskin, og datavarehus/kuber/rapportering på Cognos-plattform.","period":{"from":[2001,8],"to":[2002,6]},"roles":[{"name":"Utvikler","description":"Databasedesign og -utvikling, Extraction / Transformation / Loading (ETL), design,utvikling og testing av COM+-komponenter og ASP-websider. Alle typer dokumentasjon.\n\nGjennom sine mange år på eMegler-prosjektene bidro Roald til stabilitet,forutsigbarhet og trygghet rundt driften og videreutviklingen av eMegler. Han mener også å ha avdekket og fikset mange feil og mangler, og sørget for at beste praksiser har blitt fulgt i alle lag av applikasjonen."}],"skillsUsed":[{"name":"XML","durationInYears":0},{"name":"MS Active Server Pages 6.0","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"MS Windows NT 4.0","durationInYears":0},{"name":"MS Commerce Server 2000","durationInYears":0},{"name":"MS SQL Server 2000","durationInYears":0},{"name":"MS SourceSafe 6.0","durationInYears":0},{"name":"Fulcrum Index Server","durationInYears":0},{"name":"MS SQL Server 2000 DTS","durationInYears":0},{"name":"IBM DB2","durationInYears":0},{"name":"MS LDAP","durationInYears":0},{"name":"MS Internet Information Server 5.0","durationInYears":0},{"name":"MS Transaction Server","durationInYears":0},{"name":"VBScript","durationInYears":0},{"name":"MS Visual Interdev 6.0","durationInYears":0},{"name":"MS .NET Framework 1.1","durationInYears":0},{"name":"MS Windows Server 2000","durationInYears":0},{"name":"MS Exchange Server 2000","durationInYears":0},{"name":"MS COM+","durationInYears":0},{"name":"MS Visual Studio .NET 1.1","durationInYears":0},{"name":"AS/400 stormaskin","durationInYears":0},{"name":"80-20 Document Management Extensions Server 6.5 og 8.5","durationInYears":0},{"name":"MS Active Directory","durationInYears":0},{"name":"Cognos","durationInYears":0},{"name":"MS MDAC","durationInYears":0},{"name":"Rational Rose","durationInYears":0},{"name":"MS Visual Basic 6.0","durationInYears":0},{"name":"C#","durationInYears":0}]},{"customer":"Cicero Consulting","description":"CiceroPortalen","longDescription":"CiceroPortalen samt portaler med DnB- og Postbanken-informasjon (bl.a. fondskalkulatorer): Kunnskapsbase med mye markedsinformasjon om bank og finansbransjen, samt relevante nyheter og analyser/bakgrunnsartikler. Konstruert som en lukket internettportal som finanskonsern; de største spare- og forretningsbankene i Norge, har tilgang til.","period":{"from":[2000,8],"to":[2001,6]},"roles":[{"name":"Utvikler","description":"Database design og -utvikling, Extraction / Transformation / Loading (ETL) (bl.a. fra Oslo Børs), design og utvikling av COM+-komponenter og ASP-websider, konfig. av MS Commerce Server, forvaltning. Bidro i alle lag av portalen."}],"skillsUsed":[{"name":"MS LDAP","durationInYears":0},{"name":"MS Windows Server 2000","durationInYears":0},{"name":"MS Active Directory","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"MS Visual Interdev 6.0","durationInYears":0},{"name":"MS Active Server Pages 6.0","durationInYears":0},{"name":"VBScript","durationInYears":0},{"name":"Rational Rose Data Modeller","durationInYears":0},{"name":"MS COM+","durationInYears":0},{"name":"MS Internet Information Server 5.0","durationInYears":0},{"name":"MS SQL Server 2000","durationInYears":0},{"name":"MS Visual Basic 6.0","durationInYears":0},{"name":"File Transfer Protocol","durationInYears":0},{"name":"MS SourceSafe 6.0","durationInYears":0},{"name":"MS Commerce Server 2000","durationInYears":0}]},{"customer":"Enitel ASA","description":"Nettsted for salg av telefoni/internett og automatisk logistikk","longDescription":"Nettsted for salg av og automatisk logistikk ifbm. telefoni- og internettabonnement, brukt ute hos forhandlere landet over (bl.a. Elkjøp).","period":{"from":[1999,2],"to":[2000,6]},"roles":[{"name":"Utvikler","description":"Design og utvikling av COM+-komponenter, databasedesign og utvikling, testing,\ndokumentasjon, konfig. av Site Server, forvaltning."}],"skillsUsed":[{"name":"MS Internet Information Server","durationInYears":0},{"name":"MS DCOM","durationInYears":0},{"name":"MS Active Server Pages 6.0","durationInYears":0},{"name":"VBScript","durationInYears":0},{"name":"MS Visual Basic 6.0","durationInYears":0},{"name":"MS COM+","durationInYears":0},{"name":"MS SQL Server 6.5 og 7.0","durationInYears":0},{"name":"Maconomy","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"MS Site Server 3.0","durationInYears":0}]},{"customer":"Posten SDS","description":"PUM / DP Web","longDescription":"Utredning av Postens eksisterende IT-utviklingsmiljø og vurderinger rundt fremtidige endringer i dette. Divisjon Posttjenester Web (DP Web): Intranett for de ansatte i Divisjon Posttjenester.","period":{"from":[1998,10],"to":[1999,1]},"roles":[{"name":"Utvikler","description":"Databaseteknisk rådgiver i PUM. Analyse av Posten Norges databasesystemer pr da og kartlegging aspekter ved innføring av nyere databaseteknologi. DP Web: Design og utvikling av ASP-websider og MS Site Server-basert publisering, medlemskap og søkefunksjonalitet."}],"skillsUsed":[{"name":"MS Site Server 3.0","durationInYears":0},{"name":"MS Active Server Pages 6.0","durationInYears":0},{"name":"MS SQL Server 6.5","durationInYears":0},{"name":"MS Visual Basic 6.0","durationInYears":0},{"name":"MS Internet Information Server","durationInYears":0},{"name":"MS COM+","durationInYears":0},{"name":"JavaScript","durationInYears":0},{"name":"Oracle","durationInYears":0},{"name":"VBScript","durationInYears":0},{"name":"MS DCOM","durationInYears":0}]},{"customer":"Rikshospitalet","description":"Sentral database-tjener","longDescription":"Hovedmål å etablere en sentral database-tjener for lagring av rekvisisjons- og prøveresultat-data.","period":{"from":[1998,9],"to":[1998,9]},"roles":[{"name":"Utvikler","description":"Utarbeidet logisk datamodell for databasen og foreslått overordnet design og implementasjon for database-tjeneren."}],"skillsUsed":[{"name":"ERWin/ERX 3.5","durationInYears":0},{"name":"Oracle8i","durationInYears":0},{"name":"UNIX","durationInYears":0},{"name":"C","durationInYears":0},{"name":"UNIX shell-script","durationInYears":0}]},{"customer":"Objectware AS","description":"System for timeregistrering","longDescription":"Utvidelse av system for timeregistrering i Objectware, med funksjoner for budsjettering og prognoser.","period":{"from":[1998,8],"to":[1998,8]},"roles":[{"name":"Utvikler","description":"Modellerte utkast til utvidelse av eksisterende relasjonsdatabase. Design og utvikling av Web-grensesnitt for budsjettering/prognose-funksjonene."}],"skillsUsed":[{"name":"DBArtisan 4.01","durationInYears":0},{"name":"ERWin/ERX 3.5","durationInYears":0},{"name":"MS SQL Server 6.5","durationInYears":0}]},{"customer":"Fred Olsen & Co","description":"Fred Olsen Nettsted","longDescription":"Fred Olsen Nettsted: Informasjonsportal for Fred Olsen & Co.","period":{"from":[1998,7],"to":[1998,7]},"roles":[{"name":"Utvikler","description":"Database-design i en pre-fase av prosjektet. Modellerte og implementerte utkast til databasen."}],"skillsUsed":[{"name":"ERWin/ERX 3.5","durationInYears":0},{"name":"DBArtisan 4.01","durationInYears":0},{"name":"Microsoft SQL Server 6.5","durationInYears":0}]},{"customer":"Telenor Bedrift AS","description":"LO-PC-prosjektet","longDescription":"Database for PC-leveranser til LO-medlemmer.","period":{"from":[1998,6],"to":[1998,6]},"roles":[{"name":"Utvikler","description":"Database-design. Modellerte og implementerte utkast til databasen."}],"skillsUsed":[{"name":"ERWin/ERX 3.5","durationInYears":0},{"name":"DBArtisan 4.01","durationInYears":0},{"name":"Microsoft SQL Server 6.5","durationInYears":0}]},{"customer":"Universitetet i Tromsø","description":"Studentopptaket","longDescription":"Behandling / vurdering av søknader til studier ved Universitet i Tromsø.","period":{"from":[1994,6],"to":[1997,8]},"roles":[{"name":"","description":""},{"name":"Konsulent / Fagansvarlig / Saksbehandler","description":"Sommerjobb som konsulent og saksbehandler på alle studier ved UiTø, med spesielt ansvar for faglige vurderinger og opptak av nye studenter til Sivilingeniørstudiets linjer fysikk, informatikk og bioteknologi."}],"skillsUsed":[{"name":"Høgskoleingeniør Data og Elektronikk, Cand mag Informatikk","durationInYears":0}]},{"customer":"Universitetet i Tromsø","description":"Funksjonell programmering","longDescription":"Vitenskapelig assistent i faget \"Funksjonell programmering\" våren 1996.","period":{"from":[1996,1],"to":[1996,6]},"roles":[{"name":"Vitenskapelig assistent","description":"Lage elevoppgaver fra pensum og bistå studentene med oppgaveløsningen."}],"skillsUsed":[{"name":"Funksjonell programmering","durationInYears":0}]},{"customer":"Garnisonen i Porsanger","description":"Militærtjeneste","longDescription":"Militærtjeneste v/Voksenopplæringen. Studieveiledning for soldater. Kurs- administrasjon. Driftsansvarlig for PC-nettverk. Utvikling av Voksenopplæringens Excel-applikasjon for regnskap og budsjett. Holdt PC-innføringskurs og kurs i Turbo Pascal.","period":{"from":[1991,8],"to":[1992,6]},"roles":[],"skillsUsed":[{"name":"Høgskoleingeniør Data og Elektronikk","durationInYears":0}]},{"customer":"Statens Vegvesen","description":"Ny E6","longDescription":"","period":{"from":[1988,6],"to":[1990,8]},"roles":[{"name":"Veiarbeider","description":"Sommerjobb som motorsagfører."}],"skillsUsed":[]},{"customer":"Helsedirektoratet","description":"Registerplattform","longDescription":"Datavarehusteamet (DVT) er ansvarlig for teknisk drift og utvikling av avdelingens datavarehus og kuber. DVT er ikke en egen organisatorisk enhet, men organisert under seksjon DHDR i avdeling helseregistre (AHR). Kjernen i DVT er utviklerne. Det er vanlig at et utviklingsteam innenfor Scrum-metodikken bestå av 5-9 utviklere hvorav en er ScrumMaster. I DHHR har DVT også ansvaret for drift av datavarehuset. \n\nDatavarehuset i AHR skal dekke flere behov. Det skal bl.a være kilden til\n* Presentasjoner på internett\n* Eksempel Ventelisterapporter, styringsdata, …\n* Utlevering av personsensitive og ikke personsensitive data til forskere og andre\n* Utlevering av styringsinformasjon til RHFene (Region helseforetak).\n* Innbyggernes rett til innsyn i egne data\nOg mye, mye mer\nDette mangslungne behovet gjør at det er behov for data i ulike \"tilstander\". Helt fra \"rå\" kopier av det materialet som ble innlevert, til kvalitetssikrede og berikede datasett.\n\nFor å dekke behovet for manuelle og automatiske leveranser til ulike formål, har vi en kopi av de innleverte data, det vi kaller rådata, tilgjengelig. Disse er omstrukturert fra strukturen de ble innlevert i til en struktur som passer bedre for våre behov.\n\nFor å dekke behov i presentasjonslaget, bruker vi stjernemodeller. Her har vi basert oss på Kimballs prinsipper og følger så langt som mulig best practice på dette området. Vi leverer ferdige kuber som underlag for presentasjoner med Dundas og Power BI, der det er stilt krav til anonymisering. For andre presentasjoner, der detaljeringsbehovet ikke er så stort, leverer vi databaser med fakta- og dimensjonstabeller.\n\nAlt dette er On-Prem. Vi kjører Microsoft SQL Server 2017 og bruker hele porteføljen. SQL Server som databasemotor, SSIS som ETL-verktøy, SSAS for kuber, samt at vi bruker SSRS, om enn i liten grad, Dundas of Power BI for rapporter.\n\nQA og Produksjon kjører på fysiske servere, testmiljø og utviklerdesktoper kjører på VM'r Utviklerne har SQL Server installert lokalt, og benytter Visual Studio 2017 med addons for SSIS, SSAS og SSRS som utviklingsverktøy.\n\nAzure DevOps (On-prem-versjonen) benyttes for kildekodekontroll (Git), bygg og deploy. Det er satt opp automatisert bygg og deploy i DevOps. Bruker stort sett standardkomponentene i DevOps, men har installert noen ekstra komponenter for å få støtte for SSIS og SSAS. I tillegg er det utviklet egne rutiner i PowerShell som benyttes ved deploy.","period":{"from":[2022,10],"to":[2023,8]},"roles":[{"name":"BI-utvikler","description":"Scrum team member'. Utvikler på SQL Server Integration Services (SSIS), databaseutvikling på SQL Server, kube-utvikling på SQL Server Analysis Services (SSAS).  Testing og feilretting. Drifting av jobber i SQL Server Agent. Azure Devops- og Git-bruker."}],"skillsUsed":[{"name":"SQL Server Integration Services","durationInYears":0},{"name":"SQL Server databases","durationInYears":0},{"name":"Azure Devops","durationInYears":0},{"name":"SQL Server Analysis Services","durationInYears":0},{"name":"SQL Server Agent jobs","durationInYears":0},{"name":"Git","durationInYears":0}]}],"educations":[{"degree":"Høgskoleingeniør","school":"Narvik Ingeniørhøgskole","period":{"from":[1988,1],"to":[1991,12]}},{"degree":"Cand. Scient. i Informatikk","school":"Universitet i Tromsø","period":{"from":[1992,1],"to":[1998,12]}}],"certifications":[],"courses":[],"languages":[{"name":"Bokmål, Norsk","level":"(morsmål)"},{"name":" Engelsk","level":"Flytende skriftlig og muntlig"}],"skillCategories":[{"name":"Programmeringsspråk","skills":[{"name":"JavaScript","durationInYears":11}]}],"qualityScore":null}
